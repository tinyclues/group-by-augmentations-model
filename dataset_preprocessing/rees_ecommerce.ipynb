{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55b9dd37-bc41-46af-9aa1-e20ee99ecdd0",
   "metadata": {},
   "source": [
    "# Preparing Rees46 eCommerce dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2990553d-ecf8-4dd8-b5e3-f49b57b62d64",
   "metadata": {},
   "source": [
    "## Downloading raw datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd2ee2b-4ecf-4d4e-974c-7014405e5e21",
   "metadata": {},
   "source": [
    "Dataset description is available at\n",
    "* https://rees46.com/en/datasets\n",
    "* https://www.kaggle.com/datasets/mkechinov/ecommerce-behavior-data-from-multi-category-store\n",
    "\n",
    "More data is at\n",
    "* https://drive.google.com/drive/folders/1Nan8X33H8xrXS5XhCKZmSpClFTCJsSpE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39b06624-84f7-4d40-b626-3709badc75ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 21:01:45.850093: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n",
      "2022-10-23 21:01:45.850173: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/recsys-multi-atrribute-benchmark/datasets'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import DATASETS_ROOT_DIR\n",
    "# Directory where those datasets will be downloaded:\n",
    "DATASETS_ROOT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5842cf-b793-47f1-bd7b-38e637d163af",
   "metadata": {},
   "source": [
    "## Download manually archives from Google drive to `$DATASETS_ROOT_DIR/raw`\n",
    "For now one need to manually download data from https://drive.google.com/drive/folders/1Nan8X33H8xrXS5XhCKZmSpClFTCJsSpE to `$DATASETS_ROOT_DIR/raw`\n",
    "\n",
    "TODO: make it automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d216e12-2e5a-462c-adc1-b41306a1f3b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-Mar.csv.gz',\n",
       " '2020-Apr.csv.gz',\n",
       " '2020-Feb.csv.gz',\n",
       " '2020-Jan.csv.gz',\n",
       " '2019-Dec.csv.gz']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "list(map(os.path.basename, glob.glob(os.path.join(DATASETS_ROOT_DIR, 'raw/rees_ecommerce/*'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bd0e74-09db-4817-8942-d8e91c75f743",
   "metadata": {},
   "source": [
    "## Loading big dataframe in chunks\n",
    "In this notebook to keep reasonable RAM consumption we load only purchase and add to cart event types, skipping pageviews.\n",
    "\n",
    "We also directly replace null values by empty strings, and take day resolution for dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b6e450-05fb-450d-a2f0-9a26f0a5ffa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 36s, sys: 1min 11s, total: 20min 48s\n",
      "Wall time: 20min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "_chunks = []\n",
    "for filename in glob.glob(os.path.join(DATASETS_ROOT_DIR, 'raw/rees_ecommerce/*')):\n",
    "    with pd.read_csv(filename, chunksize=10 ** 7) as reader:\n",
    "        for chunk in reader:\n",
    "            # Setting date resolution to days\n",
    "            chunk['date'] = chunk['event_time'].str[:10].astype('datetime64[D]')\n",
    "            # one can subsample pageviews by day\n",
    "            # counts = chunk.groupby(['event_type', 'user_id', 'date'])['user_id'].transform('count')\n",
    "            # keep_lines = ((chunk['event_type'] != 'view') | (np.random.uniform(size=len(chunk)) < 5. / counts))\n",
    "            # here we just filter them out\n",
    "            keep_lines = (chunk['event_type'] != 'view')\n",
    "            _chunks.append(chunk[keep_lines].fillna('').drop(['user_session', 'event_time'], axis=1))\n",
    "\n",
    "del chunk\n",
    "events = pd.concat(_chunks)\n",
    "del _chunks\n",
    "events = events.sort_values('date', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c7c9ca-893e-41d9-8413-90330286b486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cart        15158617\n",
       "purchase     5189036\n",
       "Name: event_type, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events['event_type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1f4ac9-f7ec-43b6-87a4-f23942755802",
   "metadata": {},
   "source": [
    "We will construct our training dataset as implicit feedback of purchases, so we will restrict all tables to users with at least one purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f1be7a5-7dfc-4311-9835-8b239df2a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_with_purchases = events[events['event_type'] == 'purchase']['user_id'].unique()\n",
    "events = events[np.isin(events['user_id'], users_with_purchases)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60b20e2e-47b3-433c-adc4-e1b112da2d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cart        11786602\n",
       "purchase     5189036\n",
       "Name: event_type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events['event_type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aa8e7c-e782-4206-a51e-eeaca1785829",
   "metadata": {},
   "source": [
    "## Choosing features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac922d4e-da18-474d-a610-9fa9975ac2ac",
   "metadata": {},
   "source": [
    "We will be using following features:\n",
    "* `product_id`\n",
    "* `category_code`\n",
    "* `brand`\n",
    "* product's `price`\n",
    "\n",
    "At this point they contain no null (nulls were replaced by empty string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9943f1d-743d-4928-aea1-30d49a3239c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id       0\n",
       "category_code    0\n",
       "brand            0\n",
       "price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[['product_id', 'category_code', 'brand', 'price']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217dd24e-c620-44c6-839e-090be49194f2",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c5e525-d04f-42b7-bdd9-48a086158d9a",
   "metadata": {},
   "source": [
    "Here we will do some simple feature engineering on product attributes:\n",
    "* parsing `category_code` into 4 levels of categories hierarchy\n",
    "* clusterize `price`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75c28eac-8677-4942-ae58-b5d0ac3ea4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz import memoize\n",
    "\n",
    "@memoize\n",
    "def define_categories(label):\n",
    "    \"\"\"\n",
    "    Parsing category_code labels into 4 levels of categories' hierarchy\n",
    "    \"\"\"\n",
    "    if label == '':\n",
    "        return '', '', '', ''\n",
    "    labels = tuple(label.split('.'))\n",
    "    if len(labels) > 4:\n",
    "        raise NotImplementedError()\n",
    "    return labels + ('',) * (4 - len(labels))\n",
    "\n",
    "events['category1'], events['category2'], events['category3'], events['category4'] = \\\n",
    "    zip(*events['category_code'].map(define_categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b649a37e-77fa-45a2-8f34-b0184ff671d0",
   "metadata": {},
   "source": [
    "`category4` is mostly empty, so we won't use that feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b513649-e299-44b9-8ab8-d9554c2a3ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         16962296\n",
       "piano       13342\n",
       "Name: category4, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events['category4'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab071f73-93ed-4ab1-927a-0d6494b06555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "light            7135027\n",
       "                 4592235\n",
       "massager          606955\n",
       "headphone         432323\n",
       "refrigerators     380170\n",
       "vacuum            324322\n",
       "washer            265951\n",
       "printer           200670\n",
       "sandals           180985\n",
       "slipons           169627\n",
       "Name: category3, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events['category3'].value_counts(dropna=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ad2b252-6d42-4cf3-bc52-92c12c1c52be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 11s, sys: 2.65 s, total: 2min 14s\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans_price = KMeans(n_clusters=200, random_state=42)\n",
    "kmeans_price.fit(events['price'].sample(5 * 10 ** 5, random_state=43).values.reshape(-1, 1))\n",
    "cluster_labels = np.round(kmeans_price.cluster_centers_[:, 0], 0).astype(int)\n",
    "assert len(np.unique(cluster_labels)) == 200\n",
    "events['priceCluster'] = cluster_labels[kmeans_price.predict(events['price'].values.reshape(-1, 1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae5808-5a9c-4c1b-8ff6-32df28975f7a",
   "metadata": {},
   "source": [
    "## Encoding features and converting them into `tf.Tensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aba699-7bfd-4c7c-bfab-1a59b170a987",
   "metadata": {},
   "source": [
    "Now let's encode categorical features into ordinal using `tf.keras.layers.StringLookup` and transform out dataset into a dictionary with `tf.Tensor` for each column - result will be kept in `tf_tensors`.\n",
    "\n",
    "We also keep track of inverse transformation should we want to see a value corresponding to some label - it will be stored in `inverse_lookups` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f083889-1a08-4242-9080-7695fa7922ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 21:28:47.940226: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n",
      "2022-10-23 21:28:47.982594: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-23 21:28:48.005438: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fb5e7a735510): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding product_id column\n",
      "Reserving labels for 28113 categories out of 180632\n",
      "Encoding category1 column\n",
      "Reserving labels for 14 categories out of 14\n",
      "Encoding category2 column\n",
      "Reserving labels for 61 categories out of 63\n",
      "Encoding category3 column\n",
      "Reserving labels for 91 categories out of 92\n",
      "Encoding brand column\n",
      "Reserving labels for 2562 categories out of 5015\n",
      "Encoding priceCluster column\n",
      "Reserving labels for 200 categories out of 200\n",
      "CPU times: user 1min 8s, sys: 2.13 s, total: 1min 10s\n",
      "Wall time: 1min 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 21:28:48.303043: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from utils import get_tensorflow_dataset\n",
    "\n",
    "item_features = ['product_id', 'category1', 'category2', 'category3', 'brand', 'priceCluster']\n",
    "\n",
    "tf_tensors, inverse_lookups = get_tensorflow_dataset(events, item_features,\n",
    "                                                     date_column='date', keep_columns=['user_id', 'event_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebd792d9-7680-4308-a0b5-7e4b11b86d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([18231, 18231], dtype=int32)>,\n",
       " 'user_id': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([579849385, 560376695])>,\n",
       " 'event_type': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'cart', b'purchase'], dtype=object)>,\n",
       " 'product_id': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([3390,   19], dtype=int32)>,\n",
       " 'category1': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10], dtype=int32)>,\n",
       " 'category2': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10], dtype=int32)>,\n",
       " 'category3': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10], dtype=int32)>,\n",
       " 'brand': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([103,  11], dtype=int32)>,\n",
       " 'priceCluster': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 61, 165], dtype=int32)>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import gather_structure\n",
    "gather_structure(tf_tensors, [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e80888b1-2649-4a01-a365-79933c636a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.preprocessing.string_lookup.StringLookup at 0x7fa64f87f110>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_lookups['category2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae48ff00-9c48-4eb3-af30-834d4aeeb197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'tools', b'tools'], dtype=object)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_lookups['category2'](tf_tensors['category2'][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01b0f0f-1fb9-436b-b2f8-8760bd5be9b1",
   "metadata": {},
   "source": [
    "For film ids we can replace reverse mapping by film names for more readability if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25400d5e-2c37-46ae-b600-b2b55b98d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_inverse_lookups\n",
    "\n",
    "save_inverse_lookups(inverse_lookups, os.path.join(DATASETS_ROOT_DIR, 'rees_ecommerce/inverse_lookups.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88addb59-9ace-403f-8e00-afa8e2e42df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del inverse_lookups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbe318a-dca3-42a6-a817-1a0c7988c79d",
   "metadata": {},
   "source": [
    "## Changing format to event sequences by user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8cf793-6253-4873-a533-ee697d0722a5",
   "metadata": {},
   "source": [
    "From this point we won't need `pd.DataFrame` anymore and will work with tensorflow objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23b9dfe1-10c8-46ba-9e9d-a9da95407e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "del events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f505999-ee5d-4fa4-a804-a26353322845",
   "metadata": {},
   "source": [
    "Then, let's define for each user and for each type of event (purchase, add_to_cart, pageview) a sequence of corresponding events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62a2dd90-d0b4-4a41-9205-a928842ce90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from utils import get_user_sequences, boolean_mask_structure\n",
    "\n",
    "tf_tensors = {key.decode(): boolean_mask_structure(tf_tensors, tf_tensors['event_type'] == key)\n",
    "              for key in tf.unique(tf_tensors['event_type'])[0].numpy()}\n",
    "tf_tensors = get_user_sequences(tf_tensors, 'purchase', 'user_id')\n",
    "\n",
    "for tensors_dict in tf_tensors.values():\n",
    "    # no need in event_type it is now in dict keys\n",
    "    del tensors_dict['event_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af049ffe-af65-421e-a814-752999c076a1",
   "metadata": {},
   "source": [
    "Now our dict contains additional technical key `_user_index` that encodes what events correspond to what user. To get sequences of events one can simply gather a feature's values using this index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da1303b8-8dc5-4773-907c-30d4593bb69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tf_tensors['purchase']['_user_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb1bb00-3981-441f-9dec-2a3281d360a2",
   "metadata": {},
   "source": [
    "First dimension of this tensor corresponds to unique users, second corresponds to line numbers of events for a given user. By taking bounding shape we see number of unique users and maximal number of ratings done by one user in train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25f6a235-eeec-4f93-8b24-3a8be72f6c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1635044,    1978], dtype=int32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_tensors['purchase']['_user_index'].bounding_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540b8c3f-ebbd-475c-8b3e-b5c50534f526",
   "metadata": {},
   "source": [
    "We use same indexing of users for all event types: indexing is based on purchase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8f0dfef-3817-4bf8-bcdd-2e6802b69076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1635044,    2187], dtype=int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_tensors['cart']['_user_index'].bounding_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54902c6f-dfe6-4165-9f04-8c6e507018d8",
   "metadata": {},
   "source": [
    "Thus we can have empty sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0175276-daa4-4998-b0d2-69cca321353d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_any(tf_tensors['cart']['_user_index'].row_lengths() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb3a9f8-76d8-4ded-bb08-7ca635fe0dae",
   "metadata": {},
   "source": [
    "Each event type have local indices (this property will be kept for each batch) starting from 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f6ceef1-424d-4c44-9a8b-f2e9d25d0f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[0, 203, 148584, 627030, 696926], [1, 7751, 9146, 9192, 9353], [2]]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_tensors['purchase']['_user_index'][:3, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc36c4a0-5c08-4723-a341-f230b22d54d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[83, 267, 434, 831, 332907], [74, 18608, 21758, 21803, 21841],\n",
       " [159, 633, 3067810]]>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_tensors['cart']['_user_index'][:3, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f934da7-3e77-42df-9ca8-f6e2e054bd74",
   "metadata": {},
   "source": [
    "To get all categories added by user to cart it is enough to gather on correspondant tensor. In this example we limit to 3 users, 5 categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b940e23-d6cb-49b3-8cea-3f69b6e7493b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[10, 10, 10, 10, 24], [21, 10, 24, 24, 13], [12, 12, 10]]>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather(tf_tensors['cart']['category2'], tf_tensors['cart']['_user_index'][:3, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca168da2-639a-4128-a242-c1952b7b3702",
   "metadata": {},
   "source": [
    "## Split into train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33be8212-1be3-407a-b3a5-f4a228e294eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/jupyter/recsys-multi-atrribute-benchmark/dataset_preprocessing/utils.py'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "importlib.reload(sys.modules['utils'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3691310-3972-4d17-8963-8dea306b1798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function gather_structure at 0x7fa710650560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "CPU times: user 9.55 s, sys: 398 ms, total: 9.95 s\n",
      "Wall time: 4.72 s\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from toolz import valmap\n",
    "\n",
    "from utils import restrict_to_user_index_subset\n",
    "\n",
    "permutation = tf.random.shuffle(tf.range(tf_tensors['purchase']['_user_index'].shape[0]), seed=1729)\n",
    "tensors = {\n",
    "    'test': valmap(partial(restrict_to_user_index_subset, indices=permutation[:200000]), tf_tensors),\n",
    "    'val': valmap(partial(restrict_to_user_index_subset, indices=permutation[200000:400000]), tf_tensors),\n",
    "    'train': valmap(partial(restrict_to_user_index_subset, indices=permutation[400000:]), tf_tensors)\n",
    "}\n",
    "\n",
    "del tf_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ae81c3f-0cde-447d-b56f-d2c009fa34d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([200000,   1074], dtype=int32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors['test']['cart']['_user_index'].bounding_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77e7fd2a-3fea-475a-a793-96b065cfbb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1235044,    2187], dtype=int32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors['train']['cart']['_user_index'].bounding_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6167db3-140e-456b-814b-2c35d271e0f9",
   "metadata": {},
   "source": [
    "## Batching by users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3706ebdc-fefd-4f63-9253-3b5531eb6b1a",
   "metadata": {},
   "source": [
    "For further operation let's transform dicts into `tf.data.Dataset` batched by users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "632cb3c9-1d3b-4558-8688-245452732dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 10 calls to <function gather_structure at 0x7fa710650560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "from utils import batch_by_user\n",
    "\n",
    "datasets = {}\n",
    "for split_name, tensors_dict_by_event in tensors.items():\n",
    "    datasets[split_name] = batch_by_user(tensors_dict_by_event, 'purchase', 5 * 10 ** 3, seed=12345)\n",
    "    \n",
    "del tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a348ce44-72bc-4a42-acdc-4911e6648eb8",
   "metadata": {},
   "source": [
    "Now we have `tf.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f484051-bb4d-4bda-b39a-ddca76c247f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.ConcatenateDataset"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(datasets['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9553c6-17b5-4bad-8a6d-ae1bb1c55170",
   "metadata": {},
   "source": [
    "where each batch contain 5000 unique users and batch values is a dict with event type as key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "903d5bc8-0690-4d46-858c-1caa428edc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(iter(datasets['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0668e805-372e-4f1d-ba9e-093dff47ee4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cart', 'purchase'])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1b2ddcbe-c5c7-4bbc-9d40-923b445238bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_user_index', 'date', 'user_id', 'product_id', 'category1', 'category2', 'category3', 'brand', 'priceCluster'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch['purchase'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2f1b4494-0046-42cc-8048-f106925508e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([5000,  406], dtype=int32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch['purchase']['_user_index'].bounding_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7a22a7-6fd5-4e51-8c8c-162afdebc689",
   "metadata": {},
   "source": [
    "For now we have less users in last batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e5d4a30-5690-4029-a850-a434819cfc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([44, 10], dtype=int32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for last_batch in datasets['train']:\n",
    "    pass\n",
    "last_batch['purchase']['_user_index'].bounding_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62718662-b0fc-4ccd-a5f3-c6119f08f764",
   "metadata": {},
   "source": [
    "Note that we kept local batch indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1f1acf01-e2a7-4888-9301-d0c72d77a535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[0, 1, 2, 3, 4], [5, 6, 7], [8]]>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_batch['purchase']['_user_index'][:3, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9a3a30-d1ad-4a87-8cdc-2eadf89edb32",
   "metadata": {},
   "source": [
    "## Saving raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5c97e5e6-1cac-4420-ab64-7f367ac2777f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.4 s, sys: 176 ms, total: 42.6 s\n",
      "Wall time: 42.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for split_name, dataset in datasets.items():\n",
    "    tf.data.experimental.save(dataset, os.path.join(DATASETS_ROOT_DIR, f'rees_ecommerce/raw_{split_name}_dataset.tf'),\n",
    "                              compression='GZIP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1d2075-3427-4797-acaa-a490b3924109",
   "metadata": {},
   "source": [
    "## Aggregate preceding events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d52837-f9e5-4568-8a9c-b60404789d73",
   "metadata": {},
   "source": [
    "Till now we have only features describing items. To describe users let's consider following features:\n",
    "* for each `user_id`, `date` we look at events done on previous dates\n",
    "* independently for each item feature we construct lists of those features corresponding to preceding events\n",
    "\n",
    "So if a user have rated some films\n",
    "\n",
    "| **product_id** | **category**   | **date** |\n",
    "|----------------|-------------|----------|\n",
    "| `1`            | Shoes       | `20/01`  |\n",
    "| `9`            | Phone       | `25/01`  |\n",
    "| `8`            | Shoes       | `25/01`  |\n",
    "| `3`            | Books       | `30/01`  |\n",
    "\n",
    "we will construct `aggregated_product_id` and `aggregated_category` features as\n",
    "\n",
    "| **aggregated_product_id** | **aggregated_category**    | **date** |\n",
    "|---------------------------|----------------------------|----------|\n",
    "| []                        | []                         | `20/01`  |\n",
    "| [`1`]                     | [Shoes]                    | `25/01`  |\n",
    "| [`1`]                     | [Shoes]                    | `25/01`  |\n",
    "| [`1`, `9`, `8`]           | [Shoes, Phone, Shoes]      | `30/01`   |\n",
    "\n",
    "and so for each user, for each date corresponding to events we want to predict (`purchase` here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5f54e450-e49a-4935-981c-03db61c65294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from utils import aggregate_preceding_events\n",
    "\n",
    "aggregated_datesets = {}\n",
    "for split_name, dataset in datasets.items():\n",
    "    agg_func = partial(aggregate_preceding_events, target='purchase', item_features=item_features,\n",
    "                       user_id_column='user_id', date_column='date')\n",
    "    aggregated_datesets[split_name] = dataset.map(agg_func, num_parallel_calls=2, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f3e55bf0-34ce-41e9-956b-f0a06f4f6752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['aggregated_cart_product_id', 'aggregated_cart_category1', 'aggregated_cart_category2', 'aggregated_cart_category3', 'aggregated_cart_brand', 'aggregated_cart_priceCluster', 'aggregated_purchase_product_id', 'aggregated_purchase_category1', 'aggregated_purchase_category2', 'aggregated_purchase_category3', 'aggregated_purchase_brand', 'aggregated_purchase_priceCluster', 'product_id', 'category1', 'category2', 'category3', 'brand', 'priceCluster', 'user_id', 'date'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch = next(iter(aggregated_datesets['train']))\n",
    "first_batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7596b6-0770-4c69-ae89-59d9c524897a",
   "metadata": {},
   "source": [
    "So resulting structure contains\n",
    "* aggregated historical features: for each user (1st dim), each target event (2nd dim) we have a list of previous event's attributes (3rd dim)\n",
    "* raw item features, user id, date: for each user (1st dim) we have a list of target events (2nd dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c0a71982-3cfc-4a73-a421-505b95e999ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([5000,  406,  100], dtype=int32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch['aggregated_cart_category1'].bounding_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e6cc98d9-f8d2-40ba-8cfd-b05572fc0367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([5000,  406], dtype=int32)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch['category1'].bounding_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b6f5dc-27f9-46cc-9d58-2713f79d14d3",
   "metadata": {},
   "source": [
    "## Saving resulting datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ad5c3cda-2b58-4057-a392-41b6e0898777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 55s, sys: 7.08 s, total: 14min 2s\n",
      "Wall time: 4min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for split_name, dataset in aggregated_datesets.items():\n",
    "    tf.data.experimental.save(dataset, os.path.join(DATASETS_ROOT_DIR, f'rees_ecommerce/aggregated_{split_name}_dataset.tf'),\n",
    "                              compression='GZIP')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom [moksha-tf2-cpu.2-7] (Local)",
   "language": "python",
   "name": "local-eu.gcr.io_tinyclues-experiments_tinyclues_moksha-tf2-cpu.2-7_latest__python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
