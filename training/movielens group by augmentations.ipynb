{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea932e5b",
   "metadata": {},
   "source": [
    "# Bi-linear interaction model with group-by augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b6f05f",
   "metadata": {},
   "source": [
    "## Prepare dataset for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96897ae",
   "metadata": {},
   "source": [
    "Following the same steps as in [the training of a simple model](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/training/movielens%20simple%20model.ipynb), we first load splitted dataset generated in [notebook](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/dataset_preprocessing/movielens%20with%20imdb.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1899e738-56d3-455f-afcd-ce80fcb17232",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'movielens_imdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19cc05cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_dataset\n",
    "\n",
    "datasets = {}\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    datasets[split_name] = load_dataset(DATASET, split_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d1b29e",
   "metadata": {},
   "source": [
    "Then we parse features' names to obtain a list of offer features (that will be used to modelize film) and a list of user features (aggregated history up to chosen date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5077ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import AGG_PREFIX\n",
    "\n",
    "all_columns = list(datasets['train'].element_spec.keys())\n",
    "technical_columns = ['userId', 'date']\n",
    "user_features = list(filter(lambda x: x.startswith(AGG_PREFIX), all_columns))\n",
    "offer_features = list(filter(lambda x: x not in user_features + technical_columns, all_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7d5781",
   "metadata": {},
   "source": [
    "### Rebatching datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96990cb",
   "metadata": {},
   "source": [
    "Splitting dataset into smaller batches in the same way as described in [the training of a simple model](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/training/movielens%20simple%20model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfa53a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38 s, sys: 6.38 s, total: 44.3 s\n",
      "Wall time: 34.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from functools import partial\n",
    "from uuid import uuid4\n",
    "\n",
    "from utils import rebatch_by_events\n",
    "\n",
    "datasets['train'] = rebatch_by_events(datasets['train'], batch_size=10080, date_column='date', nb_events_by_user_by_day=8)\n",
    "for key in ['val', 'test']:\n",
    "    datasets[key] = rebatch_by_events(datasets[key], batch_size=50400, date_column='date', nb_events_by_user_by_day=8,\n",
    "                                      seed=1729).cache(f'/tmp/{uuid4()}.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20173463-08c7-4b6f-a9b8-ade7c5c1121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import add_equal_weights\n",
    "\n",
    "for key in datasets:\n",
    "    datasets[key] = datasets[key].map(partial(add_equal_weights, features=offer_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10790714",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c685bae",
   "metadata": {},
   "source": [
    "First we need to get number of different modalities inputs can take from saved vectorizers (it will be used in embeddings layer definition):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb20fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_inverse_lookups\n",
    "inverse_lookups = load_inverse_lookups(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a92d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "vocabulary_sizes = {}\n",
    "\n",
    "for feature in offer_features:\n",
    "    vocabulary_sizes[feature] = inverse_lookups[feature].vocabulary_size()\n",
    "\n",
    "for feature in user_features:\n",
    "    for key in inverse_lookups:\n",
    "        pattern = re.compile(r\"{}(\\w+)_{}\".format(AGG_PREFIX, key))\n",
    "        if pattern.match(feature):\n",
    "            vocabulary_sizes[feature] = vocabulary_sizes[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9119b378",
   "metadata": {},
   "source": [
    "### Layers definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9643942",
   "metadata": {},
   "source": [
    "To define a model with group-by augmentations we need to create some layers described in [this blog post](https://medium.com/p/508d5080c0c6/). In all following schemas we color weights that will be learned during training in red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bc288f",
   "metadata": {},
   "source": [
    "#### Generation of group-by augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37870c44",
   "metadata": {},
   "source": [
    "To get group-by augmentations we need first choose randomly some offer features we will use to get group by keys that will consist of AND and OR combinations of values from chosen features. It is implemented in `KeyGenerator` layer. Next once we get keys, we will group by and calculate mean and variance embeddings vectors for other features wrt to chosen keys. Finally, we will broadcast mean and variance vectors back to return to original batch size. Both calculation and broadcast are implemented in `GroupBy` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1753e74f-9f8b-4ed5-aa0a-cc0a829794ef",
   "metadata": {},
   "source": [
    "<img src=\"resources/group_by_augmentation.png\" alt=\"group-by augmentation generation\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35350305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from layers import KeyGenerator, GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0823204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_key_generator = KeyGenerator(number_of_offer_attributes=len(offer_features),\n",
    "                                  average_number_of_attributes_in_key=2,\n",
    "                                  name='test_key_generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b348b68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 7), dtype=int32, numpy=\n",
       "array([[2, 2, 4, 0, 1, 1, 1],\n",
       "       [4, 2, 1, 0, 4, 4, 1],\n",
       "       [3, 3, 2, 3, 1, 0, 3],\n",
       "       [4, 2, 1, 3, 4, 0, 0],\n",
       "       [2, 1, 4, 1, 4, 2, 0],\n",
       "       [1, 4, 3, 4, 1, 4, 2],\n",
       "       [1, 1, 2, 4, 2, 3, 2],\n",
       "       [0, 3, 2, 0, 1, 1, 4],\n",
       "       [1, 3, 1, 2, 3, 1, 0],\n",
       "       [2, 2, 4, 3, 1, 4, 4]], dtype=int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampling randomly values for offer features\n",
    "test_offer_features = tf.random.uniform((10, len(offer_features)), maxval=5, dtype=tf.int32)\n",
    "test_offer_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "998c2da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([3, 3, 1, 3, 0, 0, 0, 2, 1, 2], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key generator returns hashed keys for group by\n",
    "test_keys = test_key_generator(test_offer_features)\n",
    "test_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7598fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by = GroupBy(name='group_by')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "314d05c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have some embeddings vectors\n",
    "test_embeddings = tf.random.normal((10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ffa681f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([10, 3]), TensorShape([10, 3]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can apply group-by operation for all features\n",
    "test_mean, test_var = group_by(test_keys, test_embeddings)\n",
    "test_mean.shape, test_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30527f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 3), dtype=float64, numpy=\n",
       " array([[0.5, 0.5, 0. ],\n",
       "        [0.5, 0.5, 0. ],\n",
       "        [0. , 0. , 1. ]])>,\n",
       " <tf.Tensor: shape=(3, 3), dtype=float64, numpy=\n",
       " array([[0.25, 0.25, 0.  ],\n",
       "        [0.25, 0.25, 0.  ],\n",
       "        [0.  , 0.  , 0.  ]])>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or more direct example of group by\n",
    "import numpy as np\n",
    "group_by([0, 0, 1], np.eye(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43411cf",
   "metadata": {},
   "source": [
    "#### Compression of user features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1af9d9f",
   "metadata": {},
   "source": [
    "For optimisation of calculation of interaction we want to reduce number of user features we use. For that we will generate meta features using a sequence of fully connected layers based on `tf.keras.layers.experimental.EinsumDense` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d1267",
   "metadata": {},
   "source": [
    "<img src=\"resources/user_features_compression.png\" alt=\"compression of user features\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98942bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 2, 7])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from layers import UserFeaturesCompressor\n",
    "test_user_compressor = UserFeaturesCompressor(number_of_meta_features=2,\n",
    "                                              dropout_rate=0.1,\n",
    "                                              name='test_user_compressor')\n",
    "test_user_compressor(tf.random.normal((10, 3, 7))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668ff767",
   "metadata": {},
   "source": [
    "#### Compression of offer features and MaskNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c62da",
   "metadata": {},
   "source": [
    "This is a key layer that will create some meta offer features and apply instance guided mask over embedding dimension. For meta features, the idea is similar to user side: we want to get smaller number of features before interaction, but here using information about variance we can completely deactivate some features, depending on offer we want to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f39e8f",
   "metadata": {},
   "source": [
    "<img src=\"resources/offer_features_compression.png\" alt=\"compression of offer features\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd188a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 2, 7])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from layers import OfferFeaturesCompressor\n",
    "test_offer_compressor = OfferFeaturesCompressor(number_of_meta_features=2,\n",
    "                                                dropout_rate=0.1,\n",
    "                                                name='test_offer_compressor')\n",
    "test_offer_compressor([tf.random.normal((10, 3, 7)), tf.random.normal((10, 3, 7))]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8acd338e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 2, 7])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from layers import MaskNet\n",
    "test_mask = MaskNet(number_of_meta_features=2, dropout_rate=0.1)\n",
    "test_mask([tf.random.normal((10, 3, 7)), tf.random.normal((10, 3, 7))]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86ffb69",
   "metadata": {},
   "source": [
    "#### Bi-linear feature-wise interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cf6525",
   "metadata": {},
   "source": [
    "Last step is a calculation of interaction using bi-linear kernel for each pair of meta features from user and from offer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7522b5",
   "metadata": {},
   "source": [
    "<img src=\"resources/bi_linear_interaction.png\" alt=\"bi-linear feature wise interaction\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127052be-6506-4507-83a3-d526c617c02c",
   "metadata": {},
   "source": [
    "We also incorporate mini-batch generation of negative examples inside this layer in the similar way described in [the training of a simple model](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/training/movielens%20simple%20model.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2202cde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 12])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from layers import BiLinearInteraction\n",
    "test_interaction = BiLinearInteraction(number_of_negatives=3, dropout_rate=0., name='test_interaction')\n",
    "test_interaction([tf.random.normal((10, 4, 7)), tf.random.normal((10, 3, 5))], generate_negatives=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41ea0f44-0144-4079-84c1-6d03464a99c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([48, 12])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_interaction([tf.random.normal((12, 4, 7)), tf.random.normal((12, 3, 5))], generate_negatives=True).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e4c620",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357fd6b2",
   "metadata": {},
   "source": [
    "Now we can assemble all these layers into final model. Note that offer compression weights and interaction kernels are shared between different augmentations we generate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e60cfa",
   "metadata": {},
   "source": [
    "<img src=\"resources/group_by_augmentations_model.png\" alt=\"model\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b8378e",
   "metadata": {},
   "source": [
    "### Model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73764c02",
   "metadata": {},
   "source": [
    "For model's regularization we used a combination of several strategies:\n",
    "* `weight_decay` in the optimizer (for L2-penalty)\n",
    "* explicit L1-penalty on embedding layers\n",
    "* dropouts in fully-connected layers (after interaction, inside compression)\n",
    "\n",
    "We use `AdamW` optimizer and `BCE` loss, but in some cases it maybe be interesting to use [`FocalLoss`](https://www.tensorflow.org/addons/api_docs/python/tfa/losses/SigmoidFocalCrossEntropy) (with $\\gamma=1.5~…~2.5$) that automatically will concentrate on harder examples.\n",
    "\n",
    "There are some model parameters that can be changed (and tuned), during experimentations we found some typical values for those parameters:\n",
    "\n",
    "| parameter                                    | description                     | typical values | comment                                                                                                   |\n",
    "|----------------------------------------------|---------------------------------|----------------|-----------------------------------------------------------------------------------------------------------|\n",
    "| batch size, set above                        | batch size                                       | 5k … 20k       | it should not be too low if we want to have on-the-fly group-by                                      |\n",
    "| learning rate inside `OPTIMIZER`             | learning rate                                    | 0.001 … 0.005 | usually we set it as a half of the learning rate used in standard training                                               |\n",
    "| `USER_META_FEATURES`, `OFFER_META_FEATURES`  | compression meta dimension                       | 2 … 6         | prefer bigger values for larger number of offer features and complex (non-hierarchical) feature structure|\n",
    "| `NB_AUGMENTATIONS`                           | number of augmentations per step                 | 3 … 10        | bigger for larger number of offer features                                                               |\n",
    "| `AVERAGE_NUMBER_OF_FEATURES_IN_AUGMENTATION` | how many offer features used for group by key    | 1.5 … 3       | bigger for larger number of offer features                                                               |\n",
    "| `EPOCHS`                                     | number of epochs                                 | 2 … 50         | we need to double or triple number of epochs compared to std training                                      |\n",
    "| `EMBEDDING_DIM`                              | embedding latent dimensions                      | 15 … 60        | usually depends on the data amount and features modularity                                             |\n",
    "| `NUMBER_OF_NEGATIVES`                        | number of negatives examples                     | 3 … 10       | bigger number of negative examples may create some collisions for higher level offers                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1cf92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 30\n",
    "L1_COEFF = 1e-6\n",
    "DROPOUT = 0.05\n",
    "\n",
    "NB_AUGMENTATIONS = 3\n",
    "AVERAGE_NUMBER_OF_FEATURES_IN_AUGMENTATION = 2\n",
    "USER_META_FEATURES = 5\n",
    "OFFER_META_FEATURES = 3\n",
    "\n",
    "def REGULARIZER():\n",
    "    return {'class_name': 'L1L2', 'config': {'l1': L1_COEFF, 'l2': 0.}}\n",
    "\n",
    "def OUTPUT_DNN():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(30,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Activation('gelu'),\n",
    "        tf.keras.layers.Dense(20,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Activation('gelu'),\n",
    "        tf.keras.layers.Dense(1,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "    ], name='output_dnn')\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "NUMBER_OF_NEGATIVES = 4\n",
    "LOSS = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "AUC_METRIC = tf.keras.metrics.AUC(from_logits=True)\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "OPTIMIZER = tfa.optimizers.AdamW(weight_decay=1e-8, learning_rate=0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f94016",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b103374",
   "metadata": {},
   "source": [
    "We will define embeddings with the same `WeightedEmbeddings` layer described in [the training of a simple model](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/training/movielens%20simple%20model.ipynb) with one addition:\n",
    "* for offer features when aggregating a list of embedding vectors, we will also calculate variance and not only mean vector\n",
    "\n",
    "It is easy to do in the same sparse-dense matrix multiplication operation as mean calculation (we get second moment and then calculate variance from it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca4935ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import get_input_layer, WeightedEmbeddings\n",
    "from utils import WEIGHT_SUFFIX\n",
    "\n",
    "inputs = {}\n",
    "embedded_user_features, embedded_offer_features, variance_offer_features = {}, {}, {}\n",
    "for feature in user_features:\n",
    "    inputs[feature] = get_input_layer(feature)\n",
    "    emb_layer = WeightedEmbeddings(vocabulary_sizes[feature],\n",
    "                                   EMBEDDING_DIM, name=f'{feature}_embedding',\n",
    "                                   embeddings_regularizer=REGULARIZER())\n",
    "    embedded_user_features[feature] = emb_layer(inputs[feature])\n",
    "for feature in offer_features:\n",
    "    # for offer features we need weights:\n",
    "    # with dummy weights during training, and the ones used for a feature's averaging at inference time\n",
    "    inputs[f'{feature}_weight'] = get_input_layer(f'{feature}_weight', tf.float32)\n",
    "    inputs[feature] = get_input_layer(feature)\n",
    "    emb_layer = WeightedEmbeddings(vocabulary_sizes[feature],\n",
    "                                   EMBEDDING_DIM, name=f'{feature}_embedding',\n",
    "                                   embeddings_regularizer=REGULARIZER(),\n",
    "                                   calculate_variance=True)\n",
    "    embedded_offer_features[feature], variance_offer_features[feature] =\\\n",
    "        emb_layer(inputs[feature], inputs[f'{feature}_weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f442c975",
   "metadata": {},
   "source": [
    "### Combining everything into model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4753b65",
   "metadata": {},
   "source": [
    "Now we can define described model architecture on the top of embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48eb9977",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stacked = tf.stack(list(embedded_user_features.values()), axis=1)\n",
    "offer_stacked = tf.stack(list(embedded_offer_features.values()), axis=1)\n",
    "offer_variance = tf.stack(list(variance_offer_features.values()), axis=1)\n",
    "stacked_raw_offer_attrs = tf.stack([tf.cast(inp.values, tf.int32) for feature, inp in inputs.items()\n",
    "                                    if feature in offer_features], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7215846-24b0-4795-8db1-2ddad5d008c5",
   "metadata": {},
   "source": [
    "Note that we added an intermediate tensor where we stacked all raw offer features - it will be used in `KeyGenerator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea47cb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 7) dtype=int32 (created by layer 'tf.stack_3')>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_raw_offer_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01bc2e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_generator = KeyGenerator(number_of_offer_attributes=len(offer_features),\n",
    "                             average_number_of_attributes_in_key=AVERAGE_NUMBER_OF_FEATURES_IN_AUGMENTATION,\n",
    "                             name='grp_key_generator')\n",
    "\n",
    "user_compressed = UserFeaturesCompressor(USER_META_FEATURES, DROPOUT,\n",
    "                                         name='user_compressor')(user_stacked)\n",
    "offer_features_compressor = OfferFeaturesCompressor(OFFER_META_FEATURES, DROPOUT, name='offer_compressor')\n",
    "mask_net = MaskNet(OFFER_META_FEATURES, DROPOUT, name='mask_generation')\n",
    "apply_mask = tf.keras.layers.Multiply(name='apply_mask')\n",
    "bi_linear_interaction = BiLinearInteraction(number_of_negatives=NUMBER_OF_NEGATIVES, dropout_rate=DROPOUT,\n",
    "                                            initializer='random_normal', regularizer=REGULARIZER(),\n",
    "                                            name='interaction')\n",
    "output_dnn = OUTPUT_DNN()\n",
    "\n",
    "augmentation_predictions = []\n",
    "for i in range(NB_AUGMENTATIONS):\n",
    "    group_by_key = key_generator(stacked_raw_offer_attrs)\n",
    "    mean_offer_emb, variance_offer_emb = group_by(group_by_key, offer_stacked)\n",
    "    compressed_offer_embeddings = offer_features_compressor([mean_offer_emb, variance_offer_emb])\n",
    "    mask = mask_net([mean_offer_emb, variance_offer_emb])\n",
    "    masked_offer_embeddings = apply_mask([compressed_offer_embeddings, mask])\n",
    "    _output = output_dnn(bi_linear_interaction([user_compressed, masked_offer_embeddings], generate_negatives=True))\n",
    "    augmentation_predictions.append(_output)\n",
    "output = tf.concat(augmentation_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ded15-9fdc-457e-aeb7-64cc80958780",
   "metadata": {},
   "source": [
    "And for evaluation we don't need to create augmentations, we need just to take offer features' mean and variance coming from inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9c050d2-9ca3-40fe-858c-2a6ba2780b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_offer_embeddings = offer_features_compressor([offer_stacked, offer_variance])\n",
    "mask = mask_net([offer_stacked, offer_variance])\n",
    "masked_offer_embeddings = apply_mask([compressed_offer_embeddings, mask])\n",
    "\n",
    "eval_output = output_dnn(bi_linear_interaction([user_compressed, masked_offer_embeddings], generate_negatives=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2cc3833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import BroadcastLoss, BroadcastMetric\n",
    "\n",
    "model = tf.keras.Model(inputs, output, name='group_by_augmentations')\n",
    "model.compile(optimizer=OPTIMIZER,\n",
    "              loss=BroadcastLoss(LOSS, NUMBER_OF_NEGATIVES),\n",
    "              metrics=[BroadcastMetric(AUC_METRIC, NUMBER_OF_NEGATIVES)])\n",
    "\n",
    "eval_model = tf.keras.Model(inputs, eval_output, name='group_by_augmentations_eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b3f9fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, to_file=f'models/{DATASET}_group_by_augmentations.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e81c8b1",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c5fe7ce-8649-498b-ad36-d05e652a1d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/group_by_augmentations/group_by/moments_2/Reshape_4:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/group_by_augmentations/group_by/moments_2/Reshape_3:0\", shape=(None, 7, 30), dtype=float32), dense_shape=Tensor(\"gradient_tape/group_by_augmentations/group_by/moments_2/Cast:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/group_by_augmentations/group_by/moments_1/Reshape_4:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/group_by_augmentations/group_by/moments_1/Reshape_3:0\", shape=(None, 7, 30), dtype=float32), dense_shape=Tensor(\"gradient_tape/group_by_augmentations/group_by/moments_1/Cast:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/group_by_augmentations/group_by/moments/Reshape_4:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/group_by_augmentations/group_by/moments/Reshape_3:0\", shape=(None, 7, 30), dtype=float32), dense_shape=Tensor(\"gradient_tape/group_by_augmentations/group_by/moments/Cast:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"AdamW/gradients/concat_1:0\", shape=(None,), dtype=int32), values=Tensor(\"AdamW/gradients/concat:0\", shape=(None, 7, 30), dtype=float32), dense_shape=Tensor(\"gradient_tape/group_by_augmentations/group_by/SegmentStack_2/Cast:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 180s 578ms/step - loss: 0.5129 - auc: 0.5413 - val_loss: 0.4981 - val_auc: 0.5802\n",
      "Epoch 2/10\n",
      "231/231 [==============================] - 127s 526ms/step - loss: 0.4943 - auc: 0.5943 - val_loss: 0.4970 - val_auc: 0.5833\n",
      "Epoch 3/10\n",
      "231/231 [==============================] - 117s 478ms/step - loss: 0.4911 - auc: 0.6100 - val_loss: 0.4945 - val_auc: 0.5997\n",
      "Epoch 4/10\n",
      "231/231 [==============================] - 114s 471ms/step - loss: 0.4901 - auc: 0.6143 - val_loss: 0.4954 - val_auc: 0.5911\n",
      "Epoch 5/10\n",
      "231/231 [==============================] - 116s 475ms/step - loss: 0.4894 - auc: 0.6169 - val_loss: 0.4944 - val_auc: 0.5994\n",
      "Epoch 6/10\n",
      "231/231 [==============================] - 113s 465ms/step - loss: 0.4889 - auc: 0.6188 - val_loss: 0.4926 - val_auc: 0.6075\n",
      "Epoch 7/10\n",
      "231/231 [==============================] - 113s 461ms/step - loss: 0.4885 - auc: 0.6199 - val_loss: 0.4927 - val_auc: 0.6057\n",
      "Epoch 8/10\n",
      "231/231 [==============================] - 104s 425ms/step - loss: 0.4889 - auc: 0.6174 - val_loss: 0.4957 - val_auc: 0.5927\n",
      "Epoch 9/10\n",
      "231/231 [==============================] - 110s 452ms/step - loss: 0.4881 - auc: 0.6210 - val_loss: 0.4957 - val_auc: 0.5913\n",
      "Epoch 10/10\n",
      "231/231 [==============================] - 113s 460ms/step - loss: 0.4882 - auc: 0.6209 - val_loss: 0.4967 - val_auc: 0.5809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f88dc7f40a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datasets['train'], epochs=EPOCHS, validation_data=datasets['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27080ac6-2c87-49b0-b942-7c9bc02c29a0",
   "metadata": {},
   "source": [
    "## Single task models benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb00e26-0475-459a-9973-5aeb2fc8faf3",
   "metadata": {},
   "source": [
    "Using same approach as in [the simple model notebook](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/training/rees%20simple%20model.ipynb) we will look at performance gap between the model with group by augmentations against set of models specialized on tasks corresponding to one offer feature at time. We won't use augmentations in those baseline models, because they will be already aligned with offer we will use in evaluation afterwards. To illustrate importance of augmentations we will also train single model without group_by augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "373994d8-b6ec-4d7c-b878-b8c1f7bc58bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# offer columns we want to evaluate, specific to dataset we test\n",
    "TASKS = ['imdbId', 'director', 'genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2170ef73-1e06-4dda-9463-be8c1e71a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_linear_interaction_model(offer_features, name='bi_linear_model'):\n",
    "    # user_features, vocabulary_sizes, EMBEDDING_DIM, REGULARIZER, OPTIMIZER,\n",
    "    # OUTPUT_DNN, LOSS, NUMBER_OF_NEGATIVES\n",
    "    # come from global scope, but can be passed as params instead\n",
    "    inputs = {}\n",
    "    embedded_user_features, embedded_offer_features = {}, {}\n",
    "    for feature in user_features:\n",
    "        inputs[feature] = get_input_layer(feature)\n",
    "        emb_layer = WeightedEmbeddings(vocabulary_sizes[feature],\n",
    "                                       EMBEDDING_DIM, name=f'{feature}_embedding',\n",
    "                                       embeddings_regularizer=REGULARIZER())\n",
    "        embedded_user_features[feature] = emb_layer(inputs[feature])\n",
    "\n",
    "    # for offer feature we need weights:\n",
    "    # with dummy weights during training, and the ones used for a feature's averaging at inference time\n",
    "    for feature in offer_features:\n",
    "        inputs[feature] = get_input_layer(feature)\n",
    "        inputs[f'{feature}_weight'] = get_input_layer(f'{feature}_weight', tf.float32)\n",
    "        emb_layer = WeightedEmbeddings(vocabulary_sizes[feature],\n",
    "                                       EMBEDDING_DIM, name=f'{feature}_embedding',\n",
    "                                       embeddings_regularizer=REGULARIZER())\n",
    "        embedded_offer_features[feature] = emb_layer(inputs[feature], inputs[f'{feature}_weight'])\n",
    "    \n",
    "    user_stacked = tf.stack(list(embedded_user_features.values()), axis=1)\n",
    "    offer_stacked = tf.stack(list(embedded_offer_features.values()), axis=1)\n",
    "    \n",
    "    user_compressed = UserFeaturesCompressor(USER_META_FEATURES, DROPOUT,\n",
    "                                             name='user_compressor')(user_stacked)\n",
    "    \n",
    "    output_dnn = OUTPUT_DNN()\n",
    "    bi_linear_interaction = BiLinearInteraction(number_of_negatives=NUMBER_OF_NEGATIVES, dropout_rate=DROPOUT,\n",
    "                                                initializer='random_normal', regularizer=REGULARIZER(),\n",
    "                                                name='interaction')\n",
    "    \n",
    "    output = output_dnn(bi_linear_interaction([user_compressed, offer_stacked], generate_negatives=True))\n",
    "\n",
    "    model = tf.keras.Model(inputs, output, name=name)\n",
    "    model.compile(optimizer=OPTIMIZER,\n",
    "                  loss=BroadcastLoss(LOSS, NUMBER_OF_NEGATIVES),\n",
    "                  metrics=[BroadcastMetric(AUC_METRIC, NUMBER_OF_NEGATIVES)])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33553765-ab1f-4240-aa02-3b1814f79d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "231/231 [==============================] - 131s 411ms/step - loss: 0.5000 - auc: 0.6029 - val_loss: 0.4965 - val_auc: 0.6268\n",
      "Epoch 2/10\n",
      "231/231 [==============================] - 89s 360ms/step - loss: 0.4842 - auc: 0.6564 - val_loss: 0.4901 - val_auc: 0.6417\n",
      "Epoch 3/10\n",
      "231/231 [==============================] - 96s 387ms/step - loss: 0.4800 - auc: 0.6669 - val_loss: 0.4874 - val_auc: 0.6466\n",
      "Epoch 4/10\n",
      "231/231 [==============================] - 91s 364ms/step - loss: 0.4777 - auc: 0.6718 - val_loss: 0.4864 - val_auc: 0.6487\n",
      "Epoch 5/10\n",
      "231/231 [==============================] - 92s 373ms/step - loss: 0.4762 - auc: 0.6747 - val_loss: 0.4855 - val_auc: 0.6504\n",
      "Epoch 6/10\n",
      "231/231 [==============================] - 86s 347ms/step - loss: 0.4750 - auc: 0.6769 - val_loss: 0.4850 - val_auc: 0.6516\n",
      "Epoch 7/10\n",
      "231/231 [==============================] - 86s 343ms/step - loss: 0.4743 - auc: 0.6786 - val_loss: 0.4846 - val_auc: 0.6519\n",
      "Epoch 8/10\n",
      "231/231 [==============================] - 87s 346ms/step - loss: 0.4735 - auc: 0.6804 - val_loss: 0.4843 - val_auc: 0.6534\n",
      "Epoch 9/10\n",
      "231/231 [==============================] - 85s 344ms/step - loss: 0.4731 - auc: 0.6816 - val_loss: 0.4839 - val_auc: 0.6539\n",
      "Epoch 10/10\n",
      "231/231 [==============================] - 87s 350ms/step - loss: 0.4727 - auc: 0.6827 - val_loss: 0.4840 - val_auc: 0.6542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8a3b9046d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wo_augmentations = bi_linear_interaction_model(offer_features, name='model_wo_augm')\n",
    "model_wo_augmentations.fit(datasets['train'], epochs=EPOCHS, validation_data=datasets['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34c6b37f-b971-41b6-bc36-e60974bcdb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['actor', 'date', 'runtimeMinutesCluster', 'userId', 'titleType', 'genre', 'director', 'startYearCluster', 'actor_weight', 'runtimeMinutesCluster_weight', 'titleType_weight', 'genre_weight', 'director_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 101s 332ms/step - loss: 0.5019 - auc: 0.5985 - val_loss: 0.4953 - val_auc: 0.6112\n",
      "Epoch 2/10\n",
      "231/231 [==============================] - 73s 295ms/step - loss: 0.4872 - auc: 0.6417 - val_loss: 0.4908 - val_auc: 0.6305\n",
      "Epoch 3/10\n",
      "231/231 [==============================] - 75s 303ms/step - loss: 0.4825 - auc: 0.6571 - val_loss: 0.4882 - val_auc: 0.6394\n",
      "Epoch 4/10\n",
      "231/231 [==============================] - 76s 302ms/step - loss: 0.4798 - auc: 0.6644 - val_loss: 0.4870 - val_auc: 0.6432\n",
      "Epoch 5/10\n",
      "231/231 [==============================] - 78s 309ms/step - loss: 0.4780 - auc: 0.6688 - val_loss: 0.4861 - val_auc: 0.6465\n",
      "Epoch 6/10\n",
      "231/231 [==============================] - 75s 302ms/step - loss: 0.4768 - auc: 0.6714 - val_loss: 0.4861 - val_auc: 0.6472\n",
      "Epoch 7/10\n",
      "231/231 [==============================] - 76s 303ms/step - loss: 0.4760 - auc: 0.6732 - val_loss: 0.4854 - val_auc: 0.6480\n",
      "Epoch 8/10\n",
      "231/231 [==============================] - 76s 303ms/step - loss: 0.4754 - auc: 0.6747 - val_loss: 0.4852 - val_auc: 0.6489\n",
      "Epoch 9/10\n",
      "231/231 [==============================] - 75s 299ms/step - loss: 0.4748 - auc: 0.6761 - val_loss: 0.4851 - val_auc: 0.6499\n",
      "Epoch 10/10\n",
      "231/231 [==============================] - 65s 259ms/step - loss: 0.4743 - auc: 0.6773 - val_loss: 0.4848 - val_auc: 0.6510\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['imdbId', 'actor', 'date', 'runtimeMinutesCluster', 'userId', 'titleType', 'genre', 'startYearCluster', 'imdbId_weight', 'actor_weight', 'runtimeMinutesCluster_weight', 'titleType_weight', 'genre_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 87s 296ms/step - loss: 0.5013 - auc: 0.5772 - val_loss: 0.4964 - val_auc: 0.5940\n",
      "Epoch 2/10\n",
      "231/231 [==============================] - 66s 263ms/step - loss: 0.4901 - auc: 0.6170 - val_loss: 0.4924 - val_auc: 0.6103\n",
      "Epoch 3/10\n",
      "231/231 [==============================] - 68s 271ms/step - loss: 0.4867 - auc: 0.6306 - val_loss: 0.4908 - val_auc: 0.6159\n",
      "Epoch 4/10\n",
      "231/231 [==============================] - 69s 274ms/step - loss: 0.4849 - auc: 0.6357 - val_loss: 0.4902 - val_auc: 0.6191\n",
      "Epoch 5/10\n",
      "231/231 [==============================] - 62s 248ms/step - loss: 0.4838 - auc: 0.6389 - val_loss: 0.4892 - val_auc: 0.6208\n",
      "Epoch 6/10\n",
      "231/231 [==============================] - 61s 242ms/step - loss: 0.4830 - auc: 0.6408 - val_loss: 0.4893 - val_auc: 0.6217\n",
      "Epoch 7/10\n",
      "231/231 [==============================] - 61s 242ms/step - loss: 0.4825 - auc: 0.6421 - val_loss: 0.4887 - val_auc: 0.6220\n",
      "Epoch 8/10\n",
      "231/231 [==============================] - 61s 241ms/step - loss: 0.4821 - auc: 0.6433 - val_loss: 0.4893 - val_auc: 0.6227\n",
      "Epoch 9/10\n",
      "231/231 [==============================] - 61s 242ms/step - loss: 0.4818 - auc: 0.6440 - val_loss: 0.4890 - val_auc: 0.6227\n",
      "Epoch 10/10\n",
      "231/231 [==============================] - 62s 245ms/step - loss: 0.4814 - auc: 0.6451 - val_loss: 0.4888 - val_auc: 0.6234\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['imdbId', 'actor', 'date', 'runtimeMinutesCluster', 'userId', 'titleType', 'director', 'startYearCluster', 'imdbId_weight', 'actor_weight', 'runtimeMinutesCluster_weight', 'titleType_weight', 'director_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 83s 272ms/step - loss: 0.5062 - auc: 0.5174 - val_loss: 0.5011 - val_auc: 0.5126\n",
      "Epoch 2/10\n",
      "231/231 [==============================] - 60s 237ms/step - loss: 0.5005 - auc: 0.5265 - val_loss: 0.5000 - val_auc: 0.5350\n",
      "Epoch 3/10\n",
      "231/231 [==============================] - 61s 239ms/step - loss: 0.4995 - auc: 0.5421 - val_loss: 0.4995 - val_auc: 0.5422\n",
      "Epoch 4/10\n",
      "231/231 [==============================] - 62s 244ms/step - loss: 0.4989 - auc: 0.5473 - val_loss: 0.4993 - val_auc: 0.5439\n",
      "Epoch 5/10\n",
      "231/231 [==============================] - 62s 245ms/step - loss: 0.4984 - auc: 0.5509 - val_loss: 0.4990 - val_auc: 0.5465\n",
      "Epoch 6/10\n",
      "231/231 [==============================] - 61s 242ms/step - loss: 0.4982 - auc: 0.5528 - val_loss: 0.4990 - val_auc: 0.5476\n",
      "Epoch 7/10\n",
      "231/231 [==============================] - 61s 244ms/step - loss: 0.4980 - auc: 0.5541 - val_loss: 0.4990 - val_auc: 0.5473\n",
      "Epoch 8/10\n",
      "231/231 [==============================] - 62s 248ms/step - loss: 0.4979 - auc: 0.5549 - val_loss: 0.4989 - val_auc: 0.5483\n",
      "Epoch 9/10\n",
      "231/231 [==============================] - 60s 240ms/step - loss: 0.4978 - auc: 0.5557 - val_loss: 0.4990 - val_auc: 0.5488\n",
      "Epoch 10/10\n",
      "231/231 [==============================] - 60s 239ms/step - loss: 0.4977 - auc: 0.5561 - val_loss: 0.4988 - val_auc: 0.5488\n"
     ]
    }
   ],
   "source": [
    "mono_feature_models = {}\n",
    "for task_offer_feature in TASKS:\n",
    "    mono_feature_models[task_offer_feature] =\\\n",
    "        bi_linear_interaction_model([task_offer_feature], name=f'{task_offer_feature}_model')\n",
    "    mono_feature_models[task_offer_feature].fit(datasets['train'],\n",
    "                                                epochs=EPOCHS,\n",
    "                                                validation_data=datasets['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cc7d11-391a-4466-9bb5-bf9f2bbcc203",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb861dcc-1c7c-4a3e-be52-864c97543ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 26s, sys: 6.31 s, total: 1min 33s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from utils import prepare_single_task_dataset\n",
    "test_datasets = {}\n",
    "for task_offer_feature in TASKS:\n",
    "    test_datasets[task_offer_feature] = \\\n",
    "        prepare_single_task_dataset(datasets['test'], task_offer_feature, offer_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "644699ac-98a0-496d-8a76-afb73852bc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['actor', 'date', 'runtimeMinutesCluster', 'userId', 'titleType', 'genre', 'director', 'startYearCluster', 'actor_weight', 'runtimeMinutesCluster_weight', 'titleType_weight', 'genre_weight', 'director_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['imdbId', 'actor', 'date', 'runtimeMinutesCluster', 'userId', 'titleType', 'genre', 'startYearCluster', 'imdbId_weight', 'actor_weight', 'runtimeMinutesCluster_weight', 'titleType_weight', 'genre_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['imdbId', 'actor', 'date', 'runtimeMinutesCluster', 'userId', 'titleType', 'director', 'startYearCluster', 'imdbId_weight', 'actor_weight', 'runtimeMinutesCluster_weight', 'titleType_weight', 'director_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['actor', 'date', 'runtimeMinutesCluster', 'userId', 'titleType', 'genre', 'director', 'startYearCluster', 'actor_weight', 'runtimeMinutesCluster_weight', 'titleType_weight', 'genre_weight', 'director_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['imdbId', 'actor', 'date', 'runtimeMinutesCluster', 'userId', 'titleType', 'genre', 'startYearCluster', 'imdbId_weight', 'actor_weight', 'runtimeMinutesCluster_weight', 'titleType_weight', 'genre_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['imdbId', 'actor', 'date', 'runtimeMinutesCluster', 'userId', 'titleType', 'director', 'startYearCluster', 'imdbId_weight', 'actor_weight', 'runtimeMinutesCluster_weight', 'titleType_weight', 'director_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['actor', 'date', 'runtimeMinutesCluster', 'userId', 'titleType', 'genre', 'director', 'startYearCluster', 'actor_weight', 'runtimeMinutesCluster_weight', 'titleType_weight', 'genre_weight', 'director_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['imdbId', 'actor', 'date', 'runtimeMinutesCluster', 'userId', 'titleType', 'genre', 'startYearCluster', 'imdbId_weight', 'actor_weight', 'runtimeMinutesCluster_weight', 'titleType_weight', 'genre_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['imdbId', 'actor', 'date', 'runtimeMinutesCluster', 'userId', 'titleType', 'director', 'startYearCluster', 'imdbId_weight', 'actor_weight', 'runtimeMinutesCluster_weight', 'titleType_weight', 'director_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 54s, sys: 2min 19s, total: 21min 13s\n",
      "Wall time: 4min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "from utils import evaluate_model\n",
    "\n",
    "aucs = defaultdict(dict)\n",
    "for task_offer_feature in TASKS:\n",
    "    kw = {'single_task_feature': task_offer_feature, 'test_datasets': test_datasets,\n",
    "          'number_of_negatives': NUMBER_OF_NEGATIVES, 'inverse_lookups': inverse_lookups}\n",
    "    \n",
    "    aucs[task_offer_feature]['group_by augmentations'] = evaluate_model(eval_model, **kw)\n",
    "    aucs[task_offer_feature]['without augmentations'] = evaluate_model(model_wo_augmentations, **kw)\n",
    "    \n",
    "    for model_name in TASKS:\n",
    "        aucs[task_offer_feature][f'MONO:{model_name}'] = evaluate_model(mono_feature_models[model_name], **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1b891e9-e60e-4578-9bbb-8d7bf0aaa7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_metrics\n",
    "save_metrics(aucs, DATASET, 'group_by_augmentations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b549c-6a9e-4233-b52c-2db953c99e07",
   "metadata": {},
   "source": [
    "## Aggregating results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46292f1f-5f4c-43ca-bd45-e9b6a2250e7c",
   "metadata": {},
   "source": [
    "### Popular offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f862e7c9-c599-408c-8572-d2f924a36806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import wAUC\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for task_name in aucs:\n",
    "    for model_name in aucs[task_name]:\n",
    "        w_auc = wAUC(aucs[task_name][model_name], cutoff_low=200)\n",
    "        results = pd.concat([results,\n",
    "                             pd.Series({'wAUC': w_auc, 'offers': task_name, 'model': model_name}).to_frame().T],\n",
    "                            ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec9ac730-c8f3-4a95-8102-a2551742f98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_67283_row0_col0 {\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_67283_row0_col1, #T_67283_row2_col0, #T_67283_row3_col1, #T_67283_row4_col2 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_67283_row0_col2 {\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_67283_row1_col0 {\n",
       "  background-color: #b8122a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_67283_row1_col1 {\n",
       "  background-color: #b50927;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_67283_row1_col2 {\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_67283_row2_col1 {\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_67283_row2_col2, #T_67283_row4_col0, #T_67283_row4_col1 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_67283_row3_col0 {\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_67283_row3_col2 {\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_67283_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >offers</th>\n",
       "      <th class=\"col_heading level0 col0\" >film</th>\n",
       "      <th class=\"col_heading level0 col1\" >director</th>\n",
       "      <th class=\"col_heading level0 col2\" >genre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_67283_level0_row0\" class=\"row_heading level0 row0\" >group_by augmentations</th>\n",
       "      <td id=\"T_67283_row0_col0\" class=\"data row0 col0\" >0.607</td>\n",
       "      <td id=\"T_67283_row0_col1\" class=\"data row0 col1\" >0.593</td>\n",
       "      <td id=\"T_67283_row0_col2\" class=\"data row0 col2\" >0.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67283_level0_row1\" class=\"row_heading level0 row1\" >without augmentations</th>\n",
       "      <td id=\"T_67283_row1_col0\" class=\"data row1 col0\" >0.610</td>\n",
       "      <td id=\"T_67283_row1_col1\" class=\"data row1 col1\" >0.592</td>\n",
       "      <td id=\"T_67283_row1_col2\" class=\"data row1 col2\" >0.541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67283_level0_row2\" class=\"row_heading level0 row2\" >MONO:film</th>\n",
       "      <td id=\"T_67283_row2_col0\" class=\"data row2 col0\" >0.612</td>\n",
       "      <td id=\"T_67283_row2_col1\" class=\"data row2 col1\" >0.591</td>\n",
       "      <td id=\"T_67283_row2_col2\" class=\"data row2 col2\" >0.536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67283_level0_row3\" class=\"row_heading level0 row3\" >MONO:director</th>\n",
       "      <td id=\"T_67283_row3_col0\" class=\"data row3 col0\" >0.591</td>\n",
       "      <td id=\"T_67283_row3_col1\" class=\"data row3 col1\" >0.593</td>\n",
       "      <td id=\"T_67283_row3_col2\" class=\"data row3 col2\" >0.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67283_level0_row4\" class=\"row_heading level0 row4\" >MONO:genre</th>\n",
       "      <td id=\"T_67283_row4_col0\" class=\"data row4 col0\" >0.527</td>\n",
       "      <td id=\"T_67283_row4_col1\" class=\"data row4 col1\" >0.532</td>\n",
       "      <td id=\"T_67283_row4_col2\" class=\"data row4 col2\" >0.559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8a0ff36fd0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(results, 'wAUC', 'model', 'offers')\\\n",
    "    .rename(columns={'imdbId': 'film'}, index={'MONO:imdbId': 'MONO:film'})\\\n",
    "    .iloc[[3, 4, 2, 0, 1]][['film', 'director', 'genre']]\\\n",
    "    .style.background_gradient(cmap='coolwarm').format(precision=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom [moksha-tf2-cpu.2-7] (Local)",
   "language": "python",
   "name": "local-eu.gcr.io_tinyclues-experiments_tinyclues_moksha-tf2-cpu.2-7_latest__moksha"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
