{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edef15d4-49a3-40e3-82f1-2f1fd17c820d",
   "metadata": {},
   "source": [
    "# Training simple model and evalualing its predictions on different tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9113fe5b-43bd-4872-b416-86ef0ee54a02",
   "metadata": {},
   "source": [
    "## Prepare dataset for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac87ae1e-3893-4a7c-9bd7-5c84bbcc5259",
   "metadata": {},
   "source": [
    "Let's follow the same steps as in [the notebook for Movielens/IMDB dataset](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/training/movielens%20simple%20model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a30be-3b5c-4ab5-9b83-877fadbc4528",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'rees_ecommerce'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcb1cef-b1d7-4f13-8c07-68b7cfdc8bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from utils import load_dataset\n",
    "\n",
    "datasets = {}\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    datasets[split_name] = load_dataset(DATASET, split_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529c9be2-9c71-4bfc-ba64-931c0b4294ec",
   "metadata": {},
   "source": [
    "We can parse features' names, they were chosen to easily distinguish between offer features (that will be used to modelize film) and user features (aggregated history up to chosen date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bacd6ec-088e-43f7-8741-f817389aeaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import AGG_PREFIX\n",
    "\n",
    "all_columns = list(datasets['train'].element_spec.keys())\n",
    "technical_columns = ['user_id', 'date']\n",
    "user_features = list(filter(lambda x: x.startswith(AGG_PREFIX), all_columns))\n",
    "offer_features = list(filter(lambda x: x not in user_features + technical_columns, all_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749c7c8-ccce-4996-9dbb-ddd4b30535f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aggregated_cart_product_id',\n",
       " 'aggregated_purchase_brand',\n",
       " 'aggregated_cart_category3',\n",
       " 'aggregated_purchase_product_id',\n",
       " 'aggregated_cart_category2',\n",
       " 'aggregated_cart_brand',\n",
       " 'aggregated_purchase_category2',\n",
       " 'aggregated_purchase_category3',\n",
       " 'aggregated_cart_category1',\n",
       " 'aggregated_purchase_priceCluster',\n",
       " 'aggregated_cart_priceCluster',\n",
       " 'aggregated_purchase_category1']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc16225-1bf0-42cd-96cc-dde804d0f8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['priceCluster', 'category2', 'brand', 'category1', 'product_id', 'category3']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offer_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb38696-3ad7-4edc-9331-663f031c11a9",
   "metadata": {},
   "source": [
    "### Rebatch dataset by events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993d1d8c-60a7-4e91-8507-a4d63aafff4e",
   "metadata": {},
   "source": [
    "First we will unnest events for each user (stored in second dimension of saved tensors) and keep only limited number of them. This operation will be needed further to avoid collisions during generation of negative examples. Then we will rebatch results into smaller batches (`50400` events for validation and test sets and `10080` events for train set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea02c22b-3128-4312-ac7e-eba7ba312b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.1 s, sys: 732 ms, total: 30.9 s\n",
      "Wall time: 16.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from functools import partial\n",
    "from uuid import uuid4\n",
    "\n",
    "from utils import rebatch_by_events, add_equal_weights\n",
    "\n",
    "datasets['train'] = rebatch_by_events(datasets['train'], batch_size=5040, date_column='date', nb_events_by_user_by_day=8)\n",
    "for key in ['val', 'test']:\n",
    "    datasets[key] = rebatch_by_events(datasets[key], batch_size=5040, date_column='date', nb_events_by_user_by_day=8,\n",
    "                                      seed=1729).cache(f'/tmp/{uuid4()}.tf')\n",
    "\n",
    "for key in datasets:\n",
    "    datasets[key] = datasets[key].map(partial(add_equal_weights, features=offer_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6267056-b152-448e-a905-515cf6780d4f",
   "metadata": {},
   "source": [
    "## Define simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d690110-f133-4702-8533-8eb10e41b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_inverse_lookups\n",
    "inverse_lookups = load_inverse_lookups(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488d715b-2447-4235-93ee-4297dc5954a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "vocabulary_sizes = {}\n",
    "\n",
    "for feature in offer_features:\n",
    "    vocabulary_sizes[feature] = inverse_lookups[feature].vocabulary_size()\n",
    "\n",
    "for feature in user_features:\n",
    "    for key in inverse_lookups:\n",
    "        pattern = re.compile(r\"{}(\\w+)_{}\".format(AGG_PREFIX, key))\n",
    "        if pattern.match(feature):\n",
    "            vocabulary_sizes[feature] = vocabulary_sizes[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a273a2-67d6-4bae-9c3b-282b64346329",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692a7645-1ab1-441b-bb20-b4d2b0d42e20",
   "metadata": {},
   "source": [
    "<img src=\"resources/two_towers_model.png\" alt=\"two tower model\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f2bac6-852a-4c0a-ba11-e8984ae67ac9",
   "metadata": {},
   "source": [
    "### Model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028e0008-74ee-4c60-810c-39f4baa6c710",
   "metadata": {},
   "source": [
    "To choose model's parameters we did some manual tuning using validation set to maximize train and validation AUC while keeping mismatch between them small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a2a62-06e6-4758-94a5-5ba3ec5d4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "EMBEDDING_DIM = 100\n",
    "L1_COEFF = 4e-7\n",
    "DROPOUT = 0.1\n",
    "\n",
    "\n",
    "def REGULARIZER():\n",
    "    return {'class_name': 'L1L2', 'config': {'l1': L1_COEFF, 'l2': 0.}}\n",
    "\n",
    "def USER_TOWER():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(100,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Activation('tanh'),\n",
    "        tf.keras.layers.Dense(50,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Activation('tanh'),\n",
    "    ], name='user_tower')\n",
    "\n",
    "def OFFER_TOWER():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(100,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Activation('tanh'),\n",
    "        tf.keras.layers.Dense(50,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Activation('tanh'),\n",
    "    ], name='offer_tower')\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "NUMBER_OF_NEGATIVES = 4\n",
    "LOSS = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "AUC_METRIC = tf.keras.metrics.AUC(from_logits=True)\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "OPTIMIZER = tfa.optimizers.AdamW(weight_decay=4e-8, learning_rate=0.0009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07957c19-2b1b-457b-b17d-c9d21e37316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import get_input_layer, WeightedEmbeddings\n",
    "from utils import WEIGHT_SUFFIX\n",
    "\n",
    "embeddings, inputs = {}, {}\n",
    "for feature in user_features + offer_features:\n",
    "    if feature in offer_features:\n",
    "        # for offer features we need weights:\n",
    "        # with dummy weights during training, and the ones used for a feature's averaging at inference time\n",
    "        inputs[f'{feature}{WEIGHT_SUFFIX}'] = get_input_layer(f'{feature}{WEIGHT_SUFFIX}', tf.float32)\n",
    "    inputs[feature] = get_input_layer(feature)\n",
    "    # here we use input feature modality from `vocabulary_sizes` to know embeddings matrix dimensions\n",
    "    emb_layer = WeightedEmbeddings(vocabulary_sizes[feature],\n",
    "                                   EMBEDDING_DIM, name=f'{feature}_embedding',\n",
    "                                   embeddings_regularizer=REGULARIZER())\n",
    "    embeddings[feature] = emb_layer(inputs[feature], inputs.get(f'{feature}{WEIGHT_SUFFIX}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab9aa4-9e45-4cbb-a659-7d6688546d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_user_features = [embeddings[feature] for feature in user_features]\n",
    "embedded_offer_features = [embeddings[feature] for feature in offer_features]\n",
    "user_tower = USER_TOWER()(tf.keras.layers.Concatenate(name='concat_user')(embedded_user_features))\n",
    "offer_tower = OFFER_TOWER()(tf.keras.layers.Concatenate(name='concat_offer')(embedded_offer_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cee96b-5095-4635-863c-bb6be416a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import DotWithNegatives\n",
    "\n",
    "# we don't apply sigmoid on the output and will have from_logits=True in both loss and metrics\n",
    "output = DotWithNegatives(NUMBER_OF_NEGATIVES, name='prediction')([user_tower, offer_tower],\n",
    "                                                                  generate_negatives=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c2d19a-acd9-4fd8-9bcf-a9865f65bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import BroadcastLoss, BroadcastMetric\n",
    "\n",
    "model = tf.keras.Model(inputs, output, name='two_tower_model')\n",
    "model.compile(optimizer=OPTIMIZER,\n",
    "              loss=BroadcastLoss(LOSS, NUMBER_OF_NEGATIVES),\n",
    "              metrics=[BroadcastMetric(AUC_METRIC, NUMBER_OF_NEGATIVES)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237702cb-fa87-45dc-8966-020cf9bf2515",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3876f19-e017-405b-b6e0-be58b7d83cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "682/682 [==============================] - 199s 233ms/step - loss: 0.5017 - auc_4: 0.7053 - val_loss: 0.4541 - val_auc_4: 0.7542\n",
      "Epoch 2/10\n",
      "682/682 [==============================] - 132s 193ms/step - loss: 0.4469 - auc_4: 0.7439 - val_loss: 0.4324 - val_auc_4: 0.7604\n",
      "Epoch 3/10\n",
      "682/682 [==============================] - 132s 193ms/step - loss: 0.4391 - auc_4: 0.7505 - val_loss: 0.4302 - val_auc_4: 0.7620\n",
      "Epoch 4/10\n",
      "682/682 [==============================] - 138s 202ms/step - loss: 0.4365 - auc_4: 0.7535 - val_loss: 0.4290 - val_auc_4: 0.7630\n",
      "Epoch 5/10\n",
      "682/682 [==============================] - 134s 196ms/step - loss: 0.4355 - auc_4: 0.7550 - val_loss: 0.4288 - val_auc_4: 0.7639\n",
      "Epoch 6/10\n",
      "682/682 [==============================] - 134s 196ms/step - loss: 0.4345 - auc_4: 0.7567 - val_loss: 0.4288 - val_auc_4: 0.7639\n",
      "Epoch 7/10\n",
      "682/682 [==============================] - 134s 197ms/step - loss: 0.4337 - auc_4: 0.7578 - val_loss: 0.4290 - val_auc_4: 0.7644\n",
      "Epoch 8/10\n",
      "682/682 [==============================] - 136s 198ms/step - loss: 0.4328 - auc_4: 0.7591 - val_loss: 0.4282 - val_auc_4: 0.7647\n",
      "Epoch 9/10\n",
      "682/682 [==============================] - 133s 194ms/step - loss: 0.4320 - auc_4: 0.7604 - val_loss: 0.4283 - val_auc_4: 0.7649\n",
      "Epoch 10/10\n",
      "682/682 [==============================] - 131s 192ms/step - loss: 0.4311 - auc_4: 0.7617 - val_loss: 0.4292 - val_auc_4: 0.7645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faccd203ed0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datasets['train'], epochs=EPOCHS, validation_data=datasets['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7595399-bced-44ae-bbf6-05f2534141fd",
   "metadata": {},
   "source": [
    "## Single task models benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910110b3-f9b1-4663-80b9-d303ebc97359",
   "metadata": {},
   "source": [
    "As described in (TODO link to article) we can consider predictions on one chosen offer column as a single task and the whole setup as a multi-task problem. Let's now evaluate performance of a common model on a subset of tasks. We will compare its results against single task models sharing the same architecture, but using only one offer feature at time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6669fc5c-fa01-4e50-95e9-c4bbd66eb10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# offer columns we want to evaluate, specific to dataset we test\n",
    "TASKS = ['product_id', 'category1', 'category2', 'category3', 'brand', 'priceCluster']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05482dc-6ce3-47f0-8c5f-d9d25a0ecb3c",
   "metadata": {},
   "source": [
    "For simplicity of further code, let's wrap whole model definition into a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a45e96a-b5fe-4ad2-a20b-a3aad3773571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_tower_model(offer_features, name='two_tower_model'):\n",
    "    # user_features, vocabulary_sizes, EMBEDDING_DIM, REGULARIZER, USER_TOWER, OFFER_TOWER,\n",
    "    # OPTIMIZER, LOSS, NUMBER_OF_NEGATIVES\n",
    "    # come from global scope, but can be passed as params instead\n",
    "    embeddings, inputs = {}, {}\n",
    "    for feature in user_features + offer_features:\n",
    "        if feature in offer_features:\n",
    "            # for offer features we need weights:\n",
    "            # with dummy weights during training, and the ones used for a feature's averaging at inference time\n",
    "            inputs[f'{feature}{WEIGHT_SUFFIX}'] = get_input_layer(f'{feature}{WEIGHT_SUFFIX}', tf.float32)\n",
    "        inputs[feature] = get_input_layer(feature)\n",
    "        # here we use input feature modality from `vocabulary_sizes` to know embeddings matrix dimensions\n",
    "        emb_layer = WeightedEmbeddings(vocabulary_sizes[feature],\n",
    "                                       EMBEDDING_DIM, name=f'{feature}_embedding',\n",
    "                                       embeddings_regularizer=REGULARIZER())\n",
    "        embeddings[feature] = emb_layer(inputs[feature], inputs.get(f'{feature}{WEIGHT_SUFFIX}'))\n",
    "    \n",
    "    embedded_user_features = [embeddings[feature] for feature in user_features]\n",
    "    embedded_offer_features = [embeddings[feature] for feature in offer_features]\n",
    "    user_tower = USER_TOWER()(tf.keras.layers.Concatenate(name='concat_user')(embedded_user_features))\n",
    "    offer_tower = OFFER_TOWER()(tf.keras.layers.Concatenate(name='concat_offer')(embedded_offer_features))\n",
    "    \n",
    "    output = DotWithNegatives(NUMBER_OF_NEGATIVES, name='prediction')([user_tower, offer_tower], generate_negatives=True)\n",
    "    model = tf.keras.Model(inputs, output, name=name)\n",
    "    model.compile(optimizer=OPTIMIZER,\n",
    "                  loss=BroadcastLoss(LOSS, NUMBER_OF_NEGATIVES),\n",
    "                  metrics=[BroadcastMetric(AUC_METRIC, NUMBER_OF_NEGATIVES)])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191a9dca-20e1-4bda-9f32-0fe31f1cca5b",
   "metadata": {},
   "source": [
    "We train models that use only one offer feature with same hyperparameters as the initial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984349ef-6d9a-4e99-9711-5c0a33bc3a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['priceCluster', 'category1', 'category3', 'brand', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'brand_weight', 'category1_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     61/Unknown - 41s 153ms/step - loss: 0.6308 - auc_4: 0.7034"
     ]
    }
   ],
   "source": [
    "mono_feature_models = {}\n",
    "for task_offer_feature in TASKS:\n",
    "    mono_feature_models[task_offer_feature] = two_tower_model([task_offer_feature],\n",
    "                                                              name=f'{task_offer_feature}_model')\n",
    "    mono_feature_models[task_offer_feature].fit(datasets['train'],\n",
    "                                                epochs=EPOCHS,\n",
    "                                                validation_data=datasets['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e416a20a-7564-44a1-812d-6c9b1ca29b02",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95506c1c-1d7e-41b2-b4d9-7e46d9c59e79",
   "metadata": {},
   "source": [
    "Now let's load test dataset and generate some offers from it:\n",
    "* we will consider all batches from test dataset\n",
    "* we perform a group by using each feature from `TASKS` as a group by key\n",
    "* for all offer features except the one we are using as key we generate ragged tensors with bag of values it can take\n",
    "* we remove least popular values in each list\n",
    "* so now each line of dataset corresponds to an offer of type `task_offer_feature = 'value'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cf7c3c-cb90-486e-b321-7240451ea392",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_ds = load_dataset(DATASET, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa2ddd9-efcc-4d32-9ff7-81eb033a9faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 7s, sys: 29.2 s, total: 6min 36s\n",
      "Wall time: 5min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from utils import prepare_single_task_dataset\n",
    "test_datasets = {}\n",
    "for task_offer_feature in TASKS:\n",
    "    test_datasets[task_offer_feature] = \\\n",
    "        prepare_single_task_dataset(raw_test_ds, 5040, task_offer_feature, offer_features, 'date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb43883-2574-41a2-8b3f-287800b250aa",
   "metadata": {},
   "source": [
    "Now we can apply model on grouped features for each task and calculate AUC for each offer of type `task_offer_feature = 'value'`. Note, that negatives are generated in the same way as for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0966f43-5ea6-4291-9fc8-5b48375da541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category3', 'brand', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'brand_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category1', 'category3', 'brand', 'user_id', 'date', 'priceCluster_weight', 'brand_weight', 'category1_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category1', 'brand', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'brand_weight', 'category1_weight', 'product_id_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category1', 'category3', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'category1_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'category1', 'category3', 'brand', 'user_id', 'date', 'category2', 'category2_weight', 'brand_weight', 'category1_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['user_id', 'date'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['priceCluster', 'category1', 'category3', 'brand', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'brand_weight', 'category1_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category3', 'brand', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'brand_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category1', 'category3', 'brand', 'user_id', 'date', 'priceCluster_weight', 'brand_weight', 'category1_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category1', 'brand', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'brand_weight', 'category1_weight', 'product_id_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category1', 'category3', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'category1_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'category1', 'category3', 'brand', 'user_id', 'date', 'category2', 'category2_weight', 'brand_weight', 'category1_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['user_id', 'date'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['priceCluster', 'category1', 'category3', 'brand', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'brand_weight', 'category1_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category3', 'brand', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'brand_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category1', 'category3', 'brand', 'user_id', 'date', 'priceCluster_weight', 'brand_weight', 'category1_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category1', 'brand', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'brand_weight', 'category1_weight', 'product_id_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category1', 'category3', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'category1_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'category1', 'category3', 'brand', 'user_id', 'date', 'category2', 'category2_weight', 'brand_weight', 'category1_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['user_id', 'date'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['priceCluster', 'category1', 'category3', 'brand', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'brand_weight', 'category1_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category3', 'brand', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'brand_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category1', 'category3', 'brand', 'user_id', 'date', 'priceCluster_weight', 'brand_weight', 'category1_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category1', 'brand', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'brand_weight', 'category1_weight', 'product_id_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category1', 'category3', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'category1_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'category1', 'category3', 'brand', 'user_id', 'date', 'category2', 'category2_weight', 'brand_weight', 'category1_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['user_id', 'date'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['priceCluster', 'category1', 'category3', 'brand', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'brand_weight', 'category1_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category3', 'brand', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'brand_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category1', 'category3', 'brand', 'user_id', 'date', 'priceCluster_weight', 'brand_weight', 'category1_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category1', 'brand', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'brand_weight', 'category1_weight', 'product_id_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category1', 'category3', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'category1_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'category1', 'category3', 'brand', 'user_id', 'date', 'category2', 'category2_weight', 'brand_weight', 'category1_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['user_id', 'date'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['priceCluster', 'category1', 'category3', 'brand', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'brand_weight', 'category1_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category3', 'brand', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'brand_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category1', 'category3', 'brand', 'user_id', 'date', 'priceCluster_weight', 'brand_weight', 'category1_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category1', 'brand', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'brand_weight', 'category1_weight', 'product_id_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'priceCluster', 'category1', 'category3', 'user_id', 'date', 'category2', 'priceCluster_weight', 'category2_weight', 'category1_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'category1', 'category3', 'brand', 'user_id', 'date', 'category2', 'category2_weight', 'brand_weight', 'category1_weight', 'product_id_weight', 'category3_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['user_id', 'date'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    }
   ],
   "source": [
    "## %%time\n",
    "from collections import defaultdict\n",
    "from utils import evaluate_model, wAUC\n",
    "\n",
    "aucs = defaultdict(dict)\n",
    "for task_offer_feature in TASKS:\n",
    "    for model_name in TASKS:\n",
    "        aucs[task_offer_feature][f'MONO:{model_name}'] = \\\n",
    "            evaluate_model(mono_feature_models[model_name],\n",
    "                           task_offer_feature, test_datasets, inverse_lookups, NUMBER_OF_NEGATIVES)\n",
    "    aucs[task_offer_feature]['simple model'] = \\\n",
    "            evaluate_model(model, task_offer_feature, test_datasets, inverse_lookups, NUMBER_OF_NEGATIVES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a374dd80-b0dc-4905-903c-84b72735777c",
   "metadata": {},
   "source": [
    "We can aggregate AUCs from individual offers to have one value we can compare among models: weighted macro AUC. We will keep only offers with more than 200 positive events and weight their AUCs by number of events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdf4194-a2fc-4c89-a524-4dda2905ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.DataFrame()\n",
    "for task_name in aucs:\n",
    "    for model_name in aucs[task_name]:\n",
    "        w_auc = wAUC(aucs[task_name][model_name])\n",
    "        results = results.append({'wAUC': w_auc, 'offers': task_name, 'model': model_name}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869761a6-12d2-4364-9962-c0fa902e18f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9f787_row0_col0, #T_9f787_row1_col1, #T_9f787_row2_col2, #T_9f787_row3_col3, #T_9f787_row4_col4, #T_9f787_row5_col5 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9f787_row0_col1 {\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f787_row0_col2 {\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f787_row0_col3 {\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9f787_row0_col4 {\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f787_row0_col5, #T_9f787_row3_col2 {\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f787_row1_col0, #T_9f787_row2_col4 {\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9f787_row1_col2 {\n",
       "  background-color: #e16751;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9f787_row1_col3 {\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f787_row1_col4 {\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9f787_row1_col5 {\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9f787_row2_col0 {\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9f787_row2_col1 {\n",
       "  background-color: #f49a7b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f787_row2_col3 {\n",
       "  background-color: #f39577;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f787_row2_col5 {\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9f787_row3_col0, #T_9f787_row3_col4, #T_9f787_row3_col5, #T_9f787_row4_col1, #T_9f787_row4_col2, #T_9f787_row4_col3 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9f787_row3_col1 {\n",
       "  background-color: #ead5c9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f787_row4_col0 {\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9f787_row4_col5 {\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f787_row5_col0 {\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9f787_row5_col1 {\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f787_row5_col2 {\n",
       "  background-color: #cbd8ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f787_row5_col3 {\n",
       "  background-color: #c6d6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f787_row5_col4 {\n",
       "  background-color: #f1cdba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f787_row6_col0 {\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9f787_row6_col1 {\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f787_row6_col2 {\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f787_row6_col3 {\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f787_row6_col4 {\n",
       "  background-color: #f1ccb8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f787_row6_col5 {\n",
       "  background-color: #b70d28;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9f787_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >offers</th>\n",
       "      <th class=\"col_heading level0 col0\" >brand</th>\n",
       "      <th class=\"col_heading level0 col1\" >category1</th>\n",
       "      <th class=\"col_heading level0 col2\" >category2</th>\n",
       "      <th class=\"col_heading level0 col3\" >category3</th>\n",
       "      <th class=\"col_heading level0 col4\" >priceCluster</th>\n",
       "      <th class=\"col_heading level0 col5\" >product_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9f787_level0_row0\" class=\"row_heading level0 row0\" >MONO:brand</th>\n",
       "      <td id=\"T_9f787_row0_col0\" class=\"data row0 col0\" >0.720142</td>\n",
       "      <td id=\"T_9f787_row0_col1\" class=\"data row0 col1\" >0.598288</td>\n",
       "      <td id=\"T_9f787_row0_col2\" class=\"data row0 col2\" >0.607077</td>\n",
       "      <td id=\"T_9f787_row0_col3\" class=\"data row0 col3\" >0.598040</td>\n",
       "      <td id=\"T_9f787_row0_col4\" class=\"data row0 col4\" >0.606463</td>\n",
       "      <td id=\"T_9f787_row0_col5\" class=\"data row0 col5\" >0.718500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f787_level0_row1\" class=\"row_heading level0 row1\" >MONO:category1</th>\n",
       "      <td id=\"T_9f787_row1_col0\" class=\"data row1 col0\" >0.627355</td>\n",
       "      <td id=\"T_9f787_row1_col1\" class=\"data row1 col1\" >0.668074</td>\n",
       "      <td id=\"T_9f787_row1_col2\" class=\"data row1 col2\" >0.663821</td>\n",
       "      <td id=\"T_9f787_row1_col3\" class=\"data row1 col3\" >0.646415</td>\n",
       "      <td id=\"T_9f787_row1_col4\" class=\"data row1 col4\" >0.576787</td>\n",
       "      <td id=\"T_9f787_row1_col5\" class=\"data row1 col5\" >0.662828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f787_level0_row2\" class=\"row_heading level0 row2\" >MONO:category2</th>\n",
       "      <td id=\"T_9f787_row2_col0\" class=\"data row2 col0\" >0.627053</td>\n",
       "      <td id=\"T_9f787_row2_col1\" class=\"data row2 col1\" >0.643934</td>\n",
       "      <td id=\"T_9f787_row2_col2\" class=\"data row2 col2\" >0.676486</td>\n",
       "      <td id=\"T_9f787_row2_col3\" class=\"data row2 col3\" >0.650058</td>\n",
       "      <td id=\"T_9f787_row2_col4\" class=\"data row2 col4\" >0.568405</td>\n",
       "      <td id=\"T_9f787_row2_col5\" class=\"data row2 col5\" >0.660762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f787_level0_row3\" class=\"row_heading level0 row3\" >MONO:category3</th>\n",
       "      <td id=\"T_9f787_row3_col0\" class=\"data row3 col0\" >0.626376</td>\n",
       "      <td id=\"T_9f787_row3_col1\" class=\"data row3 col1\" >0.625109</td>\n",
       "      <td id=\"T_9f787_row3_col2\" class=\"data row3 col2\" >0.641843</td>\n",
       "      <td id=\"T_9f787_row3_col3\" class=\"data row3 col3\" >0.668536</td>\n",
       "      <td id=\"T_9f787_row3_col4\" class=\"data row3 col4\" >0.567290</td>\n",
       "      <td id=\"T_9f787_row3_col5\" class=\"data row3 col5\" >0.647156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f787_level0_row4\" class=\"row_heading level0 row4\" >MONO:priceCluster</th>\n",
       "      <td id=\"T_9f787_row4_col0\" class=\"data row4 col0\" >0.647901</td>\n",
       "      <td id=\"T_9f787_row4_col1\" class=\"data row4 col1\" >0.572067</td>\n",
       "      <td id=\"T_9f787_row4_col2\" class=\"data row4 col2\" >0.584299</td>\n",
       "      <td id=\"T_9f787_row4_col3\" class=\"data row4 col3\" >0.591195</td>\n",
       "      <td id=\"T_9f787_row4_col4\" class=\"data row4 col4\" >0.694362</td>\n",
       "      <td id=\"T_9f787_row4_col5\" class=\"data row4 col5\" >0.716155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f787_level0_row5\" class=\"row_heading level0 row5\" >MONO:product_id</th>\n",
       "      <td id=\"T_9f787_row5_col0\" class=\"data row5 col0\" >0.706076</td>\n",
       "      <td id=\"T_9f787_row5_col1\" class=\"data row5 col1\" >0.610038</td>\n",
       "      <td id=\"T_9f787_row5_col2\" class=\"data row5 col2\" >0.624329</td>\n",
       "      <td id=\"T_9f787_row5_col3\" class=\"data row5 col3\" >0.623540</td>\n",
       "      <td id=\"T_9f787_row5_col4\" class=\"data row5 col4\" >0.642318</td>\n",
       "      <td id=\"T_9f787_row5_col5\" class=\"data row5 col5\" >0.761413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f787_level0_row6\" class=\"row_heading level0 row6\" >simple model</th>\n",
       "      <td id=\"T_9f787_row6_col0\" class=\"data row6 col0\" >0.709834</td>\n",
       "      <td id=\"T_9f787_row6_col1\" class=\"data row6 col1\" >0.623426</td>\n",
       "      <td id=\"T_9f787_row6_col2\" class=\"data row6 col2\" >0.628428</td>\n",
       "      <td id=\"T_9f787_row6_col3\" class=\"data row6 col3\" >0.634945</td>\n",
       "      <td id=\"T_9f787_row6_col4\" class=\"data row6 col4\" >0.643003</td>\n",
       "      <td id=\"T_9f787_row6_col5\" class=\"data row6 col5\" >0.760167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fad45dda410>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(results, 'wAUC', 'model', 'offers').style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261948e7-ec42-4be6-8d30-2d32a89be249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom [moksha-tf2-cpu.2-7] (Local)",
   "language": "python",
   "name": "local-eu.gcr.io_tinyclues-experiments_tinyclues_moksha-tf2-cpu.2-7_latest__python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
