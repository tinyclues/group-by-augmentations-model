{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea932e5b",
   "metadata": {},
   "source": [
    "# Bi-linear interaction model with group-by augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b6f05f",
   "metadata": {},
   "source": [
    "## Prepare dataset for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96897ae",
   "metadata": {},
   "source": [
    "Following the same steps as in [the training of a simple model](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/training/movielens%20simple%20model.ipynb), we first load splitted dataset generated in [notebook](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/dataset_preprocessing/movielens%20with%20imdb.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1899e738-56d3-455f-afcd-ce80fcb17232",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'movielens_imdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19cc05cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_dataset\n",
    "\n",
    "datasets = {}\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    datasets[split_name] = load_dataset(DATASET, split_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d1b29e",
   "metadata": {},
   "source": [
    "Then we parse features' names to obtain a list of offer features (that will be used to modelize film) and a list of user features (aggregated history up to chosen date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5077ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import AGG_PREFIX\n",
    "\n",
    "all_columns = list(datasets['train'].element_spec.keys())\n",
    "technical_columns = ['userId', 'date']\n",
    "user_features = list(filter(lambda x: x.startswith(AGG_PREFIX), all_columns))\n",
    "offer_features = list(filter(lambda x: x not in user_features + technical_columns, all_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7d5781",
   "metadata": {},
   "source": [
    "### Rebatching datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96990cb",
   "metadata": {},
   "source": [
    "Splitting dataset into smaller batches in the same way as described in [the training of a simple model](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/training/movielens%20simple%20model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfa53a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.2 s, sys: 6.32 s, total: 47.5 s\n",
      "Wall time: 35.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from functools import partial\n",
    "from uuid import uuid4\n",
    "\n",
    "from utils import rebatch_by_events\n",
    "\n",
    "datasets['train'] = rebatch_by_events(datasets['train'], batch_size=10080, date_column='date', nb_events_by_user_by_day=8)\n",
    "for key in ['val', 'test']:\n",
    "    datasets[key] = rebatch_by_events(datasets[key], batch_size=50400, date_column='date', nb_events_by_user_by_day=8,\n",
    "                                      seed=1729).cache(f'/tmp/{uuid4()}.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20173463-08c7-4b6f-a9b8-ade7c5c1121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import add_equal_weights\n",
    "\n",
    "for key in datasets:\n",
    "    datasets[key] = datasets[key].map(partial(add_equal_weights, features=offer_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10790714",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c685bae",
   "metadata": {},
   "source": [
    "First we need to get number of different modalities inputs can take from saved vectorizers (it will be used in embeddings layer definition):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb20fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_inverse_lookups\n",
    "inverse_lookups = load_inverse_lookups(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a92d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "vocabulary_sizes = {}\n",
    "\n",
    "for feature in offer_features:\n",
    "    vocabulary_sizes[feature] = inverse_lookups[feature].vocabulary_size()\n",
    "\n",
    "for feature in user_features:\n",
    "    for key in inverse_lookups:\n",
    "        pattern = re.compile(r\"{}(\\w+)_{}\".format(AGG_PREFIX, key))\n",
    "        if pattern.match(feature):\n",
    "            vocabulary_sizes[feature] = vocabulary_sizes[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9119b378",
   "metadata": {},
   "source": [
    "### Layers definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9643942",
   "metadata": {},
   "source": [
    "To define a model with group-by augmentations we need to create some layers described in [this blog post](https://medium.com/p/508d5080c0c6/). In all following schemas we color weights that will be learned during training in red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bc288f",
   "metadata": {},
   "source": [
    "#### Generation of group-by augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37870c44",
   "metadata": {},
   "source": [
    "To get group-by augmentations we need first choose randomly some offer features we will use to get group by keys that will consist of AND and OR combinations of values from chosen features. It is implemented in `KeyGenerator` layer. Next once we get keys, we will group by and calculate mean and variance embeddings vectors for other features wrt to chosen keys. Finally, we will broadcast mean and variance vectors back to return to original batch size. Both calculation and broadcast are implemented in `GroupBy` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1753e74f-9f8b-4ed5-aa0a-cc0a829794ef",
   "metadata": {},
   "source": [
    "<img src=\"resources/group_by_augmentation.png\" alt=\"group-by augmentation generation\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35350305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from layers import KeyGenerator, GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0823204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_key_generator = KeyGenerator(number_of_offer_attributes=len(offer_features),\n",
    "                                  average_number_of_attributes_in_key=2,\n",
    "                                  name='test_key_generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b348b68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 7), dtype=int32, numpy=\n",
       "array([[4, 1, 3, 1, 1, 4, 1],\n",
       "       [1, 0, 0, 2, 1, 4, 0],\n",
       "       [3, 1, 2, 0, 0, 1, 3],\n",
       "       [1, 1, 4, 4, 0, 4, 3],\n",
       "       [4, 3, 0, 1, 4, 1, 3],\n",
       "       [3, 3, 3, 2, 4, 4, 2],\n",
       "       [0, 1, 4, 0, 2, 3, 4],\n",
       "       [1, 4, 1, 1, 0, 1, 4],\n",
       "       [0, 0, 4, 3, 2, 1, 2],\n",
       "       [3, 4, 2, 2, 0, 0, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampling randomly values for offer features\n",
    "test_offer_features = tf.random.uniform((10, len(offer_features)), maxval=5, dtype=tf.int32)\n",
    "test_offer_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "998c2da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 0, 4, 5, 6, 7, 4], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key generator returns hashed keys for group by\n",
    "test_keys = test_key_generator(test_offer_features)\n",
    "test_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7598fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by = GroupBy(name='group_by')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "314d05c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have some embeddings vectors\n",
    "test_embeddings = tf.random.normal((10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ffa681f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([10, 3]), TensorShape([10, 3]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can apply group-by operation for all features\n",
    "test_mean, test_var = group_by(test_keys, test_embeddings)\n",
    "test_mean.shape, test_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30527f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 3), dtype=float64, numpy=\n",
       " array([[0.5, 0.5, 0. ],\n",
       "        [0.5, 0.5, 0. ],\n",
       "        [0. , 0. , 1. ]])>,\n",
       " <tf.Tensor: shape=(3, 3), dtype=float64, numpy=\n",
       " array([[0.25, 0.25, 0.  ],\n",
       "        [0.25, 0.25, 0.  ],\n",
       "        [0.  , 0.  , 0.  ]])>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or more direct example of group by\n",
    "import numpy as np\n",
    "group_by([0, 0, 1], np.eye(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43411cf",
   "metadata": {},
   "source": [
    "#### Compression of user features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1af9d9f",
   "metadata": {},
   "source": [
    "For optimisation of calculation of interaction we want to reduce number of user features we use. For that we will generate meta features using a sequence of fully connected layers based on `tf.keras.layers.experimental.EinsumDense` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d1267",
   "metadata": {},
   "source": [
    "<img src=\"resources/user_features_compression.png\" alt=\"compression of user features\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98942bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 2, 7])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from layers import UserFeaturesCompressor\n",
    "test_user_compressor = UserFeaturesCompressor(number_of_meta_features=2,\n",
    "                                              dropout_rate=0.1,\n",
    "                                              name='test_user_compressor')\n",
    "test_user_compressor(tf.random.normal((10, 3, 7))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668ff767",
   "metadata": {},
   "source": [
    "#### Compression of offer features and MaskNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c62da",
   "metadata": {},
   "source": [
    "This is a key layer that will create some meta offer features and apply instance guided mask over embedding dimension. For meta features, the idea is similar to user side: we want to get smaller number of features before interaction, but here using information about variance we can completely deactivate some features, depending on offer we want to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f39e8f",
   "metadata": {},
   "source": [
    "<img src=\"resources/offer_features_compression.png\" alt=\"compression of offer features\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd188a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 2, 7])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from layers import OfferFeaturesCompressor\n",
    "test_offer_compressor = OfferFeaturesCompressor(number_of_meta_features=2,\n",
    "                                                dropout_rate=0.1,\n",
    "                                                name='test_offer_compressor')\n",
    "test_offer_compressor([tf.random.normal((10, 3, 7)), tf.random.normal((10, 3, 7))]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8acd338e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 2, 7])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from layers import MaskNet\n",
    "test_mask = MaskNet(number_of_meta_features=2, dropout_rate=0.1)\n",
    "test_mask([tf.random.normal((10, 3, 7)), tf.random.normal((10, 3, 7))]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86ffb69",
   "metadata": {},
   "source": [
    "#### Bi-linear feature-wise interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cf6525",
   "metadata": {},
   "source": [
    "Last step is a calculation of interaction using bi-linear kernel for each pair of meta features from user and from offer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7522b5",
   "metadata": {},
   "source": [
    "<img src=\"resources/bi_linear_interaction.png\" alt=\"bi-linear feature wise interaction\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127052be-6506-4507-83a3-d526c617c02c",
   "metadata": {},
   "source": [
    "We also incorporate mini-batch generation of negative examples inside this layer in the similar way described in [the training of a simple model](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/training/movielens%20simple%20model.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2202cde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 12])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from layers import BiLinearInteraction\n",
    "test_interaction = BiLinearInteraction(number_of_negatives=3, dropout_rate=0., name='test_interaction')\n",
    "test_interaction([tf.random.normal((10, 4, 7)), tf.random.normal((10, 3, 5))], generate_negatives=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41ea0f44-0144-4079-84c1-6d03464a99c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([48, 12])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_interaction([tf.random.normal((12, 4, 7)), tf.random.normal((12, 3, 5))], generate_negatives=True).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e4c620",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357fd6b2",
   "metadata": {},
   "source": [
    "Now we can assemble all these layers into final model. Note that offer compression weights and interaction kernels are shared between different augmentations we generate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e60cfa",
   "metadata": {},
   "source": [
    "<img src=\"resources/group_by_augmentations_model.png\" alt=\"model\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b8378e",
   "metadata": {},
   "source": [
    "### Model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73764c02",
   "metadata": {},
   "source": [
    "For model's regularization we used a combination of several strategies:\n",
    "* `weight_decay` in the optimizer (for L2-penalty)\n",
    "* explicit L1-penalty on embedding layers\n",
    "* dropouts in fully-connected layers (after interaction, inside compression)\n",
    "\n",
    "We use `AdamW` optimizer and `BCE` loss, but in some cases it maybe be interesting to use [`FocalLoss`](https://www.tensorflow.org/addons/api_docs/python/tfa/losses/SigmoidFocalCrossEntropy) (with $\\gamma=1.5~…~2.5$) that automatically will concentrate on harder examples.\n",
    "\n",
    "There are some model parameters that can be changed (and tuned), during experimentations we found some typical values for those parameters:\n",
    "\n",
    "| parameter                                    | description                     | typical values | comment                                                                                                   |\n",
    "|----------------------------------------------|---------------------------------|----------------|-----------------------------------------------------------------------------------------------------------|\n",
    "| batch size, set above                        | batch size                                       | 5k … 20k       | it should not be too low if we want to have on-the-fly group-by                                      |\n",
    "| learning rate inside `OPTIMIZER`             | learning rate                                    | 0.001 … 0.005 | usually we set it as a half of the learning rate used in standard training                                               |\n",
    "| `USER_META_FEATURES`, `OFFER_META_FEATURES`  | compression meta dimension                       | 2 … 6         | prefer bigger values for larger number of offer features and complex (non-hierarchical) feature structure|\n",
    "| `NB_AUGMENTATIONS`                           | number of augmentations per step                 | 3 … 10        | bigger for larger number of offer features                                                               |\n",
    "| `AVERAGE_NUMBER_OF_FEATURES_IN_AUGMENTATION` | how many offer features used for group by key    | 1.5 … 3       | bigger for larger number of offer features                                                               |\n",
    "| `EPOCHS`                                     | number of epochs                                 | 2 … 50         | we need to double or triple number of epochs compared to std training                                      |\n",
    "| `EMBEDDING_DIM`                              | embedding latent dimensions                      | 15 … 60        | usually depends on the data amount and features modularity                                             |\n",
    "| `NUMBER_OF_NEGATIVES`                        | number of negatives examples                     | 3 … 10       | bigger number of negative examples may create some collisions for higher level offers                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1cf92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "L1_COEFF = 8.5e-7\n",
    "DROPOUT = 0.17\n",
    "\n",
    "NB_AUGMENTATIONS = 3\n",
    "AVERAGE_NUMBER_OF_FEATURES_IN_AUGMENTATION = 2\n",
    "USER_META_FEATURES = 5\n",
    "OFFER_META_FEATURES = 3\n",
    "\n",
    "def REGULARIZER():\n",
    "    return {'class_name': 'L1L2', 'config': {'l1': L1_COEFF, 'l2': 0.}}\n",
    "\n",
    "def OUTPUT_DNN():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(80,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Activation('gelu'),\n",
    "        tf.keras.layers.Dense(40,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Activation('gelu'),\n",
    "        tf.keras.layers.Dense(1,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "    ], name='output_dnn')\n",
    "\n",
    "EPOCHS = 12\n",
    "\n",
    "NUMBER_OF_NEGATIVES = 4\n",
    "LOSS = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "AUC_METRIC = tf.keras.metrics.AUC(from_logits=True)\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "OPTIMIZER = tfa.optimizers.AdamW(weight_decay=8.5e-8, learning_rate=0.0008)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f94016",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b103374",
   "metadata": {},
   "source": [
    "We will define embeddings with the same `WeightedEmbeddings` layer described in [the training of a simple model](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/training/movielens%20simple%20model.ipynb) with one addition:\n",
    "* for offer features when aggregating a list of embedding vectors, we will also calculate variance and not only mean vector\n",
    "\n",
    "It is easy to do in the same sparse-dense matrix multiplication operation as mean calculation (we get second moment and then calculate variance from it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca4935ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import get_input_layer, WeightedEmbeddings\n",
    "from utils import WEIGHT_SUFFIX\n",
    "\n",
    "inputs = {}\n",
    "embedded_user_features, embedded_offer_features, variance_offer_features = {}, {}, {}\n",
    "for feature in user_features:\n",
    "    inputs[feature] = get_input_layer(feature)\n",
    "    emb_layer = WeightedEmbeddings(vocabulary_sizes[feature],\n",
    "                                   EMBEDDING_DIM, name=f'{feature}_embedding',\n",
    "                                   embeddings_regularizer=REGULARIZER())\n",
    "    embedded_user_features[feature] = emb_layer(inputs[feature])\n",
    "for feature in offer_features:\n",
    "    # for offer features we need weights:\n",
    "    # with dummy weights during training, and the ones used for a feature's averaging at inference time\n",
    "    inputs[f'{feature}_weight'] = get_input_layer(f'{feature}_weight', tf.float32)\n",
    "    inputs[feature] = get_input_layer(feature)\n",
    "    emb_layer = WeightedEmbeddings(vocabulary_sizes[feature],\n",
    "                                   EMBEDDING_DIM, name=f'{feature}_embedding',\n",
    "                                   embeddings_regularizer=REGULARIZER(),\n",
    "                                   calculate_variance=True)\n",
    "    embedded_offer_features[feature], variance_offer_features[feature] =\\\n",
    "        emb_layer(inputs[feature], inputs[f'{feature}_weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f442c975",
   "metadata": {},
   "source": [
    "### Combining everything into model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4753b65",
   "metadata": {},
   "source": [
    "Now we can define described model architecture on the top of embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48eb9977",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stacked = tf.stack(list(embedded_user_features.values()), axis=1)\n",
    "offer_stacked = tf.stack(list(embedded_offer_features.values()), axis=1)\n",
    "offer_variance = tf.stack(list(variance_offer_features.values()), axis=1)\n",
    "stacked_raw_offer_attrs = tf.stack([tf.cast(inp.values, tf.int32) for feature, inp in inputs.items()\n",
    "                                    if feature in offer_features], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7215846-24b0-4795-8db1-2ddad5d008c5",
   "metadata": {},
   "source": [
    "Note that we added an intermediate tensor where we stacked all raw offer features - it will be used in `KeyGenerator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea47cb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 7) dtype=int32 (created by layer 'tf.stack_3')>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_raw_offer_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01bc2e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_generator = KeyGenerator(number_of_offer_attributes=len(offer_features),\n",
    "                             average_number_of_attributes_in_key=AVERAGE_NUMBER_OF_FEATURES_IN_AUGMENTATION,\n",
    "                             name='grp_key_generator')\n",
    "\n",
    "user_compressed = UserFeaturesCompressor(USER_META_FEATURES, DROPOUT,\n",
    "                                         name='user_compressor')(user_stacked)\n",
    "offer_features_compressor = OfferFeaturesCompressor(OFFER_META_FEATURES, DROPOUT, name='offer_compressor')\n",
    "mask_net = MaskNet(OFFER_META_FEATURES, DROPOUT, name='mask_generation')\n",
    "apply_mask = tf.keras.layers.Multiply(name='apply_mask')\n",
    "bi_linear_interaction = BiLinearInteraction(number_of_negatives=NUMBER_OF_NEGATIVES, dropout_rate=DROPOUT,\n",
    "                                            initializer='random_normal', regularizer=REGULARIZER(),\n",
    "                                            name='interaction')\n",
    "output_dnn = OUTPUT_DNN()\n",
    "\n",
    "augmentation_predictions = []\n",
    "for i in range(NB_AUGMENTATIONS):\n",
    "    group_by_key = key_generator(stacked_raw_offer_attrs)\n",
    "    mean_offer_emb, variance_offer_emb = group_by(group_by_key, offer_stacked)\n",
    "    compressed_offer_embeddings = offer_features_compressor([mean_offer_emb, variance_offer_emb])\n",
    "    mask = mask_net([mean_offer_emb, variance_offer_emb])\n",
    "    masked_offer_embeddings = apply_mask([compressed_offer_embeddings, mask])\n",
    "    _output = output_dnn(bi_linear_interaction([user_compressed, masked_offer_embeddings], generate_negatives=True))\n",
    "    augmentation_predictions.append(_output)\n",
    "output = tf.concat(augmentation_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ded15-9fdc-457e-aeb7-64cc80958780",
   "metadata": {},
   "source": [
    "And for evaluation we don't need to create augmentations, we need just to take offer features' mean and variance coming from inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9c050d2-9ca3-40fe-858c-2a6ba2780b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_offer_embeddings = offer_features_compressor([offer_stacked, offer_variance])\n",
    "mask = mask_net([offer_stacked, offer_variance])\n",
    "masked_offer_embeddings = apply_mask([compressed_offer_embeddings, mask])\n",
    "\n",
    "eval_output = output_dnn(bi_linear_interaction([user_compressed, masked_offer_embeddings], generate_negatives=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2cc3833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import BroadcastLoss, BroadcastMetric\n",
    "\n",
    "model = tf.keras.Model(inputs, output, name='group_by_augmentations')\n",
    "model.compile(optimizer=OPTIMIZER,\n",
    "              loss=BroadcastLoss(LOSS, NUMBER_OF_NEGATIVES),\n",
    "              metrics=[BroadcastMetric(AUC_METRIC, NUMBER_OF_NEGATIVES)])\n",
    "\n",
    "eval_model = tf.keras.Model(inputs, eval_output, name='group_by_augmentations_eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b3f9fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, to_file=f'models/{DATASET}_group_by_augmentations.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e81c8b1",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c5fe7ce-8649-498b-ad36-d05e652a1d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/group_by_augmentations/group_by/moments_2/Reshape_4:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/group_by_augmentations/group_by/moments_2/Reshape_3:0\", shape=(None, 7, 100), dtype=float32), dense_shape=Tensor(\"gradient_tape/group_by_augmentations/group_by/moments_2/Cast:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/group_by_augmentations/group_by/moments_1/Reshape_4:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/group_by_augmentations/group_by/moments_1/Reshape_3:0\", shape=(None, 7, 100), dtype=float32), dense_shape=Tensor(\"gradient_tape/group_by_augmentations/group_by/moments_1/Cast:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/group_by_augmentations/group_by/moments/Reshape_4:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/group_by_augmentations/group_by/moments/Reshape_3:0\", shape=(None, 7, 100), dtype=float32), dense_shape=Tensor(\"gradient_tape/group_by_augmentations/group_by/moments/Cast:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"AdamW/gradients/concat_1:0\", shape=(None,), dtype=int32), values=Tensor(\"AdamW/gradients/concat:0\", shape=(None, 7, 100), dtype=float32), dense_shape=Tensor(\"gradient_tape/group_by_augmentations/group_by/SegmentStack_2/Cast:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 779s 3s/step - loss: 0.5327 - auc: 0.5312 - val_loss: 0.5167 - val_auc: 0.5554\n",
      "Epoch 2/12\n",
      "231/231 [==============================] - 620s 3s/step - loss: 0.4989 - auc: 0.5896 - val_loss: 0.4994 - val_auc: 0.5928\n",
      "Epoch 3/12\n",
      "231/231 [==============================] - 579s 2s/step - loss: 0.4940 - auc: 0.6075 - val_loss: 0.4991 - val_auc: 0.5892\n",
      "Epoch 4/12\n",
      "231/231 [==============================] - 477s 2s/step - loss: 0.4926 - auc: 0.6090 - val_loss: 0.4993 - val_auc: 0.5820\n",
      "Epoch 5/12\n",
      "231/231 [==============================] - 739s 3s/step - loss: 0.4906 - auc: 0.6159 - val_loss: 0.4939 - val_auc: 0.6069\n",
      "Epoch 6/12\n",
      "231/231 [==============================] - 868s 4s/step - loss: 0.4895 - auc: 0.6188 - val_loss: 0.4976 - val_auc: 0.5931\n",
      "Epoch 7/12\n",
      "231/231 [==============================] - 498s 2s/step - loss: 0.4893 - auc: 0.6177 - val_loss: 0.4937 - val_auc: 0.6034\n",
      "Epoch 8/12\n",
      "231/231 [==============================] - 498s 2s/step - loss: 0.4880 - auc: 0.6225 - val_loss: 0.4928 - val_auc: 0.6087\n",
      "Epoch 9/12\n",
      "231/231 [==============================] - 646s 3s/step - loss: 0.4884 - auc: 0.6197 - val_loss: 0.4922 - val_auc: 0.6135\n",
      "Epoch 10/12\n",
      "231/231 [==============================] - 657s 3s/step - loss: 0.4877 - auc: 0.6227 - val_loss: 0.4948 - val_auc: 0.6015\n",
      "Epoch 11/12\n",
      "231/231 [==============================] - 652s 3s/step - loss: 0.4877 - auc: 0.6220 - val_loss: 0.4903 - val_auc: 0.6197\n",
      "Epoch 12/12\n",
      "231/231 [==============================] - 669s 3s/step - loss: 0.4861 - auc: 0.6285 - val_loss: 0.4918 - val_auc: 0.6157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f74421d0fa0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datasets['train'], epochs=EPOCHS, validation_data=datasets['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27080ac6-2c87-49b0-b942-7c9bc02c29a0",
   "metadata": {},
   "source": [
    "## Single task models benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb00e26-0475-459a-9973-5aeb2fc8faf3",
   "metadata": {},
   "source": [
    "Using same approach as in [the simple model notebook](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/training/rees%20simple%20model.ipynb) we will look at performance gap between the model with group by augmentations against set of models specialized on tasks corresponding to one offer feature at time. We won't use augmentations in those baseline models, because they will be already aligned with offer we will use in evaluation afterwards. To illustrate importance of augmentations we will also train single model without group_by augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "373994d8-b6ec-4d7c-b878-b8c1f7bc58bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# offer columns we want to evaluate, specific to dataset we test\n",
    "TASKS = ['imdbId', 'director', 'genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2170ef73-1e06-4dda-9463-be8c1e71a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_linear_interaction_model(offer_features, name='bi_linear_model'):\n",
    "    # user_features, vocabulary_sizes, EMBEDDING_DIM, REGULARIZER, OPTIMIZER,\n",
    "    # OUTPUT_DNN, LOSS, NUMBER_OF_NEGATIVES\n",
    "    # come from global scope, but can be passed as params instead\n",
    "    inputs = {}\n",
    "    embedded_user_features, embedded_offer_features = {}, {}\n",
    "    for feature in user_features:\n",
    "        inputs[feature] = get_input_layer(feature)\n",
    "        emb_layer = WeightedEmbeddings(vocabulary_sizes[feature],\n",
    "                                       EMBEDDING_DIM, name=f'{feature}_embedding',\n",
    "                                       embeddings_regularizer=REGULARIZER())\n",
    "        embedded_user_features[feature] = emb_layer(inputs[feature])\n",
    "\n",
    "    # for offer feature we need weights:\n",
    "    # with dummy weights during training, and the ones used for a feature's averaging at inference time\n",
    "    for feature in offer_features:\n",
    "        inputs[feature] = get_input_layer(feature)\n",
    "        inputs[f'{feature}_weight'] = get_input_layer(f'{feature}_weight', tf.float32)\n",
    "        emb_layer = WeightedEmbeddings(vocabulary_sizes[feature],\n",
    "                                       EMBEDDING_DIM, name=f'{feature}_embedding',\n",
    "                                       embeddings_regularizer=REGULARIZER())\n",
    "        embedded_offer_features[feature] = emb_layer(inputs[feature], inputs[f'{feature}_weight'])\n",
    "    \n",
    "    user_stacked = tf.stack(list(embedded_user_features.values()), axis=1)\n",
    "    offer_stacked = tf.stack(list(embedded_offer_features.values()), axis=1)\n",
    "    \n",
    "    user_compressed = UserFeaturesCompressor(USER_META_FEATURES, DROPOUT,\n",
    "                                             name='user_compressor')(user_stacked)\n",
    "    \n",
    "    output_dnn = OUTPUT_DNN()\n",
    "    bi_linear_interaction = BiLinearInteraction(number_of_negatives=NUMBER_OF_NEGATIVES, dropout_rate=DROPOUT,\n",
    "                                                initializer='random_normal', regularizer=REGULARIZER(),\n",
    "                                                name='interaction')\n",
    "    \n",
    "    output = output_dnn(bi_linear_interaction([user_compressed, offer_stacked], generate_negatives=True))\n",
    "\n",
    "    model = tf.keras.Model(inputs, output, name=name)\n",
    "    model.compile(optimizer=OPTIMIZER,\n",
    "                  loss=BroadcastLoss(LOSS, NUMBER_OF_NEGATIVES),\n",
    "                  metrics=[BroadcastMetric(AUC_METRIC, NUMBER_OF_NEGATIVES)])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33553765-ab1f-4240-aa02-3b1814f79d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "231/231 [==============================] - 464s 2s/step - loss: 0.5181 - auc: 0.5962 - val_loss: 0.5101 - val_auc: 0.6128\n",
      "Epoch 2/12\n",
      "231/231 [==============================] - 329s 1s/step - loss: 0.4911 - auc: 0.6509 - val_loss: 0.4961 - val_auc: 0.6366\n",
      "Epoch 3/12\n",
      "231/231 [==============================] - 330s 1s/step - loss: 0.4841 - auc: 0.6637 - val_loss: 0.4911 - val_auc: 0.6458\n",
      "Epoch 4/12\n",
      "231/231 [==============================] - 333s 1s/step - loss: 0.4801 - auc: 0.6700 - val_loss: 0.4876 - val_auc: 0.6485\n",
      "Epoch 5/12\n",
      "231/231 [==============================] - 282s 1s/step - loss: 0.4774 - auc: 0.6739 - val_loss: 0.4866 - val_auc: 0.6502\n",
      "Epoch 6/12\n",
      "231/231 [==============================] - 251s 1s/step - loss: 0.4756 - auc: 0.6765 - val_loss: 0.4860 - val_auc: 0.6518\n",
      "Epoch 7/12\n",
      "231/231 [==============================] - 242s 1s/step - loss: 0.4743 - auc: 0.6787 - val_loss: 0.4856 - val_auc: 0.6525\n",
      "Epoch 8/12\n",
      "231/231 [==============================] - 243s 1s/step - loss: 0.4733 - auc: 0.6805 - val_loss: 0.4857 - val_auc: 0.6523\n",
      "Epoch 9/12\n",
      "231/231 [==============================] - 282s 1s/step - loss: 0.4723 - auc: 0.6826 - val_loss: 0.4853 - val_auc: 0.6535\n",
      "Epoch 10/12\n",
      "231/231 [==============================] - 279s 1s/step - loss: 0.4716 - auc: 0.6844 - val_loss: 0.4846 - val_auc: 0.6542\n",
      "Epoch 11/12\n",
      "231/231 [==============================] - 276s 1s/step - loss: 0.4710 - auc: 0.6858 - val_loss: 0.4845 - val_auc: 0.6559\n",
      "Epoch 12/12\n",
      "231/231 [==============================] - 289s 1s/step - loss: 0.4703 - auc: 0.6875 - val_loss: 0.4849 - val_auc: 0.6570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f75575006a0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wo_augmentations = bi_linear_interaction_model(offer_features, name='model_wo_augm')\n",
    "model_wo_augmentations.fit(datasets['train'], epochs=EPOCHS, validation_data=datasets['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34c6b37f-b971-41b6-bc36-e60974bcdb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'actor', 'startYearCluster', 'userId', 'titleType', 'runtimeMinutesCluster', 'genre', 'director', 'actor_weight', 'startYearCluster_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'genre_weight', 'director_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 258s 957ms/step - loss: 0.5109 - auc: 0.5864 - val_loss: 0.4984 - val_auc: 0.6122\n",
      "Epoch 2/12\n",
      "231/231 [==============================] - 151s 620ms/step - loss: 0.4900 - auc: 0.6396 - val_loss: 0.4929 - val_auc: 0.6306\n",
      "Epoch 3/12\n",
      "231/231 [==============================] - 122s 506ms/step - loss: 0.4846 - auc: 0.6549 - val_loss: 0.4896 - val_auc: 0.6397\n",
      "Epoch 4/12\n",
      "231/231 [==============================] - 119s 494ms/step - loss: 0.4815 - auc: 0.6622 - val_loss: 0.4880 - val_auc: 0.6434\n",
      "Epoch 5/12\n",
      "231/231 [==============================] - 119s 494ms/step - loss: 0.4792 - auc: 0.6673 - val_loss: 0.4873 - val_auc: 0.6465\n",
      "Epoch 6/12\n",
      "231/231 [==============================] - 122s 504ms/step - loss: 0.4775 - auc: 0.6709 - val_loss: 0.4860 - val_auc: 0.6483\n",
      "Epoch 7/12\n",
      "231/231 [==============================] - 119s 492ms/step - loss: 0.4761 - auc: 0.6734 - val_loss: 0.4853 - val_auc: 0.6496\n",
      "Epoch 8/12\n",
      "231/231 [==============================] - 125s 517ms/step - loss: 0.4751 - auc: 0.6755 - val_loss: 0.4852 - val_auc: 0.6494\n",
      "Epoch 9/12\n",
      "231/231 [==============================] - 138s 573ms/step - loss: 0.4743 - auc: 0.6771 - val_loss: 0.4854 - val_auc: 0.6513\n",
      "Epoch 10/12\n",
      "231/231 [==============================] - 143s 594ms/step - loss: 0.4737 - auc: 0.6788 - val_loss: 0.4847 - val_auc: 0.6523\n",
      "Epoch 11/12\n",
      "231/231 [==============================] - 143s 592ms/step - loss: 0.4731 - auc: 0.6802 - val_loss: 0.4844 - val_auc: 0.6522\n",
      "Epoch 12/12\n",
      "231/231 [==============================] - 141s 584ms/step - loss: 0.4725 - auc: 0.6817 - val_loss: 0.4845 - val_auc: 0.6533\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'actor', 'startYearCluster', 'userId', 'titleType', 'runtimeMinutesCluster', 'genre', 'imdbId', 'actor_weight', 'startYearCluster_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'genre_weight', 'imdbId_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 191s 726ms/step - loss: 0.5085 - auc: 0.5691 - val_loss: 0.4971 - val_auc: 0.5941\n",
      "Epoch 2/12\n",
      "231/231 [==============================] - 151s 627ms/step - loss: 0.4919 - auc: 0.6151 - val_loss: 0.4933 - val_auc: 0.6110\n",
      "Epoch 3/12\n",
      "231/231 [==============================] - 148s 615ms/step - loss: 0.4882 - auc: 0.6287 - val_loss: 0.4917 - val_auc: 0.6161\n",
      "Epoch 4/12\n",
      "231/231 [==============================] - 150s 624ms/step - loss: 0.4861 - auc: 0.6342 - val_loss: 0.4906 - val_auc: 0.6194\n",
      "Epoch 5/12\n",
      "231/231 [==============================] - 149s 621ms/step - loss: 0.4847 - auc: 0.6380 - val_loss: 0.4901 - val_auc: 0.6216\n",
      "Epoch 6/12\n",
      "231/231 [==============================] - 151s 629ms/step - loss: 0.4838 - auc: 0.6398 - val_loss: 0.4898 - val_auc: 0.6222\n",
      "Epoch 7/12\n",
      "231/231 [==============================] - 170s 713ms/step - loss: 0.4829 - auc: 0.6419 - val_loss: 0.4898 - val_auc: 0.6227\n",
      "Epoch 8/12\n",
      "231/231 [==============================] - 167s 696ms/step - loss: 0.4824 - auc: 0.6434 - val_loss: 0.4896 - val_auc: 0.6234\n",
      "Epoch 9/12\n",
      "231/231 [==============================] - 168s 703ms/step - loss: 0.4818 - auc: 0.6448 - val_loss: 0.4892 - val_auc: 0.6241\n",
      "Epoch 10/12\n",
      "231/231 [==============================] - 150s 625ms/step - loss: 0.4813 - auc: 0.6460 - val_loss: 0.4891 - val_auc: 0.6250\n",
      "Epoch 11/12\n",
      "231/231 [==============================] - 147s 612ms/step - loss: 0.4810 - auc: 0.6469 - val_loss: 0.4888 - val_auc: 0.6248\n",
      "Epoch 12/12\n",
      "231/231 [==============================] - 141s 586ms/step - loss: 0.4806 - auc: 0.6479 - val_loss: 0.4890 - val_auc: 0.6258\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'actor', 'startYearCluster', 'userId', 'titleType', 'runtimeMinutesCluster', 'director', 'imdbId', 'actor_weight', 'startYearCluster_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'director_weight', 'imdbId_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 166s 632ms/step - loss: 0.5107 - auc: 0.5227 - val_loss: 0.5020 - val_auc: 0.5309\n",
      "Epoch 2/12\n",
      "231/231 [==============================] - 138s 574ms/step - loss: 0.5016 - auc: 0.5367 - val_loss: 0.5013 - val_auc: 0.5403\n",
      "Epoch 3/12\n",
      "231/231 [==============================] - 142s 591ms/step - loss: 0.5004 - auc: 0.5450 - val_loss: 0.5007 - val_auc: 0.5445\n",
      "Epoch 4/12\n",
      "231/231 [==============================] - 150s 623ms/step - loss: 0.4997 - auc: 0.5482 - val_loss: 0.5000 - val_auc: 0.5481\n",
      "Epoch 5/12\n",
      "231/231 [==============================] - 140s 580ms/step - loss: 0.4992 - auc: 0.5502 - val_loss: 0.4999 - val_auc: 0.5484\n",
      "Epoch 6/12\n",
      "231/231 [==============================] - 142s 584ms/step - loss: 0.4988 - auc: 0.5513 - val_loss: 0.5000 - val_auc: 0.5474\n",
      "Epoch 7/12\n",
      "231/231 [==============================] - 139s 576ms/step - loss: 0.4986 - auc: 0.5521 - val_loss: 0.5000 - val_auc: 0.5492\n",
      "Epoch 8/12\n",
      "231/231 [==============================] - 125s 518ms/step - loss: 0.4984 - auc: 0.5532 - val_loss: 0.4996 - val_auc: 0.5491\n",
      "Epoch 9/12\n",
      "231/231 [==============================] - 126s 523ms/step - loss: 0.4983 - auc: 0.5535 - val_loss: 0.4999 - val_auc: 0.5495\n",
      "Epoch 10/12\n",
      "231/231 [==============================] - 131s 541ms/step - loss: 0.4981 - auc: 0.5546 - val_loss: 0.4996 - val_auc: 0.5496\n",
      "Epoch 11/12\n",
      "231/231 [==============================] - 127s 523ms/step - loss: 0.4980 - auc: 0.5549 - val_loss: 0.4993 - val_auc: 0.5498\n",
      "Epoch 12/12\n",
      "231/231 [==============================] - 130s 533ms/step - loss: 0.4979 - auc: 0.5555 - val_loss: 0.4993 - val_auc: 0.5500\n"
     ]
    }
   ],
   "source": [
    "mono_feature_models = {}\n",
    "for task_offer_feature in TASKS:\n",
    "    mono_feature_models[task_offer_feature] =\\\n",
    "        bi_linear_interaction_model([task_offer_feature], name=f'{task_offer_feature}_model')\n",
    "    mono_feature_models[task_offer_feature].fit(datasets['train'],\n",
    "                                                epochs=EPOCHS,\n",
    "                                                validation_data=datasets['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cc7d11-391a-4466-9bb5-bf9f2bbcc203",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb861dcc-1c7c-4a3e-be52-864c97543ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 30s, sys: 7.08 s, total: 1min 37s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from utils import prepare_single_task_dataset\n",
    "test_datasets = {}\n",
    "for task_offer_feature in TASKS:\n",
    "    test_datasets[task_offer_feature] = \\\n",
    "        prepare_single_task_dataset(datasets['test'], task_offer_feature, offer_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "644699ac-98a0-496d-8a76-afb73852bc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'actor', 'startYearCluster', 'userId', 'titleType', 'runtimeMinutesCluster', 'genre', 'director', 'actor_weight', 'startYearCluster_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'genre_weight', 'director_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'actor', 'startYearCluster', 'userId', 'titleType', 'runtimeMinutesCluster', 'genre', 'imdbId', 'actor_weight', 'startYearCluster_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'genre_weight', 'imdbId_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'actor', 'startYearCluster', 'userId', 'titleType', 'runtimeMinutesCluster', 'director', 'imdbId', 'actor_weight', 'startYearCluster_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'director_weight', 'imdbId_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'actor', 'startYearCluster', 'userId', 'titleType', 'runtimeMinutesCluster', 'genre', 'director', 'actor_weight', 'startYearCluster_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'genre_weight', 'director_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'actor', 'startYearCluster', 'userId', 'titleType', 'runtimeMinutesCluster', 'genre', 'imdbId', 'actor_weight', 'startYearCluster_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'genre_weight', 'imdbId_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'actor', 'startYearCluster', 'userId', 'titleType', 'runtimeMinutesCluster', 'director', 'imdbId', 'actor_weight', 'startYearCluster_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'director_weight', 'imdbId_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'actor', 'startYearCluster', 'userId', 'titleType', 'runtimeMinutesCluster', 'genre', 'director', 'actor_weight', 'startYearCluster_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'genre_weight', 'director_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'actor', 'startYearCluster', 'userId', 'titleType', 'runtimeMinutesCluster', 'genre', 'imdbId', 'actor_weight', 'startYearCluster_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'genre_weight', 'imdbId_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'actor', 'startYearCluster', 'userId', 'titleType', 'runtimeMinutesCluster', 'director', 'imdbId', 'actor_weight', 'startYearCluster_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'director_weight', 'imdbId_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 19s, sys: 3min 21s, total: 24min 41s\n",
      "Wall time: 5min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "from utils import evaluate_model\n",
    "\n",
    "aucs = defaultdict(dict)\n",
    "for task_offer_feature in TASKS:\n",
    "    kw = {'single_task_feature': task_offer_feature, 'test_datasets': test_datasets,\n",
    "          'number_of_negatives': NUMBER_OF_NEGATIVES, 'inverse_lookups': inverse_lookups}\n",
    "    \n",
    "    aucs[task_offer_feature]['group_by augmentations'] = evaluate_model(eval_model, **kw)\n",
    "    aucs[task_offer_feature]['without augmentations'] = evaluate_model(model_wo_augmentations, **kw)\n",
    "    \n",
    "    for model_name in TASKS:\n",
    "        aucs[task_offer_feature][f'MONO:{model_name}'] = evaluate_model(mono_feature_models[model_name], **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1b891e9-e60e-4578-9bbb-8d7bf0aaa7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_metrics\n",
    "save_metrics(aucs, DATASET, 'group_by_augmentations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b549c-6a9e-4233-b52c-2db953c99e07",
   "metadata": {},
   "source": [
    "## Aggregating results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46292f1f-5f4c-43ca-bd45-e9b6a2250e7c",
   "metadata": {},
   "source": [
    "### Popular offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f862e7c9-c599-408c-8572-d2f924a36806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import wAUC\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for task_name in aucs:\n",
    "    for model_name in aucs[task_name]:\n",
    "        w_auc = wAUC(aucs[task_name][model_name], cutoff_low=200)\n",
    "        results = pd.concat([results,\n",
    "                             pd.Series({'wAUC': w_auc, 'offers': task_name, 'model': model_name}).to_frame().T],\n",
    "                            ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec9ac730-c8f3-4a95-8102-a2551742f98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_938b5_row0_col0 {\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_938b5_row0_col1 {\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_938b5_row0_col2 {\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_938b5_row1_col0 {\n",
       "  background-color: #bb1b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_938b5_row1_col1 {\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_938b5_row1_col2, #T_938b5_row4_col0, #T_938b5_row4_col1 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_938b5_row2_col0, #T_938b5_row3_col1, #T_938b5_row4_col2 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_938b5_row2_col1 {\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_938b5_row2_col2 {\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_938b5_row3_col0 {\n",
       "  background-color: #ef886b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_938b5_row3_col2 {\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_938b5_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >offers</th>\n",
       "      <th class=\"col_heading level0 col0\" >film</th>\n",
       "      <th class=\"col_heading level0 col1\" >director</th>\n",
       "      <th class=\"col_heading level0 col2\" >genre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_938b5_level0_row0\" class=\"row_heading level0 row0\" >group_by augmentations</th>\n",
       "      <td id=\"T_938b5_row0_col0\" class=\"data row0 col0\" >0.608</td>\n",
       "      <td id=\"T_938b5_row0_col1\" class=\"data row0 col1\" >0.592</td>\n",
       "      <td id=\"T_938b5_row0_col2\" class=\"data row0 col2\" >0.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_938b5_level0_row1\" class=\"row_heading level0 row1\" >without augmentations</th>\n",
       "      <td id=\"T_938b5_row1_col0\" class=\"data row1 col0\" >0.610</td>\n",
       "      <td id=\"T_938b5_row1_col1\" class=\"data row1 col1\" >0.591</td>\n",
       "      <td id=\"T_938b5_row1_col2\" class=\"data row1 col2\" >0.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_938b5_level0_row2\" class=\"row_heading level0 row2\" >MONO:film</th>\n",
       "      <td id=\"T_938b5_row2_col0\" class=\"data row2 col0\" >0.612</td>\n",
       "      <td id=\"T_938b5_row2_col1\" class=\"data row2 col1\" >0.593</td>\n",
       "      <td id=\"T_938b5_row2_col2\" class=\"data row2 col2\" >0.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_938b5_level0_row3\" class=\"row_heading level0 row3\" >MONO:director</th>\n",
       "      <td id=\"T_938b5_row3_col0\" class=\"data row3 col0\" >0.594</td>\n",
       "      <td id=\"T_938b5_row3_col1\" class=\"data row3 col1\" >0.595</td>\n",
       "      <td id=\"T_938b5_row3_col2\" class=\"data row3 col2\" >0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_938b5_level0_row4\" class=\"row_heading level0 row4\" >MONO:genre</th>\n",
       "      <td id=\"T_938b5_row4_col0\" class=\"data row4 col0\" >0.524</td>\n",
       "      <td id=\"T_938b5_row4_col1\" class=\"data row4 col1\" >0.532</td>\n",
       "      <td id=\"T_938b5_row4_col2\" class=\"data row4 col2\" >0.558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f73c8340ca0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(results, 'wAUC', 'model', 'offers')\\\n",
    "    .rename(columns={'imdbId': 'film'}, index={'MONO:imdbId': 'MONO:film'})\\\n",
    "    .iloc[[3, 4, 2, 0, 1]][['film', 'director', 'genre']]\\\n",
    "    .style.background_gradient(cmap='coolwarm').format(precision=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom [moksha-tf2-cpu.2-7] (Local)",
   "language": "python",
   "name": "local-eu.gcr.io_tinyclues-experiments_tinyclues_moksha-tf2-cpu.2-7_latest__moksha"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
