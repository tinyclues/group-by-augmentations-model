{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edef15d4-49a3-40e3-82f1-2f1fd17c820d",
   "metadata": {},
   "source": [
    "# Training simple model and evalualing its predictions on different tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9113fe5b-43bd-4872-b416-86ef0ee54a02",
   "metadata": {},
   "source": [
    "## Prepare dataset for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac87ae1e-3893-4a7c-9bd7-5c84bbcc5259",
   "metadata": {},
   "source": [
    "First let's load splitted dataset generated in [another notebook](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/dataset_preprocessing/movielens%20with%20imdb.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "807a30be-3b5c-4ab5-9b83-877fadbc4528",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'movielens_imdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffcb1cef-b1d7-4f13-8c07-68b7cfdc8bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/recsys-multi-atrribute-benchmark/training/utils.py:26: load (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.load(...)` instead.\n"
     ]
    }
   ],
   "source": [
    "from utils import load_dataset\n",
    "\n",
    "datasets = {}\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    datasets[split_name] = load_dataset(DATASET, split_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529c9be2-9c71-4bfc-ba64-931c0b4294ec",
   "metadata": {},
   "source": [
    "We can parse features' names, they were chosen to easily distinguish between offer features (that will be used to modelize film) and user features (aggregated history up to chosen date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bacd6ec-088e-43f7-8741-f817389aeaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import AGG_PREFIX\n",
    "\n",
    "all_columns = list(datasets['train'].element_spec.keys())\n",
    "technical_columns = ['userId', 'date']\n",
    "user_features = list(filter(lambda x: x.startswith(AGG_PREFIX), all_columns))\n",
    "offer_features = list(filter(lambda x: x not in user_features + technical_columns, all_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e749c7c8-ccce-4996-9dbb-ddd4b30535f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aggregated_ratings_imdbId',\n",
       " 'aggregated_ratings_titleType',\n",
       " 'aggregated_ratings_genre',\n",
       " 'aggregated_ratings_runtimeMinutesCluster',\n",
       " 'aggregated_ratings_director',\n",
       " 'aggregated_ratings_actor',\n",
       " 'aggregated_ratings_startYearCluster']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fc16225-1bf0-42cd-96cc-dde804d0f8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['genre',\n",
       " 'actor',\n",
       " 'director',\n",
       " 'imdbId',\n",
       " 'titleType',\n",
       " 'runtimeMinutesCluster',\n",
       " 'startYearCluster']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offer_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb38696-3ad7-4edc-9331-663f031c11a9",
   "metadata": {},
   "source": [
    "### Rebatch dataset by events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993d1d8c-60a7-4e91-8507-a4d63aafff4e",
   "metadata": {},
   "source": [
    "First we will unnest events for each user (stored in second dimension of saved tensors) and keep only limited number of them. This operation will be needed further to avoid collisions during generation of negative examples. Then we will rebatch results into smaller batches (`50400` events for validation and test sets and `10080` events for train set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea02c22b-3128-4312-ac7e-eba7ba312b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "CPU times: user 40.6 s, sys: 6.18 s, total: 46.7 s\n",
      "Wall time: 34.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from functools import partial\n",
    "from uuid import uuid4\n",
    "\n",
    "from utils import rebatch_by_events\n",
    "\n",
    "datasets['train'] = rebatch_by_events(datasets['train'], batch_size=10080, date_column='date', nb_events_by_user_by_day=8)\n",
    "for key in ['val', 'test']:\n",
    "    datasets[key] = rebatch_by_events(datasets[key], batch_size=50400, date_column='date', nb_events_by_user_by_day=8,\n",
    "                                      seed=1729).cache(f'/tmp/{uuid4()}.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f438dd-88d2-4149-ba09-9bc776344d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10080"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch, y = next(iter(datasets['train']))\n",
    "train_batch['imdbId'].shape[0]  # check batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6267056-b152-448e-a905-515cf6780d4f",
   "metadata": {},
   "source": [
    "## Define simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5585ad1-6f31-4bee-ba40-d1aac2f9a625",
   "metadata": {},
   "source": [
    "Let's now define a simple model we want to test. Independetly from model's choice we need to embed inputs in some vectorial space. To define such embeddings we need number of different modalities inputs can take, and we can get this information from saved vectorizers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d690110-f133-4702-8533-8eb10e41b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_inverse_lookups\n",
    "inverse_lookups = load_inverse_lookups(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "488d715b-2447-4235-93ee-4297dc5954a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "vocabulary_sizes = {}\n",
    "\n",
    "for feature in offer_features:\n",
    "    vocabulary_sizes[feature] = inverse_lookups[feature].vocabulary_size()\n",
    "\n",
    "for feature in user_features:\n",
    "    for key in inverse_lookups:\n",
    "        pattern = re.compile(r\"{}(\\w+)_{}\".format(AGG_PREFIX, key))\n",
    "        if pattern.match(feature):\n",
    "            vocabulary_sizes[feature] = vocabulary_sizes[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ad366-26b9-4443-8a63-27008d154f79",
   "metadata": {},
   "source": [
    "Now `vocabulary_sizes` contains modality of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4276ac0a-6e6c-4ccc-b65e-f24c24eaf170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'genre': 36,\n",
       " 'actor': 2510,\n",
       " 'director': 3095,\n",
       " 'imdbId': 7894,\n",
       " 'titleType': 20,\n",
       " 'runtimeMinutesCluster': 35,\n",
       " 'startYearCluster': 40,\n",
       " 'aggregated_ratings_imdbId': 7894,\n",
       " 'aggregated_ratings_titleType': 20,\n",
       " 'aggregated_ratings_genre': 36,\n",
       " 'aggregated_ratings_runtimeMinutesCluster': 35,\n",
       " 'aggregated_ratings_director': 3095,\n",
       " 'aggregated_ratings_actor': 2510,\n",
       " 'aggregated_ratings_startYearCluster': 40}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a273a2-67d6-4bae-9c3b-282b64346329",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d62b8a31-60e9-4650-8509-652c2866b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f744f91-e1df-4aac-b450-44a425a4ee8e",
   "metadata": {},
   "source": [
    "For the benchmarks we want to do, model's architecture doesn't play a crucial role, we saw the same problems in any model that averages embeddings of offer features in a naive way. So let's take some simple model's architecture, for example collaborative filtering using two towers neural network:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692a7645-1ab1-441b-bb20-b4d2b0d42e20",
   "metadata": {},
   "source": [
    "<img src=\"resources/two_towers_model.png\" alt=\"two tower model\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f2bac6-852a-4c0a-ba11-e8984ae67ac9",
   "metadata": {},
   "source": [
    "### Model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028e0008-74ee-4c60-810c-39f4baa6c710",
   "metadata": {},
   "source": [
    "To choose model's parameters we did some manual tuning using validation set to maximize train and validation AUC while keeping mismatch between them small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f01a2a62-06e6-4758-94a5-5ba3ec5d4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# model parameters\n",
    "EMBEDDING_DIM = 100\n",
    "L1_COEFF = 8.5e-7\n",
    "DROPOUT = 0.17\n",
    "\n",
    "\n",
    "def REGULARIZER():\n",
    "    return {'class_name': 'L1L2', 'config': {'l1': L1_COEFF, 'l2': 0.}}\n",
    "\n",
    "def USER_TOWER():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(80,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Activation('tanh'),\n",
    "        tf.keras.layers.Dense(40,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Activation('tanh'),\n",
    "    ], name='user_tower')\n",
    "\n",
    "def OFFER_TOWER():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(80,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Activation('tanh'),\n",
    "        tf.keras.layers.Dense(40,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Activation('tanh'),\n",
    "    ], name='offer_tower')\n",
    "\n",
    "EPOCHS = 12\n",
    "\n",
    "NUMBER_OF_NEGATIVES = 4\n",
    "LOSS = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "AUC_METRIC = tf.keras.metrics.AUC(from_logits=True)\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "OPTIMIZER = tfa.optimizers.AdamW(weight_decay=8.5e-8, learning_rate=0.0008)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f825d2-88ca-41ad-8031-23a4e6fef17a",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d21f78f-2c0a-40b7-b356-6d6ebca614d0",
   "metadata": {},
   "source": [
    "Let's embed all available `user_features` and `offer_features` into vectorial space of dimension `EMBEDDING_DIM`. We use custom embeddings layer class `WeightedEmbeddings` that will automatically take a mean embedding vector when needed.\n",
    "\n",
    "In particular,\n",
    "* `user_features` are lists of attributes and we don't need to take into account any weights.\n",
    "* `offer_features` during the inference can contain lists of attributes because of aggregation. We will also pass weights explicitly during the inference\n",
    "* `offer_features` during training are lists with only one element, so we need to define dummy weights for training\n",
    "\n",
    "All three cases can be treated by the same layer, where we will define a sparse matrix of all attributes we want to embed and then multiply it by the dense matrix with embeddings, multiplying by weights at the same time (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "167b3d95-81c0-4edf-b0b3-46c6cc95fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import add_equal_weights\n",
    "\n",
    "for key in datasets:\n",
    "    datasets[key] = datasets[key].map(partial(add_equal_weights, features=offer_features))\n",
    "train_batch, y = next(iter(datasets['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d82771e6-24d3-479f-8abe-c93dbdcad8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0]]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy weights needed for training\n",
    "train_batch['genre_weight'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef6e1b98-5b4d-41ec-8413-92425dd63898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float32, numpy=\n",
       "array([[ 0.04494161, -0.01325916, -0.02227489,  0.03725203, -0.04359887],\n",
       "       [ 0.03168532,  0.00576754,  0.00114274,  0.02043159, -0.04843969],\n",
       "       [ 0.03831346, -0.00374581, -0.01056607,  0.02884181, -0.04601928]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeddings layer example\n",
    "from layers import WeightedEmbeddings\n",
    "example_layer = WeightedEmbeddings(3, 5, name='test')\n",
    "example_layer(tf.ragged.constant([[0], [1], [0, 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aa1e4c-0367-46c8-b85d-b7d5b1d302d5",
   "metadata": {},
   "source": [
    "Now we can define all embeddings layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07957c19-2b1b-457b-b17d-c9d21e37316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import get_input_layer, WeightedEmbeddings\n",
    "from utils import WEIGHT_SUFFIX\n",
    "\n",
    "embeddings, inputs = {}, {}\n",
    "for feature in user_features + offer_features:\n",
    "    if feature in offer_features:\n",
    "        # for offer features we need weights:\n",
    "        # with dummy weights during training, and the ones used for a feature's averaging at inference time\n",
    "        inputs[f'{feature}{WEIGHT_SUFFIX}'] = get_input_layer(f'{feature}{WEIGHT_SUFFIX}', tf.float32)\n",
    "    inputs[feature] = get_input_layer(feature)\n",
    "    # here we use input feature modality from `vocabulary_sizes` to know embeddings matrix dimensions\n",
    "    emb_layer = WeightedEmbeddings(vocabulary_sizes[feature],\n",
    "                                   EMBEDDING_DIM, name=f'{feature}_embedding',\n",
    "                                   embeddings_regularizer=REGULARIZER())\n",
    "    embeddings[feature] = emb_layer(inputs[feature], inputs.get(f'{feature}{WEIGHT_SUFFIX}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13375747-17f8-42cd-ba11-172bc209878a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aggregated_ratings_imdbId': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'aggregated_ratings_imdbId_embedding')>,\n",
       " 'aggregated_ratings_titleType': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'aggregated_ratings_titleType_embedding')>,\n",
       " 'aggregated_ratings_genre': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'aggregated_ratings_genre_embedding')>,\n",
       " 'aggregated_ratings_runtimeMinutesCluster': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'aggregated_ratings_runtimeMinutesCluster_embedding')>,\n",
       " 'aggregated_ratings_director': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'aggregated_ratings_director_embedding')>,\n",
       " 'aggregated_ratings_actor': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'aggregated_ratings_actor_embedding')>,\n",
       " 'aggregated_ratings_startYearCluster': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'aggregated_ratings_startYearCluster_embedding')>,\n",
       " 'genre': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'genre_embedding')>,\n",
       " 'actor': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'actor_embedding')>,\n",
       " 'director': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'director_embedding')>,\n",
       " 'imdbId': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'imdbId_embedding')>,\n",
       " 'titleType': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'titleType_embedding')>,\n",
       " 'runtimeMinutesCluster': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'runtimeMinutesCluster_embedding')>,\n",
       " 'startYearCluster': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'startYearCluster_embedding')>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5698ee88-50ff-4250-af07-c27eebe2a665",
   "metadata": {},
   "source": [
    "### Combining everything into model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267636cc-9a2e-469f-9ea7-d259ec05361c",
   "metadata": {},
   "source": [
    "Now we can define described model architecture on the top of embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69ab9aa4-9e45-4cbb-a659-7d6688546d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_user_features = [embeddings[feature] for feature in user_features]\n",
    "embedded_offer_features = [embeddings[feature] for feature in offer_features]\n",
    "user_tower = USER_TOWER()(tf.keras.layers.Concatenate(name='concat_user')(embedded_user_features))\n",
    "offer_tower = OFFER_TOWER()(tf.keras.layers.Concatenate(name='concat_offer')(embedded_offer_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3739f61-7e24-4d05-be34-18edec538267",
   "metadata": {},
   "source": [
    "### Negative generation in mini-batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfe350c-3fb8-4e39-901e-431214d10d60",
   "metadata": {},
   "source": [
    "As our dataset contains only positive examples, up to this point we used only them. We have different choices of how to choose negative examples, but we chose most optimal one for calculations (both in memory and time) - we will generate negatives at the same time as calculating interactions between user and offer embeddings, proceding in minibatches:\n",
    "* let's fix a number `N - 1` of how many negative examples we want to generate for each positive one\n",
    "* consider minibatches of size `N` with events done on the same (or close) date (this was ensured by batch construction above), so we will get negative example from the actions on the same date as the positive one, similar to [Contrastive Predictive Coding](https://arxiv.org/abs/1807.03748) method.\n",
    "* inside each minibatch we have users `u1, u2, ..., uN` who rated films `f1, f2, ..., fN` respectively on the same date `d`\n",
    "* let's consider all possible pairs `(u1, f1), (u1, f2), ..., (uN, fN)` (`N ** 2` pairs in total)\n",
    "* among those pairs there are `N` positive examples, all other `N(N - 1)` pairs are considered as negative ones\n",
    "* it gives us exactly `N - 1` negative examples for each from `N` positive ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ecf1a5-e57e-408b-b30e-ad32d3b2356d",
   "metadata": {},
   "source": [
    "We pair this process with interaction calculation by calculating not only scalar products between positive pairs, but between all `N ** 2` pairs per minibatch. Such operation can be written as multiplication of tensors, keeping number of embeddings calculations fixed (`2 * N` for each minibatch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82a36d9c-4e5a-4f61-afcc-610ecf4504e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotWithNegatives(tf.keras.layers.Layer):\n",
    "    def __init__(self, number_of_negatives, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.number_of_negatives = number_of_negatives\n",
    "        \n",
    "    def call(self, inputs, generate_negatives):\n",
    "        user_embeddings, offer_embeddings = inputs\n",
    "        if generate_negatives:\n",
    "            # here we will generate negative examples inside mini-batches\n",
    "            batch_size = tf.shape(user_embeddings)[0]\n",
    "            # we split original batch into mini-batches of size (number_of_negatives + 1)\n",
    "            minibatch_shape = (batch_size // (self.number_of_negatives + 1), (self.number_of_negatives + 1), -1)\n",
    "            user_embeddings = tf.reshape(user_embeddings, minibatch_shape)\n",
    "            offer_embeddings = tf.reshape(offer_embeddings, minibatch_shape)\n",
    "            # for each pair of lines i,j inside minibatch, we consider pairs user/offer\n",
    "            # * as positive examples when i==j\n",
    "            # * as negative examples otherwise\n",
    "            # at the end we flatten mini-batch dimension and obtain batch_size * (number_of_negatives + 1) predictions\n",
    "            res = tf.einsum('bid,bjd->bij', user_embeddings, offer_embeddings)\n",
    "        else:\n",
    "            # otherwise we do just scalar product, let's write it in einsum notation too to see a difference between two\n",
    "            res = tf.einsum('bd,bd->b', user_embeddings, offer_embeddings)\n",
    "        return tf.reshape(res, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5cee96b-5095-4635-863c-bb6be416a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't apply sigmoid on the output and will have from_logits=True in both loss and metrics\n",
    "output = DotWithNegatives(NUMBER_OF_NEGATIVES, name='prediction')([user_tower, offer_tower], generate_negatives=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e77d19f-e3df-4244-b689-feee5db9b6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'prediction')>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d22722-8de8-4093-a46b-cd7fe4553af7",
   "metadata": {},
   "source": [
    "Now our labels from batch are not aligned with output we produce, to get positive/negative labels at needed positions we just need to find which index would correspond to which label when considering a minibatch. This logic is implemented in auxilary classes `BroadcastLoss` and `BroadcastMetric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53c2d19a-acd9-4fd8-9bcf-a9865f65bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import BroadcastLoss, BroadcastMetric\n",
    "\n",
    "model = tf.keras.Model(inputs, output, name='two_tower_model')\n",
    "model.compile(optimizer=OPTIMIZER,\n",
    "              loss=BroadcastLoss(LOSS, NUMBER_OF_NEGATIVES),\n",
    "              metrics=[BroadcastMetric(AUC_METRIC, NUMBER_OF_NEGATIVES)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc3fa47b-2ac2-40b1-aa26-e8cc56fab46b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, to_file=f'models/{DATASET}_simple_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237702cb-fa87-45dc-8966-020cf9bf2515",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a77a6113-ba67-4ba0-a762-20d4c14272db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 141s 396ms/step - loss: 0.5597 - auc: 0.5648 - val_loss: 0.5736 - val_auc: 0.5315\n",
      "Epoch 2/12\n",
      "231/231 [==============================] - 87s 343ms/step - loss: 0.5079 - auc: 0.6202 - val_loss: 0.5386 - val_auc: 0.6108\n",
      "Epoch 3/12\n",
      "231/231 [==============================] - 91s 359ms/step - loss: 0.4993 - auc: 0.6281 - val_loss: 0.5077 - val_auc: 0.6342\n",
      "Epoch 4/12\n",
      "231/231 [==============================] - 91s 366ms/step - loss: 0.4957 - auc: 0.6318 - val_loss: 0.4966 - val_auc: 0.6373\n",
      "Epoch 5/12\n",
      "231/231 [==============================] - 88s 349ms/step - loss: 0.4934 - auc: 0.6341 - val_loss: 0.4945 - val_auc: 0.6379\n",
      "Epoch 6/12\n",
      "231/231 [==============================] - 88s 345ms/step - loss: 0.4915 - auc: 0.6363 - val_loss: 0.4929 - val_auc: 0.6393\n",
      "Epoch 7/12\n",
      "231/231 [==============================] - 84s 331ms/step - loss: 0.4900 - auc: 0.6381 - val_loss: 0.4927 - val_auc: 0.6387\n",
      "Epoch 8/12\n",
      "231/231 [==============================] - 87s 340ms/step - loss: 0.4886 - auc: 0.6396 - val_loss: 0.4895 - val_auc: 0.6409\n",
      "Epoch 9/12\n",
      "231/231 [==============================] - 92s 362ms/step - loss: 0.4872 - auc: 0.6413 - val_loss: 0.4886 - val_auc: 0.6412\n",
      "Epoch 10/12\n",
      "231/231 [==============================] - 89s 362ms/step - loss: 0.4861 - auc: 0.6425 - val_loss: 0.4874 - val_auc: 0.6419\n",
      "Epoch 11/12\n",
      "231/231 [==============================] - 84s 331ms/step - loss: 0.4851 - auc: 0.6438 - val_loss: 0.4866 - val_auc: 0.6423\n",
      "Epoch 12/12\n",
      "231/231 [==============================] - 73s 283ms/step - loss: 0.4843 - auc: 0.6446 - val_loss: 0.4866 - val_auc: 0.6421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd2a80f89a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datasets['train'], epochs=EPOCHS, validation_data=datasets['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7595399-bced-44ae-bbf6-05f2534141fd",
   "metadata": {},
   "source": [
    "## Single task models benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910110b3-f9b1-4663-80b9-d303ebc97359",
   "metadata": {},
   "source": [
    "As described in (TODO link to article) we can consider predictions on one chosen offer column as a single task and the whole setup as a multi-task problem. Let's now evaluate performance of a common model on a subset of tasks. We will compare its results against single task models sharing the same architecture, but using only one offer feature at time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6669fc5c-fa01-4e50-95e9-c4bbd66eb10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# offer columns we want to evaluate, specific to dataset we test\n",
    "TASKS = ['imdbId', 'director', 'genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05482dc-6ce3-47f0-8c5f-d9d25a0ecb3c",
   "metadata": {},
   "source": [
    "For simplicity of further code, let's wrap whole model definition into a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a45e96a-b5fe-4ad2-a20b-a3aad3773571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_tower_model(offer_features, name='two_tower_model'):\n",
    "    # user_features, vocabulary_sizes, EMBEDDING_DIM, REGULARIZER, USER_TOWER, OFFER_TOWER,\n",
    "    # OPTIMIZER, LOSS, NUMBER_OF_NEGATIVES\n",
    "    # come from global scope, but can be passed as params instead\n",
    "    embeddings, inputs = {}, {}\n",
    "    for feature in user_features + offer_features:\n",
    "        if feature in offer_features:\n",
    "            # for offer features we need weights:\n",
    "            # with dummy weights during training, and the ones used for a feature's averaging at inference time\n",
    "            inputs[f'{feature}{WEIGHT_SUFFIX}'] = get_input_layer(f'{feature}{WEIGHT_SUFFIX}', tf.float32)\n",
    "        inputs[feature] = get_input_layer(feature)\n",
    "        # here we use input feature modality from `vocabulary_sizes` to know embeddings matrix dimensions\n",
    "        emb_layer = WeightedEmbeddings(vocabulary_sizes[feature],\n",
    "                                       EMBEDDING_DIM, name=f'{feature}_embedding',\n",
    "                                       embeddings_regularizer=REGULARIZER())\n",
    "        embeddings[feature] = emb_layer(inputs[feature], inputs.get(f'{feature}{WEIGHT_SUFFIX}'))\n",
    "    \n",
    "    embedded_user_features = [embeddings[feature] for feature in user_features]\n",
    "    embedded_offer_features = [embeddings[feature] for feature in offer_features]\n",
    "    user_tower = USER_TOWER()(tf.keras.layers.Concatenate(name='concat_user')(embedded_user_features))\n",
    "    offer_tower = OFFER_TOWER()(tf.keras.layers.Concatenate(name='concat_offer')(embedded_offer_features))\n",
    "    \n",
    "    output = DotWithNegatives(NUMBER_OF_NEGATIVES, name='prediction')([user_tower, offer_tower], generate_negatives=True)\n",
    "    model = tf.keras.Model(inputs, output, name=name)\n",
    "    model.compile(optimizer=OPTIMIZER,\n",
    "                  loss=BroadcastLoss(LOSS, NUMBER_OF_NEGATIVES),\n",
    "                  metrics=[BroadcastMetric(AUC_METRIC, NUMBER_OF_NEGATIVES)])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191a9dca-20e1-4bda-9f32-0fe31f1cca5b",
   "metadata": {},
   "source": [
    "We train models that use only one offer feature with same hyperparameters as the initial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "984349ef-6d9a-4e99-9711-5c0a33bc3a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['genre', 'actor', 'date', 'director', 'userId', 'titleType', 'runtimeMinutesCluster', 'startYearCluster', 'genre_weight', 'actor_weight', 'director_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 98s 305ms/step - loss: 0.5340 - auc: 0.5744 - val_loss: 0.5319 - val_auc: 0.5305\n",
      "Epoch 2/12\n",
      "231/231 [==============================] - 69s 268ms/step - loss: 0.5014 - auc: 0.6170 - val_loss: 0.5224 - val_auc: 0.6040\n",
      "Epoch 3/12\n",
      "231/231 [==============================] - 69s 269ms/step - loss: 0.4965 - auc: 0.6239 - val_loss: 0.5015 - val_auc: 0.6262\n",
      "Epoch 4/12\n",
      "231/231 [==============================] - 70s 274ms/step - loss: 0.4934 - auc: 0.6293 - val_loss: 0.4932 - val_auc: 0.6319\n",
      "Epoch 5/12\n",
      "231/231 [==============================] - 70s 277ms/step - loss: 0.4912 - auc: 0.6333 - val_loss: 0.4909 - val_auc: 0.6339\n",
      "Epoch 6/12\n",
      "231/231 [==============================] - 70s 276ms/step - loss: 0.4895 - auc: 0.6358 - val_loss: 0.4900 - val_auc: 0.6351\n",
      "Epoch 7/12\n",
      "231/231 [==============================] - 70s 274ms/step - loss: 0.4880 - auc: 0.6379 - val_loss: 0.4884 - val_auc: 0.6368\n",
      "Epoch 8/12\n",
      "231/231 [==============================] - 71s 276ms/step - loss: 0.4868 - auc: 0.6397 - val_loss: 0.4873 - val_auc: 0.6380\n",
      "Epoch 9/12\n",
      "231/231 [==============================] - 70s 272ms/step - loss: 0.4858 - auc: 0.6409 - val_loss: 0.4866 - val_auc: 0.6388\n",
      "Epoch 10/12\n",
      "231/231 [==============================] - 71s 275ms/step - loss: 0.4848 - auc: 0.6428 - val_loss: 0.4862 - val_auc: 0.6396\n",
      "Epoch 11/12\n",
      "231/231 [==============================] - 67s 257ms/step - loss: 0.4840 - auc: 0.6440 - val_loss: 0.4852 - val_auc: 0.6400\n",
      "Epoch 12/12\n",
      "231/231 [==============================] - 70s 279ms/step - loss: 0.4835 - auc: 0.6448 - val_loss: 0.4854 - val_auc: 0.6401\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['genre', 'actor', 'date', 'imdbId', 'userId', 'titleType', 'runtimeMinutesCluster', 'startYearCluster', 'genre_weight', 'actor_weight', 'imdbId_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 96s 320ms/step - loss: 0.5266 - auc: 0.5685 - val_loss: 0.5231 - val_auc: 0.5166\n",
      "Epoch 2/12\n",
      "231/231 [==============================] - 72s 283ms/step - loss: 0.5006 - auc: 0.5987 - val_loss: 0.5149 - val_auc: 0.5763\n",
      "Epoch 3/12\n",
      "231/231 [==============================] - 71s 284ms/step - loss: 0.4974 - auc: 0.6034 - val_loss: 0.5015 - val_auc: 0.6094\n",
      "Epoch 4/12\n",
      "231/231 [==============================] - 71s 277ms/step - loss: 0.4956 - auc: 0.6062 - val_loss: 0.4955 - val_auc: 0.6119\n",
      "Epoch 5/12\n",
      "231/231 [==============================] - 71s 276ms/step - loss: 0.4942 - auc: 0.6084 - val_loss: 0.4948 - val_auc: 0.6123\n",
      "Epoch 6/12\n",
      "231/231 [==============================] - 71s 275ms/step - loss: 0.4931 - auc: 0.6099 - val_loss: 0.4933 - val_auc: 0.6139\n",
      "Epoch 7/12\n",
      "231/231 [==============================] - 70s 275ms/step - loss: 0.4920 - auc: 0.6118 - val_loss: 0.4924 - val_auc: 0.6147\n",
      "Epoch 8/12\n",
      "231/231 [==============================] - 71s 279ms/step - loss: 0.4913 - auc: 0.6130 - val_loss: 0.4922 - val_auc: 0.6153\n",
      "Epoch 9/12\n",
      "231/231 [==============================] - 70s 273ms/step - loss: 0.4906 - auc: 0.6143 - val_loss: 0.4914 - val_auc: 0.6159\n",
      "Epoch 10/12\n",
      "231/231 [==============================] - 69s 265ms/step - loss: 0.4901 - auc: 0.6149 - val_loss: 0.4911 - val_auc: 0.6163\n",
      "Epoch 11/12\n",
      "231/231 [==============================] - 68s 271ms/step - loss: 0.4896 - auc: 0.6155 - val_loss: 0.4901 - val_auc: 0.6169\n",
      "Epoch 12/12\n",
      "231/231 [==============================] - 68s 264ms/step - loss: 0.4891 - auc: 0.6166 - val_loss: 0.4894 - val_auc: 0.6172\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['actor', 'date', 'director', 'imdbId', 'userId', 'titleType', 'runtimeMinutesCluster', 'startYearCluster', 'actor_weight', 'director_weight', 'imdbId_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 101s 323ms/step - loss: 0.5341 - auc: 0.5259 - val_loss: 0.5078 - val_auc: 0.5041\n",
      "Epoch 2/12\n",
      "231/231 [==============================] - 71s 278ms/step - loss: 0.5083 - auc: 0.5289 - val_loss: 0.5054 - val_auc: 0.5200\n",
      "Epoch 3/12\n",
      "231/231 [==============================] - 71s 276ms/step - loss: 0.5062 - auc: 0.5313 - val_loss: 0.5038 - val_auc: 0.5435\n",
      "Epoch 4/12\n",
      "231/231 [==============================] - 71s 278ms/step - loss: 0.5053 - auc: 0.5321 - val_loss: 0.5032 - val_auc: 0.5444\n",
      "Epoch 5/12\n",
      "231/231 [==============================] - 74s 289ms/step - loss: 0.5046 - auc: 0.5333 - val_loss: 0.5032 - val_auc: 0.5450\n",
      "Epoch 6/12\n",
      "231/231 [==============================] - 71s 275ms/step - loss: 0.5041 - auc: 0.5337 - val_loss: 0.5027 - val_auc: 0.5456\n",
      "Epoch 7/12\n",
      "231/231 [==============================] - 70s 274ms/step - loss: 0.5037 - auc: 0.5346 - val_loss: 0.5022 - val_auc: 0.5456\n",
      "Epoch 8/12\n",
      "231/231 [==============================] - 73s 286ms/step - loss: 0.5032 - auc: 0.5351 - val_loss: 0.5018 - val_auc: 0.5466\n",
      "Epoch 9/12\n",
      "231/231 [==============================] - 74s 289ms/step - loss: 0.5028 - auc: 0.5357 - val_loss: 0.5019 - val_auc: 0.5464\n",
      "Epoch 10/12\n",
      "231/231 [==============================] - 59s 229ms/step - loss: 0.5025 - auc: 0.5361 - val_loss: 0.5017 - val_auc: 0.5464\n",
      "Epoch 11/12\n",
      "231/231 [==============================] - 57s 224ms/step - loss: 0.5022 - auc: 0.5367 - val_loss: 0.5014 - val_auc: 0.5463\n",
      "Epoch 12/12\n",
      "231/231 [==============================] - 57s 221ms/step - loss: 0.5020 - auc: 0.5370 - val_loss: 0.5011 - val_auc: 0.5473\n"
     ]
    }
   ],
   "source": [
    "mono_feature_models = {}\n",
    "for task_offer_feature in TASKS:\n",
    "    mono_feature_models[task_offer_feature] = two_tower_model([task_offer_feature],\n",
    "                                                              name=f'{task_offer_feature}_model')\n",
    "    mono_feature_models[task_offer_feature].fit(datasets['train'],\n",
    "                                                epochs=EPOCHS,\n",
    "                                                validation_data=datasets['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e416a20a-7564-44a1-812d-6c9b1ca29b02",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95506c1c-1d7e-41b2-b4d9-7e46d9c59e79",
   "metadata": {},
   "source": [
    "Now let's generate some offers from test dataset:\n",
    "* we will consider all batches from test dataset\n",
    "* we perform a group by using each feature from `TASKS` as a group by key\n",
    "* for all offer features except the one we are using as key we generate ragged tensors with bag of values it can take\n",
    "* we remove least popular values in each list\n",
    "* so now each line of dataset corresponds to an offer of type `task_offer_feature = 'value'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1aa2ddd9-efcc-4d32-9ff7-81eb033a9faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 55s, sys: 8.03 s, total: 2min 3s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from utils import prepare_single_task_dataset\n",
    "test_datasets = {}\n",
    "for task_offer_feature in TASKS:\n",
    "    test_datasets[task_offer_feature] = \\\n",
    "        prepare_single_task_dataset(datasets['test'], task_offer_feature, offer_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e37e8cc-2b65-4654-afdc-7da7ee11fbf7",
   "metadata": {},
   "source": [
    "Test dataset for a given task keeps a column used for group by as is, but other offer columns become lists (to encode bag of values) and we need to average embeddings for them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9e5e18d-fde0-4684-80ba-6cf637a81e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch, y = next(iter(test_datasets['genre']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d84f438f-4526-4132-aa9f-9c15dca33bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[10],\n",
       " [10],\n",
       " [14],\n",
       " [14],\n",
       " [11]]>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch['genre'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de9c840f-fb0d-4dad-b50e-6359ee31f947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0]]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch['genre_weight'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "232acc42-8751-449a-894f-7f8c4c1a7447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[312, 0, 546, 790, 903, 835, 513, 786, 537, 321, 298, 842, 7, 773, 548,\n",
       "  318, 655, 310, 924, 155, 562, 659, 2, 387, 455, 217, 613, 615, 512, 232,\n",
       "  889, 225, 483, 358, 436, 274, 471, 493, 698, 438, 177, 108, 473, 488,\n",
       "  491, 111, 6, 269, 42, 253, 348, 774, 534, 5, 9, 77, 8, 575, 245, 516,\n",
       "  399, 349, 341, 775, 442, 467, 541, 472, 84, 634, 416, 139, 418, 377,\n",
       "  452, 18, 660, 439, 409, 417, 432, 601, 644, 226, 408, 664, 268, 291,\n",
       "  480, 376, 243, 476, 23, 517, 113, 629, 170, 670, 197, 362, 48, 230, 271,\n",
       "  124, 440, 121, 214, 328, 167, 391, 149, 371, 375, 344, 252, 627, 313,\n",
       "  431, 286, 583, 169, 98, 277, 174, 370, 258, 293, 165, 482, 330, 294,\n",
       "  244, 285, 218, 396, 289, 228, 381, 237, 554, 107, 411, 148, 306, 205,\n",
       "  130, 47, 203, 194, 337, 254, 105, 208, 216, 128, 182, 92, 403, 199, 248,\n",
       "  150, 275, 173, 406, 247, 260, 372, 212, 320, 16, 93, 355, 202, 240, 272,\n",
       "  120, 331, 82, 131, 44, 129, 55, 184, 196, 96, 156, 235, 397, 266, 24,\n",
       "  134, 211, 163, 160, 181, 32, 249, 142, 30, 94, 127, 14, 123, 284, 151,\n",
       "  68, 189, 118, 59, 65, 80, 125, 112, 117, 37, 187, 137, 106, 38, 97, 62,\n",
       "  135, 61, 87, 69, 109, 119, 19, 104, 116, 101, 36, 72, 78, 15, 39, 58,\n",
       "  41, 26, 20, 40, 25, 17, 21, 50, 11, 27, 12, 10, 22]]>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch['director'][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9bb8c63b-a6fb-42a1-af9c-8e937ce70ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[0.00089855335, 0.00089855335, 0.00089855335, 0.00089855335,\n",
       "  0.00089855335, 0.00089855335, 0.00092101714, 0.00092101714, 0.000943481,\n",
       "  0.000943481, 0.000943481, 0.000943481, 0.00096594484, 0.00096594484,\n",
       "  0.0009884087, 0.0009884087, 0.0010108725, 0.0010108725, 0.0010108725,\n",
       "  0.0010108725, 0.0010333363, 0.0010333363, 0.0010558001, 0.0010558001,\n",
       "  0.0010558001, 0.0010558001, 0.0010558001, 0.0010558001, 0.001078264,\n",
       "  0.001078264, 0.001078264, 0.0011007278, 0.0011007278, 0.0011007278,\n",
       "  0.0011231917, 0.0011231917, 0.0011231917, 0.0011231917, 0.0011231917,\n",
       "  0.0011456555, 0.0011456555, 0.0011456555, 0.0011456555, 0.0011456555,\n",
       "  0.0011456555, 0.0011681194, 0.0011905831, 0.0011905831, 0.0011905831,\n",
       "  0.001213047, 0.001213047, 0.0012355108, 0.0012579747, 0.0012579747,\n",
       "  0.0012804385, 0.0013029024, 0.0013029024, 0.0013029024, 0.0013253662,\n",
       "  0.0013253662, 0.0013253662, 0.0013253662, 0.0013253662, 0.0013253662,\n",
       "  0.0013478299, 0.0013702938, 0.0013702938, 0.0013702938, 0.0013927576,\n",
       "  0.0014152215, 0.0014376853, 0.0014376853, 0.0014376853, 0.0014601492,\n",
       "  0.001482613, 0.0015050768, 0.0015050768, 0.0015050768, 0.0015050768,\n",
       "  0.0015275406, 0.0015275406, 0.0015275406, 0.0015275406, 0.0015500045,\n",
       "  0.0015500045, 0.0015500045, 0.0015724683, 0.0015724683, 0.0015724683,\n",
       "  0.0015724683, 0.001617396, 0.0016398599, 0.0016398599, 0.0016398599,\n",
       "  0.0016623237, 0.0016623237, 0.0016847875, 0.0016847875, 0.0017297151,\n",
       "  0.001752179, 0.001752179, 0.001752179, 0.001752179, 0.0017746428,\n",
       "  0.0017971067, 0.0018195705, 0.0018195705, 0.0018195705, 0.0018195705,\n",
       "  0.0018644981, 0.0018644981, 0.001886962, 0.001886962, 0.001886962,\n",
       "  0.0019094258, 0.0019094258, 0.0019768174, 0.0019768174, 0.002021745,\n",
       "  0.002021745, 0.0020442088, 0.0020442088, 0.0020666725, 0.0020891365,\n",
       "  0.002156528, 0.0022014556, 0.0022014556, 0.0022014556, 0.0022239194,\n",
       "  0.0022463833, 0.0022463833, 0.0022463833, 0.002291311, 0.002291311,\n",
       "  0.0023137748, 0.0023362387, 0.0023587025, 0.0023587025, 0.0024036302,\n",
       "  0.0024485579, 0.0024710216, 0.0024934856, 0.002560877, 0.0026058047,\n",
       "  0.0026282684, 0.0026507324, 0.0026507324, 0.0026507324, 0.0027181238,\n",
       "  0.0027630515, 0.0027630515, 0.0027855153, 0.0027855153, 0.0027855153,\n",
       "  0.002942762, 0.0030775452, 0.0030775452, 0.003100009, 0.003122473,\n",
       "  0.0031449366, 0.0031674004, 0.0031898643, 0.0031898643, 0.0031898643,\n",
       "  0.003234792, 0.003234792, 0.0033246474, 0.0034145026, 0.003504358,\n",
       "  0.0035268217, 0.0035717494, 0.0035942134, 0.0037065325, 0.0037289963,\n",
       "  0.0037514602, 0.003773924, 0.003773924, 0.003796388, 0.0038413154,\n",
       "  0.003908707, 0.003908707, 0.0039536348, 0.004021026, 0.004021026,\n",
       "  0.0040884176, 0.004178273, 0.004178273, 0.004200737, 0.0042232005,\n",
       "  0.00433552, 0.0044253753, 0.0044927667, 0.0045152307, 0.004537694,\n",
       "  0.0049195793, 0.0049195793, 0.0049195793, 0.005121754, 0.005301465,\n",
       "  0.005301465, 0.0053688562, 0.005503639, 0.005526103, 0.0055934945,\n",
       "  0.0057732053, 0.0059753796, 0.0059978436, 0.006087699, 0.006200018,\n",
       "  0.00644712, 0.006604367, 0.006626831, 0.006626831, 0.006873933,\n",
       "  0.0069637885, 0.007143499, 0.0073232097, 0.0074579925, 0.007547848,\n",
       "  0.007997124, 0.00855872, 0.008985533, 0.009030461, 0.009052925,\n",
       "  0.009502201, 0.009636984, 0.0102210445, 0.0103108995, 0.010850032,\n",
       "  0.010872495, 0.011097133, 0.011658729, 0.011658729, 0.011771048,\n",
       "  0.011928296, 0.012242789, 0.012287716, 0.013118879, 0.013253662,\n",
       "  0.013882649, 0.014511636, 0.015073232, 0.01722976, 0.018083386,\n",
       "  0.019251505, 0.026125439, 0.026934136, 0.028933417, 0.030213855,\n",
       "  0.030483421]]>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch['director_weight'][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb43883-2574-41a2-8b3f-287800b250aa",
   "metadata": {},
   "source": [
    "Now we can apply model on grouped features for each task and calculate AUC for each offer of type `task_offer_feature = 'value'`. Note, that negatives are generated in the same way as for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0966f43-5ea6-4291-9fc8-5b48375da541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['genre', 'actor', 'date', 'imdbId', 'userId', 'titleType', 'runtimeMinutesCluster', 'startYearCluster', 'genre_weight', 'actor_weight', 'imdbId_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['actor', 'date', 'director', 'imdbId', 'userId', 'titleType', 'runtimeMinutesCluster', 'startYearCluster', 'actor_weight', 'director_weight', 'imdbId_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['genre', 'actor', 'date', 'director', 'userId', 'titleType', 'runtimeMinutesCluster', 'startYearCluster', 'genre_weight', 'actor_weight', 'director_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['genre', 'actor', 'date', 'imdbId', 'userId', 'titleType', 'runtimeMinutesCluster', 'startYearCluster', 'genre_weight', 'actor_weight', 'imdbId_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['actor', 'date', 'director', 'imdbId', 'userId', 'titleType', 'runtimeMinutesCluster', 'startYearCluster', 'actor_weight', 'director_weight', 'imdbId_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['genre', 'actor', 'date', 'director', 'userId', 'titleType', 'runtimeMinutesCluster', 'startYearCluster', 'genre_weight', 'actor_weight', 'director_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['genre', 'actor', 'date', 'imdbId', 'userId', 'titleType', 'runtimeMinutesCluster', 'startYearCluster', 'genre_weight', 'actor_weight', 'imdbId_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['actor', 'date', 'director', 'imdbId', 'userId', 'titleType', 'runtimeMinutesCluster', 'startYearCluster', 'actor_weight', 'director_weight', 'imdbId_weight', 'titleType_weight', 'runtimeMinutesCluster_weight', 'startYearCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 32s, sys: 1min 28s, total: 14min 1s\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "from utils import evaluate_model, wAUC\n",
    "\n",
    "aucs = defaultdict(dict)\n",
    "for task_offer_feature in TASKS:\n",
    "    for model_name in TASKS:\n",
    "        aucs[task_offer_feature][f'MONO:{model_name}'] = \\\n",
    "            evaluate_model(mono_feature_models[model_name],\n",
    "                           task_offer_feature, test_datasets, NUMBER_OF_NEGATIVES, inverse_lookups)\n",
    "    aucs[task_offer_feature]['simple model'] = \\\n",
    "            evaluate_model(model, task_offer_feature, test_datasets, NUMBER_OF_NEGATIVES, inverse_lookups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "816487f0-5070-475c-ae5e-f0582f62f3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>name</th>\n",
       "      <th>number of events</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.661372</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.624429</td>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.556605</td>\n",
       "      <td>The Silence of the Lambs</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.573551</td>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.602212</td>\n",
       "      <td>Star Wars: Episode IV - A New Hope</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                auc                                name  number of events\n",
       "group_idx                                                                \n",
       "10         0.661372            The Shawshank Redemption              1183\n",
       "11         0.624429                        Pulp Fiction              1052\n",
       "12         0.556605            The Silence of the Lambs               979\n",
       "13         0.573551                        Forrest Gump               928\n",
       "14         0.602212  Star Wars: Episode IV - A New Hope               787"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs['imdbId']['MONO:imdbId'][10:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a374dd80-b0dc-4905-903c-84b72735777c",
   "metadata": {},
   "source": [
    "We can aggregate AUCs from individual offers to have one value we can compare among models: weighted macro AUC. We will keep only offers with more than 200 positive events and weight their AUCs by number of events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dbdf4194-a2fc-4c89-a524-4dda2905ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.DataFrame()\n",
    "for task_name in aucs:\n",
    "    for model_name in aucs[task_name]:\n",
    "        w_auc = wAUC(aucs[task_name][model_name])\n",
    "        results = pd.concat([results,\n",
    "                             pd.Series({'wAUC': w_auc, 'offers': task_name, 'model': model_name}).to_frame().T],\n",
    "                            ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "869761a6-12d2-4364-9962-c0fa902e18f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_553c7_row0_col0, #T_553c7_row2_col0 {\n",
       "  background-color: #b8122a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_553c7_row0_col1 {\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_553c7_row0_col2 {\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_553c7_row1_col0, #T_553c7_row1_col2, #T_553c7_row2_col1 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_553c7_row1_col1, #T_553c7_row3_col0, #T_553c7_row3_col2 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_553c7_row2_col2 {\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_553c7_row3_col1 {\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_553c7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >offers</th>\n",
       "      <th id=\"T_553c7_level0_col0\" class=\"col_heading level0 col0\" >director</th>\n",
       "      <th id=\"T_553c7_level0_col1\" class=\"col_heading level0 col1\" >genre</th>\n",
       "      <th id=\"T_553c7_level0_col2\" class=\"col_heading level0 col2\" >imdbId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_553c7_level0_row0\" class=\"row_heading level0 row0\" >MONO:director</th>\n",
       "      <td id=\"T_553c7_row0_col0\" class=\"data row0 col0\" >0.586179</td>\n",
       "      <td id=\"T_553c7_row0_col1\" class=\"data row0 col1\" >0.539052</td>\n",
       "      <td id=\"T_553c7_row0_col2\" class=\"data row0 col2\" >0.587248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_553c7_level0_row1\" class=\"row_heading level0 row1\" >MONO:genre</th>\n",
       "      <td id=\"T_553c7_row1_col0\" class=\"data row1 col0\" >0.538615</td>\n",
       "      <td id=\"T_553c7_row1_col1\" class=\"data row1 col1\" >0.551291</td>\n",
       "      <td id=\"T_553c7_row1_col2\" class=\"data row1 col2\" >0.512951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_553c7_level0_row2\" class=\"row_heading level0 row2\" >MONO:imdbId</th>\n",
       "      <td id=\"T_553c7_row2_col0\" class=\"data row2 col0\" >0.586306</td>\n",
       "      <td id=\"T_553c7_row2_col1\" class=\"data row2 col1\" >0.531941</td>\n",
       "      <td id=\"T_553c7_row2_col2\" class=\"data row2 col2\" >0.599211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_553c7_level0_row3\" class=\"row_heading level0 row3\" >simple model</th>\n",
       "      <td id=\"T_553c7_row3_col0\" class=\"data row3 col0\" >0.586910</td>\n",
       "      <td id=\"T_553c7_row3_col1\" class=\"data row3 col1\" >0.534218</td>\n",
       "      <td id=\"T_553c7_row3_col2\" class=\"data row3 col2\" >0.603315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd30832c130>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(results, 'wAUC', 'model', 'offers').style.background_gradient(cmap='coolwarm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom [moksha-tf2-cpu.2-7] (Local)",
   "language": "python",
   "name": "local-eu.gcr.io_tinyclues-experiments_tinyclues_moksha-tf2-cpu.2-7_latest__moksha"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
