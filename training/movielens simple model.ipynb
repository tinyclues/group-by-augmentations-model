{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edef15d4-49a3-40e3-82f1-2f1fd17c820d",
   "metadata": {},
   "source": [
    "# Training simple model and evalualing its predictions on different tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9113fe5b-43bd-4872-b416-86ef0ee54a02",
   "metadata": {},
   "source": [
    "## Prepare dataset for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac87ae1e-3893-4a7c-9bd7-5c84bbcc5259",
   "metadata": {},
   "source": [
    "First let's load splitted dataset generated in [another notebook](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/dataset_preprocessing/movielens%20with%20imdb.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "807a30be-3b5c-4ab5-9b83-877fadbc4528",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'movielens_imdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffcb1cef-b1d7-4f13-8c07-68b7cfdc8bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_dataset\n",
    "\n",
    "datasets = {}\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    datasets[split_name] = load_dataset(DATASET, split_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529c9be2-9c71-4bfc-ba64-931c0b4294ec",
   "metadata": {},
   "source": [
    "We can parse features' names, they were chosen to easily distinguish between offer features (that will be used to modelize film) and user features (aggregated history up to chosen date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bacd6ec-088e-43f7-8741-f817389aeaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import AGG_PREFIX\n",
    "\n",
    "all_columns = list(datasets['train'].element_spec.keys())\n",
    "technical_columns = ['userId', 'date']\n",
    "user_features = list(filter(lambda x: x.startswith(AGG_PREFIX), all_columns))\n",
    "offer_features = list(filter(lambda x: x not in user_features + technical_columns, all_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e749c7c8-ccce-4996-9dbb-ddd4b30535f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aggregated_ratings_imdbId',\n",
       " 'aggregated_ratings_genre',\n",
       " 'aggregated_ratings_actor',\n",
       " 'aggregated_ratings_titleType',\n",
       " 'aggregated_ratings_startYearCluster',\n",
       " 'aggregated_ratings_runtimeMinutesCluster',\n",
       " 'aggregated_ratings_director']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fc16225-1bf0-42cd-96cc-dde804d0f8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['genre',\n",
       " 'actor',\n",
       " 'startYearCluster',\n",
       " 'runtimeMinutesCluster',\n",
       " 'imdbId',\n",
       " 'titleType',\n",
       " 'director']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offer_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb38696-3ad7-4edc-9331-663f031c11a9",
   "metadata": {},
   "source": [
    "### Rebatch dataset by events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993d1d8c-60a7-4e91-8507-a4d63aafff4e",
   "metadata": {},
   "source": [
    "First we will unnest events for each user (stored in second dimension of saved tensors) and keep only limited number of them. This operation will be needed further to avoid collisions during generation of negative examples. Then we will rebatch results into smaller batches (`50400` events for validation and test sets and `10080` events for train set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea02c22b-3128-4312-ac7e-eba7ba312b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min, sys: 8.29 s, total: 1min 8s\n",
      "Wall time: 53.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from functools import partial\n",
    "from uuid import uuid4\n",
    "\n",
    "from utils import rebatch_by_events\n",
    "\n",
    "datasets['train'] = rebatch_by_events(datasets['train'], batch_size=10080, date_column='date', nb_events_by_user_by_day=8)\n",
    "for key in ['val', 'test']:\n",
    "    datasets[key] = rebatch_by_events(datasets[key], batch_size=50400, date_column='date', nb_events_by_user_by_day=8,\n",
    "                                      seed=1729).cache(f'/tmp/{uuid4()}.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f438dd-88d2-4149-ba09-9bc776344d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10080"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch, y = next(iter(datasets['train']))\n",
    "train_batch['imdbId'].shape[0]  # check batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6267056-b152-448e-a905-515cf6780d4f",
   "metadata": {},
   "source": [
    "## Define simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5585ad1-6f31-4bee-ba40-d1aac2f9a625",
   "metadata": {},
   "source": [
    "Let's now define a simple model we want to test. Independetly from model's choice we need to embed inputs in some vectorial space. To define such embeddings we need number of different modalities inputs can take, and we can get this information from saved vectorizers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d690110-f133-4702-8533-8eb10e41b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_inverse_lookups\n",
    "inverse_lookups = load_inverse_lookups(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "488d715b-2447-4235-93ee-4297dc5954a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "vocabulary_sizes = {}\n",
    "\n",
    "for feature in offer_features:\n",
    "    vocabulary_sizes[feature] = inverse_lookups[feature].vocabulary_size()\n",
    "\n",
    "for feature in user_features:\n",
    "    for key in inverse_lookups:\n",
    "        pattern = re.compile(r\"{}(\\w+)_{}\".format(AGG_PREFIX, key))\n",
    "        if pattern.match(feature):\n",
    "            vocabulary_sizes[feature] = vocabulary_sizes[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ad366-26b9-4443-8a63-27008d154f79",
   "metadata": {},
   "source": [
    "Now `vocabulary_sizes` contains modality of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4276ac0a-6e6c-4ccc-b65e-f24c24eaf170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'genre': 36,\n",
       " 'actor': 2510,\n",
       " 'startYearCluster': 40,\n",
       " 'runtimeMinutesCluster': 35,\n",
       " 'imdbId': 7894,\n",
       " 'titleType': 20,\n",
       " 'director': 3095,\n",
       " 'aggregated_ratings_imdbId': 7894,\n",
       " 'aggregated_ratings_genre': 36,\n",
       " 'aggregated_ratings_actor': 2510,\n",
       " 'aggregated_ratings_titleType': 20,\n",
       " 'aggregated_ratings_startYearCluster': 40,\n",
       " 'aggregated_ratings_runtimeMinutesCluster': 35,\n",
       " 'aggregated_ratings_director': 3095}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a273a2-67d6-4bae-9c3b-282b64346329",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d62b8a31-60e9-4650-8509-652c2866b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f744f91-e1df-4aac-b450-44a425a4ee8e",
   "metadata": {},
   "source": [
    "For the benchmarks we want to do, model's architecture doesn't play a crucial role, we saw the same problems in any model that averages embeddings of offer features in a naive way. So let's take some simple model's architecture, for example collaborative filtering using two towers neural network:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692a7645-1ab1-441b-bb20-b4d2b0d42e20",
   "metadata": {},
   "source": [
    "<img src=\"resources/two_towers_model.png\" alt=\"two tower model\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f2bac6-852a-4c0a-ba11-e8984ae67ac9",
   "metadata": {},
   "source": [
    "### Model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028e0008-74ee-4c60-810c-39f4baa6c710",
   "metadata": {},
   "source": [
    "To choose model's parameters we did some manual tuning using validation set to maximize train and validation AUC while keeping mismatch between them small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f01a2a62-06e6-4758-94a5-5ba3ec5d4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# model parameters\n",
    "EMBEDDING_DIM = 100\n",
    "L1_COEFF = 8.5e-7\n",
    "DROPOUT = 0.17\n",
    "\n",
    "\n",
    "def REGULARIZER():\n",
    "    return {'class_name': 'L1L2', 'config': {'l1': L1_COEFF, 'l2': 0.}}\n",
    "\n",
    "def USER_TOWER():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(80,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Activation('tanh'),\n",
    "        tf.keras.layers.Dense(40,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Activation('tanh'),\n",
    "    ], name='user_tower')\n",
    "\n",
    "def OFFER_TOWER():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(80,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Activation('tanh'),\n",
    "        tf.keras.layers.Dense(40,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Activation('tanh'),\n",
    "    ], name='offer_tower')\n",
    "\n",
    "EPOCHS = 12\n",
    "\n",
    "NUMBER_OF_NEGATIVES = 4\n",
    "LOSS = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "AUC_METRIC = tf.keras.metrics.AUC(from_logits=True)\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "OPTIMIZER = tfa.optimizers.AdamW(weight_decay=8.5e-8, learning_rate=0.0008)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f825d2-88ca-41ad-8031-23a4e6fef17a",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d21f78f-2c0a-40b7-b356-6d6ebca614d0",
   "metadata": {},
   "source": [
    "Let's embed all available `user_features` and `offer_features` into vectorial space of dimension `EMBEDDING_DIM`. We use custom embeddings layer class `WeightedEmbeddings` that will automatically take a mean embedding vector when needed.\n",
    "\n",
    "In particular,\n",
    "* `user_features` are lists of attributes and we don't need to take into account any weights.\n",
    "* `offer_features` during the inference can contain lists of attributes because of aggregation. We will also pass weights explicitly during the inference\n",
    "* `offer_features` during training are lists with only one element, so we need to define dummy weights for training\n",
    "\n",
    "All three cases can be treated by the same layer, where we will define a sparse matrix of all attributes we want to embed and then multiply it by the dense matrix with embeddings, multiplying by weights at the same time (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "167b3d95-81c0-4edf-b0b3-46c6cc95fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import add_equal_weights\n",
    "\n",
    "for key in datasets:\n",
    "    datasets[key] = datasets[key].map(partial(add_equal_weights, features=offer_features))\n",
    "train_batch, y = next(iter(datasets['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d82771e6-24d3-479f-8abe-c93dbdcad8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0]]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy weights needed for training\n",
    "train_batch['genre_weight'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef6e1b98-5b4d-41ec-8413-92425dd63898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float32, numpy=\n",
       "array([[ 2.1628764e-02, -2.8588939e-02, -3.4905314e-02, -2.4152195e-02,\n",
       "        -2.8023064e-02],\n",
       "       [-2.1700919e-02, -2.7018106e-02,  3.2597784e-02,  1.3066243e-02,\n",
       "         1.8497590e-02],\n",
       "       [-3.6077574e-05, -2.7803522e-02, -1.1537652e-03, -5.5429759e-03,\n",
       "        -4.7627371e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeddings layer example\n",
    "from layers import WeightedEmbeddings\n",
    "example_layer = WeightedEmbeddings(3, 5, name='test')\n",
    "example_layer(tf.ragged.constant([[0], [1], [0, 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aa1e4c-0367-46c8-b85d-b7d5b1d302d5",
   "metadata": {},
   "source": [
    "Now we can define all embeddings layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07957c19-2b1b-457b-b17d-c9d21e37316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import get_input_layer, WeightedEmbeddings\n",
    "from utils import WEIGHT_SUFFIX\n",
    "\n",
    "embeddings, inputs = {}, {}\n",
    "for feature in user_features + offer_features:\n",
    "    if feature in offer_features:\n",
    "        # for offer features we need weights:\n",
    "        # with dummy weights during training, and weights used for a feature's averaging at inference time\n",
    "        inputs[f'{feature}{WEIGHT_SUFFIX}'] = get_input_layer(f'{feature}{WEIGHT_SUFFIX}', tf.float32)\n",
    "    inputs[feature] = get_input_layer(feature)\n",
    "    # here we use input feature modality from `vocabulary_sizes` to know embeddings matrix dimensions\n",
    "    emb_layer = WeightedEmbeddings(vocabulary_sizes[feature],\n",
    "                                   EMBEDDING_DIM, name=f'{feature}_embedding',\n",
    "                                   embeddings_regularizer=REGULARIZER())\n",
    "    embeddings[feature] = emb_layer(inputs[feature], inputs.get(f'{feature}{WEIGHT_SUFFIX}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13375747-17f8-42cd-ba11-172bc209878a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aggregated_ratings_imdbId': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'aggregated_ratings_imdbId_embedding')>,\n",
       " 'aggregated_ratings_genre': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'aggregated_ratings_genre_embedding')>,\n",
       " 'aggregated_ratings_actor': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'aggregated_ratings_actor_embedding')>,\n",
       " 'aggregated_ratings_titleType': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'aggregated_ratings_titleType_embedding')>,\n",
       " 'aggregated_ratings_startYearCluster': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'aggregated_ratings_startYearCluster_embedding')>,\n",
       " 'aggregated_ratings_runtimeMinutesCluster': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'aggregated_ratings_runtimeMinutesCluster_embedding')>,\n",
       " 'aggregated_ratings_director': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'aggregated_ratings_director_embedding')>,\n",
       " 'genre': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'genre_embedding')>,\n",
       " 'actor': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'actor_embedding')>,\n",
       " 'startYearCluster': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'startYearCluster_embedding')>,\n",
       " 'runtimeMinutesCluster': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'runtimeMinutesCluster_embedding')>,\n",
       " 'imdbId': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'imdbId_embedding')>,\n",
       " 'titleType': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'titleType_embedding')>,\n",
       " 'director': <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'director_embedding')>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5698ee88-50ff-4250-af07-c27eebe2a665",
   "metadata": {},
   "source": [
    "### Combining everything into model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267636cc-9a2e-469f-9ea7-d259ec05361c",
   "metadata": {},
   "source": [
    "Now we can define described model architecture on the top of embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69ab9aa4-9e45-4cbb-a659-7d6688546d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_user_features = [embeddings[feature] for feature in user_features]\n",
    "embedded_offer_features = [embeddings[feature] for feature in offer_features]\n",
    "user_tower = USER_TOWER()(tf.keras.layers.Concatenate(name='concat_user')(embedded_user_features))\n",
    "offer_tower = OFFER_TOWER()(tf.keras.layers.Concatenate(name='concat_offer')(embedded_offer_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3739f61-7e24-4d05-be34-18edec538267",
   "metadata": {},
   "source": [
    "### Negative generation in mini-batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfe350c-3fb8-4e39-901e-431214d10d60",
   "metadata": {},
   "source": [
    "As our dataset contains only positive examples, up to this point we used only them. We have different choices of how to choose negative examples, but we chose most optimal one for calculations (both in memory and time) - we will generate negatives at the same time as calculating interactions between user and offer embeddings, proceding in minibatches:\n",
    "* let's fix a number `N - 1` of how many negative examples we want to generate for each positive one\n",
    "* consider minibatches of size `N` with events done on the same (or close) date (this was ensured by batch construction above), so we will get negative example from the actions on the same date as the positive one, similar to [Contrastive Predictive Coding](https://arxiv.org/abs/1807.03748) method.\n",
    "* inside each minibatch we have users `u1, u2, ..., uN` who rated films `f1, f2, ..., fN` respectively on the same date `d`\n",
    "* let's consider all possible pairs `(u1, f1), (u1, f2), ..., (uN, fN)` (`N ** 2` pairs in total)\n",
    "* among those pairs there are `N` positive examples, all other `N(N - 1)` pairs are considered as negative ones\n",
    "* it gives us exactly `N - 1` negative examples for each from `N` positive ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ecf1a5-e57e-408b-b30e-ad32d3b2356d",
   "metadata": {},
   "source": [
    "We pair this process with interaction calculation by calculating not only scalar products between positive pairs, but between all `N ** 2` pairs per minibatch. Such operation can be written as multiplication of tensors, keeping number of embeddings calculations fixed (`2 * N` for each minibatch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82a36d9c-4e5a-4f61-afcc-610ecf4504e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotWithNegatives(tf.keras.layers.Layer):\n",
    "    def __init__(self, number_of_negatives, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.number_of_negatives = number_of_negatives\n",
    "        \n",
    "    def call(self, inputs, generate_negatives):\n",
    "        user_embeddings, offer_embeddings = inputs\n",
    "        if generate_negatives:\n",
    "            # here we will generate negative examples inside mini-batches\n",
    "            batch_size = tf.shape(user_embeddings)[0]\n",
    "            # we split original batch into mini-batches of size (number_of_negatives + 1)\n",
    "            minibatch_shape = (batch_size // (self.number_of_negatives + 1), (self.number_of_negatives + 1), -1)\n",
    "            user_embeddings = tf.reshape(user_embeddings, minibatch_shape)\n",
    "            offer_embeddings = tf.reshape(offer_embeddings, minibatch_shape)\n",
    "            # for each pair of lines i,j inside minibatch, we consider pairs user/offer\n",
    "            # * as positive examples when i==j\n",
    "            # * as negative examples otherwise\n",
    "            # at the end we flatten mini-batch dimension and obtain batch_size * (number_of_negatives + 1) predictions\n",
    "            res = tf.einsum('bid,bjd->bij', user_embeddings, offer_embeddings)\n",
    "        else:\n",
    "            # otherwise we do just scalar product, let's write it in einsum notation too to see a difference between two\n",
    "            res = tf.einsum('bd,bd->b', user_embeddings, offer_embeddings)\n",
    "        return tf.reshape(res, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5cee96b-5095-4635-863c-bb6be416a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't apply sigmoid on the output and will have from_logits=True in both loss and metrics\n",
    "output = DotWithNegatives(NUMBER_OF_NEGATIVES, name='prediction')([user_tower, offer_tower], generate_negatives=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e77d19f-e3df-4244-b689-feee5db9b6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'prediction')>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d22722-8de8-4093-a46b-cd7fe4553af7",
   "metadata": {},
   "source": [
    "Now our labels from batch are not aligned with output we produce, to get positive/negative labels at needed positions we just need to find which index would correspond to which label when considering a minibatch. This logic is implemented in auxilary classes `BroadcastLoss` and `BroadcastMetric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53c2d19a-acd9-4fd8-9bcf-a9865f65bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import BroadcastLoss, BroadcastMetric\n",
    "\n",
    "model = tf.keras.Model(inputs, output, name='two_tower_model')\n",
    "model.compile(optimizer=OPTIMIZER,\n",
    "              loss=BroadcastLoss(LOSS, NUMBER_OF_NEGATIVES),\n",
    "              metrics=[BroadcastMetric(AUC_METRIC, NUMBER_OF_NEGATIVES)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc3fa47b-2ac2-40b1-aa26-e8cc56fab46b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, to_file=f'models/{DATASET}_simple_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237702cb-fa87-45dc-8966-020cf9bf2515",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a77a6113-ba67-4ba0-a762-20d4c14272db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 226s 728ms/step - loss: 0.5586 - auc: 0.5651 - val_loss: 0.5658 - val_auc: 0.5348\n",
      "Epoch 2/12\n",
      "231/231 [==============================] - 149s 608ms/step - loss: 0.5072 - auc: 0.6205 - val_loss: 0.5417 - val_auc: 0.6169\n",
      "Epoch 3/12\n",
      "231/231 [==============================] - 137s 551ms/step - loss: 0.4989 - auc: 0.6281 - val_loss: 0.5040 - val_auc: 0.6349\n",
      "Epoch 4/12\n",
      "231/231 [==============================] - 98s 404ms/step - loss: 0.4954 - auc: 0.6317 - val_loss: 0.4956 - val_auc: 0.6363\n",
      "Epoch 5/12\n",
      "231/231 [==============================] - 113s 459ms/step - loss: 0.4932 - auc: 0.6340 - val_loss: 0.4927 - val_auc: 0.6386\n",
      "Epoch 6/12\n",
      "231/231 [==============================] - 124s 504ms/step - loss: 0.4913 - auc: 0.6363 - val_loss: 0.4928 - val_auc: 0.6391\n",
      "Epoch 7/12\n",
      "231/231 [==============================] - 125s 508ms/step - loss: 0.4897 - auc: 0.6384 - val_loss: 0.4904 - val_auc: 0.6402\n",
      "Epoch 8/12\n",
      "231/231 [==============================] - 129s 524ms/step - loss: 0.4881 - auc: 0.6405 - val_loss: 0.4903 - val_auc: 0.6405\n",
      "Epoch 9/12\n",
      "231/231 [==============================] - 125s 504ms/step - loss: 0.4868 - auc: 0.6421 - val_loss: 0.4892 - val_auc: 0.6408\n",
      "Epoch 10/12\n",
      "231/231 [==============================] - 129s 517ms/step - loss: 0.4857 - auc: 0.6431 - val_loss: 0.4885 - val_auc: 0.6407\n",
      "Epoch 11/12\n",
      "231/231 [==============================] - 128s 519ms/step - loss: 0.4847 - auc: 0.6444 - val_loss: 0.4869 - val_auc: 0.6419\n",
      "Epoch 12/12\n",
      "231/231 [==============================] - 128s 520ms/step - loss: 0.4839 - auc: 0.6453 - val_loss: 0.4861 - val_auc: 0.6425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b183db2b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datasets['train'], epochs=EPOCHS, validation_data=datasets['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7595399-bced-44ae-bbf6-05f2534141fd",
   "metadata": {},
   "source": [
    "## Single task models benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910110b3-f9b1-4663-80b9-d303ebc97359",
   "metadata": {},
   "source": [
    "As described in [the blog post](https://medium.com/p/508d5080c0c6/) we can consider predictions on one chosen offer column as a single task and the whole setup as a multi-task problem. Let's now evaluate performance of a common model on a subset of tasks. We will compare its results against single task models sharing the same architecture, but using only one offer feature at time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6669fc5c-fa01-4e50-95e9-c4bbd66eb10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# offer columns we want to evaluate, specific to dataset we test\n",
    "TASKS = ['imdbId', 'director', 'genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05482dc-6ce3-47f0-8c5f-d9d25a0ecb3c",
   "metadata": {},
   "source": [
    "For simplicity of further code, let's wrap whole model definition into a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a45e96a-b5fe-4ad2-a20b-a3aad3773571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_tower_model(offer_features, name='two_tower_model'):\n",
    "    # user_features, vocabulary_sizes, EMBEDDING_DIM, REGULARIZER, USER_TOWER, OFFER_TOWER,\n",
    "    # OPTIMIZER, LOSS, NUMBER_OF_NEGATIVES\n",
    "    # come from global scope, but can be passed as params instead\n",
    "    embeddings, inputs = {}, {}\n",
    "    for feature in user_features + offer_features:\n",
    "        if feature in offer_features:\n",
    "            # for offer features we need weights:\n",
    "            # with dummy weights during training, and the ones used for a feature's averaging at inference time\n",
    "            inputs[f'{feature}{WEIGHT_SUFFIX}'] = get_input_layer(f'{feature}{WEIGHT_SUFFIX}', tf.float32)\n",
    "        inputs[feature] = get_input_layer(feature)\n",
    "        # here we use input feature modality from `vocabulary_sizes` to know embeddings matrix dimensions\n",
    "        emb_layer = WeightedEmbeddings(vocabulary_sizes[feature],\n",
    "                                       EMBEDDING_DIM, name=f'{feature}_embedding',\n",
    "                                       embeddings_regularizer=REGULARIZER())\n",
    "        embeddings[feature] = emb_layer(inputs[feature], inputs.get(f'{feature}{WEIGHT_SUFFIX}'))\n",
    "    \n",
    "    embedded_user_features = [embeddings[feature] for feature in user_features]\n",
    "    embedded_offer_features = [embeddings[feature] for feature in offer_features]\n",
    "    user_tower = USER_TOWER()(tf.keras.layers.Concatenate(name='concat_user')(embedded_user_features))\n",
    "    offer_tower = OFFER_TOWER()(tf.keras.layers.Concatenate(name='concat_offer')(embedded_offer_features))\n",
    "    \n",
    "    output = DotWithNegatives(NUMBER_OF_NEGATIVES, name='prediction')([user_tower, offer_tower], generate_negatives=True)\n",
    "    model = tf.keras.Model(inputs, output, name=name)\n",
    "    model.compile(optimizer=OPTIMIZER,\n",
    "                  loss=BroadcastLoss(LOSS, NUMBER_OF_NEGATIVES),\n",
    "                  metrics=[BroadcastMetric(AUC_METRIC, NUMBER_OF_NEGATIVES)])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191a9dca-20e1-4bda-9f32-0fe31f1cca5b",
   "metadata": {},
   "source": [
    "We train models that use only one offer feature with same hyperparameters as the initial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "984349ef-6d9a-4e99-9711-5c0a33bc3a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['genre', 'actor', 'startYearCluster', 'runtimeMinutesCluster', 'titleType', 'date', 'director', 'userId', 'genre_weight', 'actor_weight', 'startYearCluster_weight', 'runtimeMinutesCluster_weight', 'titleType_weight', 'director_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 168s 577ms/step - loss: 0.5339 - auc: 0.5746 - val_loss: 0.5345 - val_auc: 0.5314\n",
      "Epoch 2/12\n",
      "231/231 [==============================] - 117s 469ms/step - loss: 0.5011 - auc: 0.6183 - val_loss: 0.5236 - val_auc: 0.6067\n",
      "Epoch 3/12\n",
      "231/231 [==============================] - 122s 493ms/step - loss: 0.4959 - auc: 0.6263 - val_loss: 0.5014 - val_auc: 0.6282\n",
      "Epoch 4/12\n",
      "231/231 [==============================] - 115s 460ms/step - loss: 0.4929 - auc: 0.6314 - val_loss: 0.4923 - val_auc: 0.6335\n",
      "Epoch 5/12\n",
      "231/231 [==============================] - 120s 482ms/step - loss: 0.4906 - auc: 0.6347 - val_loss: 0.4903 - val_auc: 0.6349\n",
      "Epoch 6/12\n",
      "231/231 [==============================] - 119s 479ms/step - loss: 0.4888 - auc: 0.6369 - val_loss: 0.4894 - val_auc: 0.6355\n",
      "Epoch 7/12\n",
      "231/231 [==============================] - 121s 487ms/step - loss: 0.4874 - auc: 0.6386 - val_loss: 0.4881 - val_auc: 0.6366\n",
      "Epoch 8/12\n",
      "231/231 [==============================] - 108s 432ms/step - loss: 0.4862 - auc: 0.6404 - val_loss: 0.4875 - val_auc: 0.6371\n",
      "Epoch 9/12\n",
      "231/231 [==============================] - 123s 496ms/step - loss: 0.4852 - auc: 0.6417 - val_loss: 0.4869 - val_auc: 0.6381\n",
      "Epoch 10/12\n",
      "231/231 [==============================] - 119s 479ms/step - loss: 0.4845 - auc: 0.6429 - val_loss: 0.4864 - val_auc: 0.6379\n",
      "Epoch 11/12\n",
      "231/231 [==============================] - 121s 489ms/step - loss: 0.4838 - auc: 0.6439 - val_loss: 0.4853 - val_auc: 0.6398\n",
      "Epoch 12/12\n",
      "231/231 [==============================] - 118s 477ms/step - loss: 0.4832 - auc: 0.6449 - val_loss: 0.4857 - val_auc: 0.6386\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['genre', 'actor', 'startYearCluster', 'runtimeMinutesCluster', 'imdbId', 'titleType', 'date', 'userId', 'genre_weight', 'actor_weight', 'startYearCluster_weight', 'runtimeMinutesCluster_weight', 'imdbId_weight', 'titleType_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 164s 543ms/step - loss: 0.5278 - auc: 0.5679 - val_loss: 0.5215 - val_auc: 0.5145\n",
      "Epoch 2/12\n",
      "231/231 [==============================] - 93s 369ms/step - loss: 0.5009 - auc: 0.5975 - val_loss: 0.5162 - val_auc: 0.5717\n",
      "Epoch 3/12\n",
      "231/231 [==============================] - 94s 375ms/step - loss: 0.4976 - auc: 0.6032 - val_loss: 0.5009 - val_auc: 0.6083\n",
      "Epoch 4/12\n",
      "231/231 [==============================] - 82s 321ms/step - loss: 0.4957 - auc: 0.6066 - val_loss: 0.4961 - val_auc: 0.6130\n",
      "Epoch 5/12\n",
      "231/231 [==============================] - 55s 217ms/step - loss: 0.4942 - auc: 0.6094 - val_loss: 0.4936 - val_auc: 0.6143\n",
      "Epoch 6/12\n",
      "231/231 [==============================] - 88s 351ms/step - loss: 0.4929 - auc: 0.6113 - val_loss: 0.4927 - val_auc: 0.6154\n",
      "Epoch 7/12\n",
      "231/231 [==============================] - 87s 345ms/step - loss: 0.4921 - auc: 0.6124 - val_loss: 0.4920 - val_auc: 0.6159\n",
      "Epoch 8/12\n",
      "231/231 [==============================] - 86s 343ms/step - loss: 0.4913 - auc: 0.6137 - val_loss: 0.4916 - val_auc: 0.6159\n",
      "Epoch 9/12\n",
      "231/231 [==============================] - 87s 341ms/step - loss: 0.4906 - auc: 0.6144 - val_loss: 0.4905 - val_auc: 0.6166\n",
      "Epoch 10/12\n",
      "231/231 [==============================] - 86s 343ms/step - loss: 0.4900 - auc: 0.6155 - val_loss: 0.4903 - val_auc: 0.6168\n",
      "Epoch 11/12\n",
      "231/231 [==============================] - 89s 351ms/step - loss: 0.4896 - auc: 0.6160 - val_loss: 0.4900 - val_auc: 0.6171\n",
      "Epoch 12/12\n",
      "231/231 [==============================] - 87s 343ms/step - loss: 0.4891 - auc: 0.6167 - val_loss: 0.4904 - val_auc: 0.6162\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['actor', 'startYearCluster', 'runtimeMinutesCluster', 'imdbId', 'titleType', 'date', 'director', 'userId', 'actor_weight', 'startYearCluster_weight', 'runtimeMinutesCluster_weight', 'imdbId_weight', 'titleType_weight', 'director_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 123s 403ms/step - loss: 0.5328 - auc: 0.5261 - val_loss: 0.5083 - val_auc: 0.5039\n",
      "Epoch 2/12\n",
      "231/231 [==============================] - 85s 337ms/step - loss: 0.5081 - auc: 0.5293 - val_loss: 0.5054 - val_auc: 0.5194\n",
      "Epoch 3/12\n",
      "231/231 [==============================] - 68s 272ms/step - loss: 0.5062 - auc: 0.5310 - val_loss: 0.5038 - val_auc: 0.5420\n",
      "Epoch 4/12\n",
      "231/231 [==============================] - 88s 351ms/step - loss: 0.5052 - auc: 0.5321 - val_loss: 0.5033 - val_auc: 0.5456\n",
      "Epoch 5/12\n",
      "231/231 [==============================] - 87s 344ms/step - loss: 0.5046 - auc: 0.5330 - val_loss: 0.5033 - val_auc: 0.5456\n",
      "Epoch 6/12\n",
      "231/231 [==============================] - 86s 342ms/step - loss: 0.5040 - auc: 0.5338 - val_loss: 0.5030 - val_auc: 0.5454\n",
      "Epoch 7/12\n",
      "231/231 [==============================] - 88s 351ms/step - loss: 0.5035 - auc: 0.5347 - val_loss: 0.5025 - val_auc: 0.5459\n",
      "Epoch 8/12\n",
      "231/231 [==============================] - 87s 343ms/step - loss: 0.5031 - auc: 0.5356 - val_loss: 0.5025 - val_auc: 0.5450\n",
      "Epoch 9/12\n",
      "231/231 [==============================] - 87s 344ms/step - loss: 0.5027 - auc: 0.5362 - val_loss: 0.5019 - val_auc: 0.5459\n",
      "Epoch 10/12\n",
      "231/231 [==============================] - 86s 341ms/step - loss: 0.5024 - auc: 0.5365 - val_loss: 0.5019 - val_auc: 0.5466\n",
      "Epoch 11/12\n",
      "231/231 [==============================] - 87s 344ms/step - loss: 0.5021 - auc: 0.5372 - val_loss: 0.5023 - val_auc: 0.5463\n",
      "Epoch 12/12\n",
      "231/231 [==============================] - 87s 345ms/step - loss: 0.5019 - auc: 0.5374 - val_loss: 0.5016 - val_auc: 0.5466\n"
     ]
    }
   ],
   "source": [
    "mono_feature_models = {}\n",
    "for task_offer_feature in TASKS:\n",
    "    mono_feature_models[task_offer_feature] = two_tower_model([task_offer_feature],\n",
    "                                                              name=f'{task_offer_feature}_model')\n",
    "    mono_feature_models[task_offer_feature].fit(datasets['train'],\n",
    "                                                epochs=EPOCHS,\n",
    "                                                validation_data=datasets['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e416a20a-7564-44a1-812d-6c9b1ca29b02",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95506c1c-1d7e-41b2-b4d9-7e46d9c59e79",
   "metadata": {},
   "source": [
    "Now let's generate some offers from test dataset:\n",
    "* we will consider all batches from test dataset\n",
    "* we perform a group by using each feature from `TASKS` as a group by key\n",
    "* for all offer features except the one we are using as key we generate ragged tensors with bag of values it can take\n",
    "* we remove least popular values in each list\n",
    "* so now each line of dataset corresponds to an offer of type `task_offer_feature = 'value'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1aa2ddd9-efcc-4d32-9ff7-81eb033a9faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 31s, sys: 11.4 s, total: 2min 43s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from utils import prepare_single_task_dataset\n",
    "test_datasets = {}\n",
    "for task_offer_feature in TASKS:\n",
    "    test_datasets[task_offer_feature] = \\\n",
    "        prepare_single_task_dataset(datasets['test'], task_offer_feature, offer_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e37e8cc-2b65-4654-afdc-7da7ee11fbf7",
   "metadata": {},
   "source": [
    "Test dataset for a given task keeps a column used for group by as is, but other offer columns become lists (to encode bag of values) and we need to average embeddings for them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9e5e18d-fde0-4684-80ba-6cf637a81e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch, y = next(iter(test_datasets['genre']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d84f438f-4526-4132-aa9f-9c15dca33bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[10],\n",
       " [10],\n",
       " [14],\n",
       " [14],\n",
       " [11]]>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch['genre'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de9c840f-fb0d-4dad-b50e-6359ee31f947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0]]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch['genre_weight'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "232acc42-8751-449a-894f-7f8c4c1a7447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[312, 0, 546, 790, 903, 835, 513, 786, 537, 321, 298, 842, 7, 773, 548,\n",
       "  318, 655, 310, 924, 155, 562, 659, 2, 387, 455, 217, 613, 615, 512, 232,\n",
       "  889, 225, 483, 358, 436, 274, 471, 493, 698, 438, 177, 108, 473, 488,\n",
       "  491, 111, 6, 269, 42, 253, 348, 774, 534, 5, 9, 77, 8, 575, 245, 516,\n",
       "  399, 349, 341, 775, 442, 467, 541, 472, 84, 634, 416, 139, 418, 377,\n",
       "  452, 18, 660, 439, 409, 417, 432, 601, 644, 226, 408, 664, 268, 291,\n",
       "  480, 376, 243, 476, 23, 517, 113, 629, 170, 670, 197, 362, 48, 230, 271,\n",
       "  124, 440, 121, 214, 328, 167, 391, 149, 371, 375, 344, 252, 627, 313,\n",
       "  431, 286, 583, 169, 98, 277, 174, 370, 258, 293, 165, 482, 330, 294,\n",
       "  244, 285, 218, 396, 289, 228, 381, 237, 554, 107, 411, 148, 306, 205,\n",
       "  130, 47, 203, 194, 337, 254, 105, 208, 216, 128, 182, 92, 403, 199, 248,\n",
       "  150, 275, 173, 406, 247, 260, 372, 212, 320, 16, 93, 355, 202, 240, 272,\n",
       "  120, 331, 82, 131, 44, 129, 55, 184, 196, 96, 156, 235, 397, 266, 24,\n",
       "  134, 211, 163, 160, 181, 32, 249, 142, 30, 94, 127, 14, 123, 284, 151,\n",
       "  68, 189, 118, 59, 65, 80, 125, 112, 117, 37, 187, 137, 106, 38, 97, 62,\n",
       "  135, 61, 87, 69, 109, 119, 19, 104, 116, 101, 36, 72, 78, 15, 39, 58,\n",
       "  41, 26, 20, 40, 25, 17, 21, 50, 11, 27, 12, 10, 22]]>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch['director'][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9bb8c63b-a6fb-42a1-af9c-8e937ce70ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[0.00089855335, 0.00089855335, 0.00089855335, 0.00089855335,\n",
       "  0.00089855335, 0.00089855335, 0.00092101714, 0.00092101714, 0.000943481,\n",
       "  0.000943481, 0.000943481, 0.000943481, 0.00096594484, 0.00096594484,\n",
       "  0.0009884087, 0.0009884087, 0.0010108725, 0.0010108725, 0.0010108725,\n",
       "  0.0010108725, 0.0010333363, 0.0010333363, 0.0010558001, 0.0010558001,\n",
       "  0.0010558001, 0.0010558001, 0.0010558001, 0.0010558001, 0.001078264,\n",
       "  0.001078264, 0.001078264, 0.0011007278, 0.0011007278, 0.0011007278,\n",
       "  0.0011231917, 0.0011231917, 0.0011231917, 0.0011231917, 0.0011231917,\n",
       "  0.0011456555, 0.0011456555, 0.0011456555, 0.0011456555, 0.0011456555,\n",
       "  0.0011456555, 0.0011681194, 0.0011905831, 0.0011905831, 0.0011905831,\n",
       "  0.001213047, 0.001213047, 0.0012355108, 0.0012579747, 0.0012579747,\n",
       "  0.0012804385, 0.0013029024, 0.0013029024, 0.0013029024, 0.0013253662,\n",
       "  0.0013253662, 0.0013253662, 0.0013253662, 0.0013253662, 0.0013253662,\n",
       "  0.0013478299, 0.0013702938, 0.0013702938, 0.0013702938, 0.0013927576,\n",
       "  0.0014152215, 0.0014376853, 0.0014376853, 0.0014376853, 0.0014601492,\n",
       "  0.001482613, 0.0015050768, 0.0015050768, 0.0015050768, 0.0015050768,\n",
       "  0.0015275406, 0.0015275406, 0.0015275406, 0.0015275406, 0.0015500045,\n",
       "  0.0015500045, 0.0015500045, 0.0015724683, 0.0015724683, 0.0015724683,\n",
       "  0.0015724683, 0.001617396, 0.0016398599, 0.0016398599, 0.0016398599,\n",
       "  0.0016623237, 0.0016623237, 0.0016847875, 0.0016847875, 0.0017297151,\n",
       "  0.001752179, 0.001752179, 0.001752179, 0.001752179, 0.0017746428,\n",
       "  0.0017971067, 0.0018195705, 0.0018195705, 0.0018195705, 0.0018195705,\n",
       "  0.0018644981, 0.0018644981, 0.001886962, 0.001886962, 0.001886962,\n",
       "  0.0019094258, 0.0019094258, 0.0019768174, 0.0019768174, 0.002021745,\n",
       "  0.002021745, 0.0020442088, 0.0020442088, 0.0020666725, 0.0020891365,\n",
       "  0.002156528, 0.0022014556, 0.0022014556, 0.0022014556, 0.0022239194,\n",
       "  0.0022463833, 0.0022463833, 0.0022463833, 0.002291311, 0.002291311,\n",
       "  0.0023137748, 0.0023362387, 0.0023587025, 0.0023587025, 0.0024036302,\n",
       "  0.0024485579, 0.0024710216, 0.0024934856, 0.002560877, 0.0026058047,\n",
       "  0.0026282684, 0.0026507324, 0.0026507324, 0.0026507324, 0.0027181238,\n",
       "  0.0027630515, 0.0027630515, 0.0027855153, 0.0027855153, 0.0027855153,\n",
       "  0.002942762, 0.0030775452, 0.0030775452, 0.003100009, 0.003122473,\n",
       "  0.0031449366, 0.0031674004, 0.0031898643, 0.0031898643, 0.0031898643,\n",
       "  0.003234792, 0.003234792, 0.0033246474, 0.0034145026, 0.003504358,\n",
       "  0.0035268217, 0.0035717494, 0.0035942134, 0.0037065325, 0.0037289963,\n",
       "  0.0037514602, 0.003773924, 0.003773924, 0.003796388, 0.0038413154,\n",
       "  0.003908707, 0.003908707, 0.0039536348, 0.004021026, 0.004021026,\n",
       "  0.0040884176, 0.004178273, 0.004178273, 0.004200737, 0.0042232005,\n",
       "  0.00433552, 0.0044253753, 0.0044927667, 0.0045152307, 0.004537694,\n",
       "  0.0049195793, 0.0049195793, 0.0049195793, 0.005121754, 0.005301465,\n",
       "  0.005301465, 0.0053688562, 0.005503639, 0.005526103, 0.0055934945,\n",
       "  0.0057732053, 0.0059753796, 0.0059978436, 0.006087699, 0.006200018,\n",
       "  0.00644712, 0.006604367, 0.006626831, 0.006626831, 0.006873933,\n",
       "  0.0069637885, 0.007143499, 0.0073232097, 0.0074579925, 0.007547848,\n",
       "  0.007997124, 0.00855872, 0.008985533, 0.009030461, 0.009052925,\n",
       "  0.009502201, 0.009636984, 0.0102210445, 0.0103108995, 0.010850032,\n",
       "  0.010872495, 0.011097133, 0.011658729, 0.011658729, 0.011771048,\n",
       "  0.011928296, 0.012242789, 0.012287716, 0.013118879, 0.013253662,\n",
       "  0.013882649, 0.014511636, 0.015073232, 0.01722976, 0.018083386,\n",
       "  0.019251505, 0.026125439, 0.026934136, 0.028933417, 0.030213855,\n",
       "  0.030483421]]>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch['director_weight'][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb43883-2574-41a2-8b3f-287800b250aa",
   "metadata": {},
   "source": [
    "Now we can apply model on grouped features for each task and calculate AUC for each offer of type `task_offer_feature = 'value'`. Note, that negatives are generated in the same way as for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0966f43-5ea6-4291-9fc8-5b48375da541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['genre', 'actor', 'startYearCluster', 'runtimeMinutesCluster', 'imdbId', 'titleType', 'date', 'userId', 'genre_weight', 'actor_weight', 'startYearCluster_weight', 'runtimeMinutesCluster_weight', 'imdbId_weight', 'titleType_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['actor', 'startYearCluster', 'runtimeMinutesCluster', 'imdbId', 'titleType', 'date', 'director', 'userId', 'actor_weight', 'startYearCluster_weight', 'runtimeMinutesCluster_weight', 'imdbId_weight', 'titleType_weight', 'director_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['genre', 'actor', 'startYearCluster', 'runtimeMinutesCluster', 'titleType', 'date', 'director', 'userId', 'genre_weight', 'actor_weight', 'startYearCluster_weight', 'runtimeMinutesCluster_weight', 'titleType_weight', 'director_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['genre', 'actor', 'startYearCluster', 'runtimeMinutesCluster', 'imdbId', 'titleType', 'date', 'userId', 'genre_weight', 'actor_weight', 'startYearCluster_weight', 'runtimeMinutesCluster_weight', 'imdbId_weight', 'titleType_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['actor', 'startYearCluster', 'runtimeMinutesCluster', 'imdbId', 'titleType', 'date', 'director', 'userId', 'actor_weight', 'startYearCluster_weight', 'runtimeMinutesCluster_weight', 'imdbId_weight', 'titleType_weight', 'director_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['genre', 'actor', 'startYearCluster', 'runtimeMinutesCluster', 'titleType', 'date', 'director', 'userId', 'genre_weight', 'actor_weight', 'startYearCluster_weight', 'runtimeMinutesCluster_weight', 'titleType_weight', 'director_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['genre', 'actor', 'startYearCluster', 'runtimeMinutesCluster', 'imdbId', 'titleType', 'date', 'userId', 'genre_weight', 'actor_weight', 'startYearCluster_weight', 'runtimeMinutesCluster_weight', 'imdbId_weight', 'titleType_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['actor', 'startYearCluster', 'runtimeMinutesCluster', 'imdbId', 'titleType', 'date', 'director', 'userId', 'actor_weight', 'startYearCluster_weight', 'runtimeMinutesCluster_weight', 'imdbId_weight', 'titleType_weight', 'director_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/home/jupyter/.local/lib/python3.9/site-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['date', 'userId'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 56s, sys: 51.3 s, total: 14min 47s\n",
      "Wall time: 5min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "from utils import evaluate_model, wAUC\n",
    "\n",
    "aucs = defaultdict(dict)\n",
    "for task_offer_feature in TASKS:\n",
    "    for model_name in TASKS:\n",
    "        aucs[task_offer_feature][f'MONO:{model_name}'] = \\\n",
    "            evaluate_model(mono_feature_models[model_name],\n",
    "                           task_offer_feature, test_datasets, NUMBER_OF_NEGATIVES, inverse_lookups)\n",
    "    aucs[task_offer_feature]['simple model'] = \\\n",
    "            evaluate_model(model, task_offer_feature, test_datasets, NUMBER_OF_NEGATIVES, inverse_lookups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "816487f0-5070-475c-ae5e-f0582f62f3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>name</th>\n",
       "      <th>number of events</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.635294</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.586313</td>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.556541</td>\n",
       "      <td>The Silence of the Lambs</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.621494</td>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.605024</td>\n",
       "      <td>Star Wars: Episode IV - A New Hope</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                auc                                name  number of events\n",
       "group_idx                                                                \n",
       "10         0.635294            The Shawshank Redemption              1183\n",
       "11         0.586313                        Pulp Fiction              1052\n",
       "12         0.556541            The Silence of the Lambs               979\n",
       "13         0.621494                        Forrest Gump               928\n",
       "14         0.605024  Star Wars: Episode IV - A New Hope               787"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs['imdbId']['MONO:imdbId'][10:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a374dd80-b0dc-4905-903c-84b72735777c",
   "metadata": {},
   "source": [
    "We can aggregate AUCs from individual offers to have one value we can compare among models: weighted macro AUC. We will keep only offers with more than 200 positive events and weight their AUCs by number of events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbdf4194-a2fc-4c89-a524-4dda2905ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.DataFrame()\n",
    "for task_name in aucs:\n",
    "    for model_name in aucs[task_name]:\n",
    "        w_auc = wAUC(aucs[task_name][model_name])\n",
    "        results = pd.concat([results,\n",
    "                             pd.Series({'wAUC': w_auc, 'offers': task_name, 'model': model_name}).to_frame().T],\n",
    "                            ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "869761a6-12d2-4364-9962-c0fa902e18f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_04fa2_row0_col0, #T_04fa2_row2_col1, #T_04fa2_row3_col2 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_04fa2_row0_col1 {\n",
       "  background-color: #ba162b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_04fa2_row0_col2 {\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_04fa2_row1_col0 {\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_04fa2_row1_col1 {\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_04fa2_row1_col2 {\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_04fa2_row2_col0 {\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_04fa2_row2_col2, #T_04fa2_row3_col0, #T_04fa2_row3_col1 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_04fa2_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >offers</th>\n",
       "      <th class=\"col_heading level0 col0\" >film</th>\n",
       "      <th class=\"col_heading level0 col1\" >director</th>\n",
       "      <th class=\"col_heading level0 col2\" >genre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_04fa2_level0_row0\" class=\"row_heading level0 row0\" >simple model</th>\n",
       "      <td id=\"T_04fa2_row0_col0\" class=\"data row0 col0\" >0.632</td>\n",
       "      <td id=\"T_04fa2_row0_col1\" class=\"data row0 col1\" >0.609</td>\n",
       "      <td id=\"T_04fa2_row0_col2\" class=\"data row0 col2\" >0.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04fa2_level0_row1\" class=\"row_heading level0 row1\" >MONO:film</th>\n",
       "      <td id=\"T_04fa2_row1_col0\" class=\"data row1 col0\" >0.629</td>\n",
       "      <td id=\"T_04fa2_row1_col1\" class=\"data row1 col1\" >0.608</td>\n",
       "      <td id=\"T_04fa2_row1_col2\" class=\"data row1 col2\" >0.537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04fa2_level0_row2\" class=\"row_heading level0 row2\" >MONO:director</th>\n",
       "      <td id=\"T_04fa2_row2_col0\" class=\"data row2 col0\" >0.608</td>\n",
       "      <td id=\"T_04fa2_row2_col1\" class=\"data row2 col1\" >0.610</td>\n",
       "      <td id=\"T_04fa2_row2_col2\" class=\"data row2 col2\" >0.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04fa2_level0_row3\" class=\"row_heading level0 row3\" >MONO:genre</th>\n",
       "      <td id=\"T_04fa2_row3_col0\" class=\"data row3 col0\" >0.541</td>\n",
       "      <td id=\"T_04fa2_row3_col1\" class=\"data row3 col1\" >0.548</td>\n",
       "      <td id=\"T_04fa2_row3_col2\" class=\"data row3 col2\" >0.551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f3c42a8d8e0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(results, 'wAUC', 'model', 'offers')\\\n",
    "    .rename(columns={'imdbId': 'film'}, index={'MONO:imdbId': 'MONO:film'})\\\n",
    "    .iloc[[3, 2, 0, 1]][['film', 'director', 'genre']]\\\n",
    "    .style.background_gradient(cmap='coolwarm').format(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940c525-7836-4cf1-b3f8-76ec752c5b17",
   "metadata": {},
   "source": [
    "Saving raw AUCs in case we want to reaggregate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0f1215c-ba32-4424-a00f-34b5a413ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_metrics\n",
    "save_metrics(aucs, DATASET, 'simple_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom [moksha-tf2-cpu.2-7] (Local)",
   "language": "python",
   "name": "local-eu.gcr.io_tinyclues-experiments_tinyclues_moksha-tf2-cpu.2-7_latest__moksha"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
