{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea932e5b",
   "metadata": {},
   "source": [
    "# Bi-linear interaction model with group-by augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b6f05f",
   "metadata": {},
   "source": [
    "## Prepare dataset for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96897ae",
   "metadata": {},
   "source": [
    "Following the same steps as in [the training for Movielens/IMDB dataset](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/training/movielens%20simple%20model.ipynb), we first load splitted dataset generated in [notebook](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/dataset_preprocessing/movielens%20with%20imdb.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1899e738-56d3-455f-afcd-ce80fcb17232",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'rees_ecommerce'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19cc05cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/recsys-multi-atrribute-benchmark/training/utils.py:26: load (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.load(...)` instead.\n"
     ]
    }
   ],
   "source": [
    "from utils import load_dataset\n",
    "\n",
    "datasets = {}\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    datasets[split_name] = load_dataset(DATASET, split_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d1b29e",
   "metadata": {},
   "source": [
    "Then we parse features' names to obtain a list of offer features (that will be used to modelize film) and a list of user features (aggregated history up to chosen date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5077ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import AGG_PREFIX\n",
    "\n",
    "all_columns = list(datasets['train'].element_spec.keys())\n",
    "technical_columns = ['user_id', 'date']\n",
    "user_features = list(filter(lambda x: x.startswith(AGG_PREFIX), all_columns))\n",
    "offer_features = list(filter(lambda x: x not in user_features + technical_columns, all_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7d5781",
   "metadata": {},
   "source": [
    "### Rebatching datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96990cb",
   "metadata": {},
   "source": [
    "Splitting dataset into smaller batches in the same way as described in [the training for Movielens/IMDB dataset](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/training/movielens%20simple%20model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfa53a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "CPU times: user 30.8 s, sys: 1.19 s, total: 32 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from functools import partial\n",
    "from uuid import uuid4\n",
    "\n",
    "from utils import rebatch_by_events\n",
    "\n",
    "datasets['train'] = rebatch_by_events(datasets['train'], batch_size=5040, date_column='date', nb_events_by_user_by_day=8)\n",
    "for key in ['val', 'test']:\n",
    "    datasets[key] = rebatch_by_events(datasets[key], batch_size=5040, date_column='date', nb_events_by_user_by_day=8,\n",
    "                                      seed=1729).cache(f'/tmp/{uuid4()}.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20173463-08c7-4b6f-a9b8-ade7c5c1121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import add_equal_weights\n",
    "\n",
    "for key in datasets:\n",
    "    datasets[key] = datasets[key].map(partial(add_equal_weights, features=offer_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10790714",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c685bae",
   "metadata": {},
   "source": [
    "First we need to get number of different modalities inputs can take from saved vectorizers (it will be used in embeddings layer definition):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb20fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_inverse_lookups\n",
    "inverse_lookups = load_inverse_lookups(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a92d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "vocabulary_sizes = {}\n",
    "\n",
    "for feature in offer_features:\n",
    "    vocabulary_sizes[feature] = inverse_lookups[feature].vocabulary_size()\n",
    "\n",
    "for feature in user_features:\n",
    "    for key in inverse_lookups:\n",
    "        pattern = re.compile(r\"{}(\\w+)_{}\".format(AGG_PREFIX, key))\n",
    "        if pattern.match(feature):\n",
    "            vocabulary_sizes[feature] = vocabulary_sizes[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e4c620",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffc0d5d6-af03-41b3-b048-0bf847491afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357fd6b2",
   "metadata": {},
   "source": [
    "Now we can assemble all these layers into final model. Note that offer compression weights and interaction kernels are shared between different augmentations we generate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e60cfa",
   "metadata": {},
   "source": [
    "<img src=\"resources/group_by_augmentations_model.png\" alt=\"model\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b8378e",
   "metadata": {},
   "source": [
    "### Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92cd4fc4-85d0-4274-a053-bd1ec955c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "L1_COEFF = 2e-7\n",
    "DROPOUT = 0.1\n",
    "NB_AUGMENTATIONS = 3\n",
    "AVERAGE_NUMBER_OF_FEATURES_IN_AUGMENTATION = 2\n",
    "USER_META_FEATURES = 5\n",
    "OFFER_META_FEATURES = 3\n",
    "\n",
    "def REGULARIZER():\n",
    "    return {'class_name': 'L1L2', 'config': {'l1': L1_COEFF, 'l2': 0.}}\n",
    "\n",
    "def OUTPUT_DNN():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(100,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Activation('tanh'),\n",
    "        tf.keras.layers.Dense(50,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "        tf.keras.layers.Dropout(DROPOUT),\n",
    "        tf.keras.layers.Activation('tanh'),\n",
    "        tf.keras.layers.Dense(1,\n",
    "                              kernel_regularizer=REGULARIZER(),\n",
    "                              bias_regularizer=REGULARIZER()),\n",
    "    ], name='output_Dnn')\n",
    "\n",
    "EPOCHS = 8\n",
    "\n",
    "NUMBER_OF_NEGATIVES = 4\n",
    "LOSS = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "AUC_METRIC = tf.keras.metrics.AUC(from_logits=True)\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "OPTIMIZER = tfa.optimizers.AdamW(weight_decay=4e-8, learning_rate=0.0008)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f94016",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b103374",
   "metadata": {},
   "source": [
    "We will define embeddings with the same `WeightedEmbeddings` layer described in [the training of a simple model](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/training/movielens%20simple%20model.ipynb) with one addition:\n",
    "* for offer features when aggregating a list of embedding vectors, we will also calculate variance and not only mean vector\n",
    "\n",
    "It is easy to do in the same sparse-dense matrix multiplication operation as mean calculation (we get second moment and then calculate variance from it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca4935ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import get_input_layer, WeightedEmbeddings\n",
    "from utils import WEIGHT_SUFFIX\n",
    "\n",
    "inputs = {}\n",
    "embedded_user_features, embedded_offer_features, variance_offer_features = {}, {}, {}\n",
    "for feature in user_features:\n",
    "    inputs[feature] = get_input_layer(feature)\n",
    "    emb_layer = WeightedEmbeddings(vocabulary_sizes[feature],\n",
    "                                   EMBEDDING_DIM, name=f'{feature}_embedding',\n",
    "                                   embeddings_regularizer=REGULARIZER())\n",
    "    embedded_user_features[feature] = emb_layer(inputs[feature])\n",
    "for feature in offer_features:\n",
    "    # for offer features we need weights:\n",
    "    # with dummy weights during training, and the ones used for a feature's averaging at inference time\n",
    "    inputs[f'{feature}_weight'] = get_input_layer(f'{feature}_weight', tf.float32)\n",
    "    inputs[feature] = get_input_layer(feature)\n",
    "    emb_layer = WeightedEmbeddings(vocabulary_sizes[feature],\n",
    "                                   EMBEDDING_DIM, name=f'{feature}_embedding',\n",
    "                                   embeddings_regularizer=REGULARIZER(),\n",
    "                                   calculate_variance=True)\n",
    "    embedded_offer_features[feature], variance_offer_features[feature] =\\\n",
    "        emb_layer(inputs[feature], inputs[f'{feature}_weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f442c975",
   "metadata": {},
   "source": [
    "### Combining everything into model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4753b65",
   "metadata": {},
   "source": [
    "Now we can define described model architecture on the top of embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48eb9977",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stacked = tf.stack(list(embedded_user_features.values()), axis=1)\n",
    "offer_stacked = tf.stack(list(embedded_offer_features.values()), axis=1)\n",
    "offer_variance = tf.stack(list(variance_offer_features.values()), axis=1)\n",
    "stacked_raw_offer_attrs = tf.stack([tf.cast(inp.values, tf.int32) for feature, inp in inputs.items()\n",
    "                                    if feature in offer_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01bc2e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from layers import KeyGenerator, GroupBy\n",
    "from layers import UserFeaturesCompressor\n",
    "from layers import OfferFeaturesCompressor\n",
    "\n",
    "from layers import MaskNet\n",
    "\n",
    "from layers import BiLinearInteraction\n",
    "\n",
    "\n",
    "group_by = GroupBy(name='group_by')\n",
    "key_generator = KeyGenerator(number_of_offer_attributes=len(offer_features),\n",
    "                             average_number_of_attributes_in_key=AVERAGE_NUMBER_OF_FEATURES_IN_AUGMENTATION,\n",
    "                             name='grp_key_generator')\n",
    "\n",
    "user_compressed = UserFeaturesCompressor(USER_META_FEATURES, DROPOUT,\n",
    "                                         name='user_compressor')(user_stacked)\n",
    "offer_features_compressor = OfferFeaturesCompressor(OFFER_META_FEATURES, DROPOUT, name='offer_compressor')\n",
    "mask_net = MaskNet(OFFER_META_FEATURES, DROPOUT, name='mask_generation')\n",
    "apply_mask = tf.keras.layers.Multiply(name='apply_mask')\n",
    "bi_linear_interaction = BiLinearInteraction(number_of_negatives=NUMBER_OF_NEGATIVES, dropout_rate=DROPOUT,\n",
    "                                            initializer='random_normal', regularizer=REGULARIZER(),\n",
    "                                            name='interaction')\n",
    "output_dnn = OUTPUT_DNN()\n",
    "\n",
    "augmentation_predictions = []\n",
    "for i in range(NB_AUGMENTATIONS):\n",
    "    group_by_key = key_generator(stacked_raw_offer_attrs)\n",
    "    mean_offer_emb, variance_offer_emb = group_by(group_by_key, offer_stacked)\n",
    "    compressed_offer_embeddings = offer_features_compressor([mean_offer_emb, variance_offer_emb])\n",
    "    mask = mask_net([mean_offer_emb, variance_offer_emb])\n",
    "    masked_offer_embeddings = apply_mask([compressed_offer_embeddings, mask])\n",
    "    _output = output_dnn(bi_linear_interaction([user_compressed, masked_offer_embeddings], generate_negatives=True))\n",
    "    augmentation_predictions.append(_output)\n",
    "output = tf.concat(augmentation_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e5f2ba-237c-4559-9c1d-40a34508b78d",
   "metadata": {},
   "source": [
    "And for evaluation we don't need to create augmentations, we need just to take offer features' mean and variance coming from inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c4086eb-1451-4db7-abaa-b2eddd5d78b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_offer_embeddings = offer_features_compressor([offer_stacked, offer_variance])\n",
    "mask = mask_net([offer_stacked, offer_variance])\n",
    "masked_offer_embeddings = apply_mask([compressed_offer_embeddings, mask])\n",
    "\n",
    "eval_output = output_dnn(bi_linear_interaction([user_compressed, masked_offer_embeddings], generate_negatives=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2cc3833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import BroadcastLoss, BroadcastMetric\n",
    "\n",
    "model = tf.keras.Model(inputs, output, name='group_by_augmentations')\n",
    "model.compile(optimizer=OPTIMIZER,\n",
    "              loss=BroadcastLoss(LOSS, NUMBER_OF_NEGATIVES),\n",
    "              metrics=[BroadcastMetric(AUC_METRIC, NUMBER_OF_NEGATIVES)])\n",
    "\n",
    "eval_model = tf.keras.Model(inputs, eval_output, name='group_by_augmentations_eval')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e81c8b1",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ce05bab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['date', 'user_id'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/679 [==============================] - 427s 528ms/step - loss: 0.4686 - auc: 0.6910 - val_loss: 0.4479 - val_auc: 0.7155\n",
      "Epoch 2/8\n",
      "679/679 [==============================] - 317s 467ms/step - loss: 0.4448 - auc: 0.7195 - val_loss: 0.4440 - val_auc: 0.7212\n",
      "Epoch 3/8\n",
      "679/679 [==============================] - 349s 513ms/step - loss: 0.4418 - auc: 0.7251 - val_loss: 0.4435 - val_auc: 0.7236\n",
      "Epoch 4/8\n",
      "679/679 [==============================] - 325s 477ms/step - loss: 0.4399 - auc: 0.7288 - val_loss: 0.4448 - val_auc: 0.7228\n",
      "Epoch 5/8\n",
      "679/679 [==============================] - 316s 466ms/step - loss: 0.4398 - auc: 0.7296 - val_loss: 0.4419 - val_auc: 0.7260\n",
      "Epoch 6/8\n",
      "679/679 [==============================] - 327s 482ms/step - loss: 0.4386 - auc: 0.7324 - val_loss: 0.4434 - val_auc: 0.7257\n",
      "Epoch 7/8\n",
      "679/679 [==============================] - 266s 391ms/step - loss: 0.4383 - auc: 0.7337 - val_loss: 0.4417 - val_auc: 0.7296\n",
      "Epoch 8/8\n",
      "679/679 [==============================] - 281s 414ms/step - loss: 0.4371 - auc: 0.7366 - val_loss: 0.4424 - val_auc: 0.7276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f81b85f4760>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datasets['train'], epochs=EPOCHS, validation_data=datasets['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27080ac6-2c87-49b0-b942-7c9bc02c29a0",
   "metadata": {},
   "source": [
    "## Single task models benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb00e26-0475-459a-9973-5aeb2fc8faf3",
   "metadata": {},
   "source": [
    "Using same approach as in [the simple model notebook](https://github.com/tinyclues/recsys-multi-atrribute-benchmark/blob/master/training/movielens%20simple%20model.ipynb) we will look at performance gap between the model with group by augmentations against set of models specialized on tasks corresponding to one offer feature at time. We won't use augmentations in those baseline models, because they will be already aligned with offer we will use in evaluation afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "373994d8-b6ec-4d7c-b878-b8c1f7bc58bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# offer columns we want to evaluate, specific to dataset we test\n",
    "TASKS = ['product_id', 'category1', 'category2', 'category3', 'brand', 'priceCluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2170ef73-1e06-4dda-9463-be8c1e71a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_linear_interaction_model(single_task_feature, name='bi_linear_model'):\n",
    "    # user_features, vocabulary_sizes, EMBEDDING_DIM, REGULARIZER, USER_TOWER, OFFER_TOWER,\n",
    "    # OPTIMIZER, LOSS, NUMBER_OF_NEGATIVES\n",
    "    # come from global scope, but can be passed as params instead\n",
    "    inputs = {}\n",
    "    embedded_user_features, embedded_offer_features, variance_offer_features = {}, {}, {}\n",
    "    for feature in user_features:\n",
    "        inputs[feature] = get_input_layer(feature)\n",
    "        emb_layer = WeightedEmbeddings(vocabulary_sizes[feature],\n",
    "                                       EMBEDDING_DIM, name=f'{feature}_embedding',\n",
    "                                       embeddings_regularizer=REGULARIZER())\n",
    "        embedded_user_features[feature] = emb_layer(inputs[feature])\n",
    "\n",
    "    # for offer feature we need weights:\n",
    "    # with dummy weights during training, and the ones used for a feature's averaging at inference time\n",
    "    inputs[f'{single_task_feature}_weight'] = get_input_layer(f'{single_task_feature}_weight', tf.float32)\n",
    "    inputs[single_task_feature] = get_input_layer(single_task_feature)\n",
    "    emb_layer = WeightedEmbeddings(vocabulary_sizes[single_task_feature],\n",
    "                                   EMBEDDING_DIM, name=f'{single_task_feature}_embedding',\n",
    "                                   embeddings_regularizer=REGULARIZER())\n",
    "    embedded_offer_feature = emb_layer(inputs[single_task_feature],\n",
    "                                       inputs[f'{single_task_feature}_weight'])\n",
    "    \n",
    "    user_stacked = tf.stack(list(embedded_user_features.values()), axis=1)\n",
    "    offer_stacked = tf.expand_dims(embedded_offer_feature, axis=1)\n",
    "    \n",
    "    \n",
    "    user_compressed = UserFeaturesCompressor(USER_META_FEATURES, DROPOUT,\n",
    "                                             name='user_compressor')(user_stacked)\n",
    "    mask_net = MaskNet(OFFER_META_FEATURES, DROPOUT, name='mask_generation')\n",
    "    apply_mask = tf.keras.layers.Multiply(name='apply_mask')\n",
    "    bi_linear_interaction = BiLinearInteraction(number_of_negatives=NUMBER_OF_NEGATIVES, dropout_rate=DROPOUT,\n",
    "                                                initializer='random_normal', regularizer=REGULARIZER(),\n",
    "                                                name='interaction')\n",
    "    output_dnn = OUTPUT_DNN()\n",
    "\n",
    "    \n",
    "    mask = mask_net([offer_stacked, offer_stacked])\n",
    "    masked_offer_embeddings = apply_mask([offer_stacked, mask])\n",
    "    \n",
    "    output = OUTPUT_DNN()(bi_linear_interaction([user_compressed, masked_offer_embeddings],\n",
    "                                                generate_negatives=True))\n",
    "\n",
    "    model = tf.keras.Model(inputs, output, name=name)\n",
    "    model.compile(optimizer=OPTIMIZER,\n",
    "                  loss=BroadcastLoss(LOSS, NUMBER_OF_NEGATIVES),\n",
    "                  metrics=[BroadcastMetric(AUC_METRIC, NUMBER_OF_NEGATIVES)])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34c6b37f-b971-41b6-bc36-e60974bcdb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/679 [==============================] - 195s 251ms/step - loss: 0.4535 - auc: 0.7277 - val_loss: 0.4385 - val_auc: 0.7514\n",
      "Epoch 2/8\n",
      "679/679 [==============================] - 156s 229ms/step - loss: 0.4291 - auc: 0.7639 - val_loss: 0.4338 - val_auc: 0.7572\n",
      "Epoch 3/8\n",
      "679/679 [==============================] - 152s 223ms/step - loss: 0.4222 - auc: 0.7732 - val_loss: 0.4351 - val_auc: 0.7575\n",
      "Epoch 4/8\n",
      "679/679 [==============================] - 149s 220ms/step - loss: 0.4182 - auc: 0.7798 - val_loss: 0.4357 - val_auc: 0.7567\n",
      "Epoch 5/8\n",
      "679/679 [==============================] - 149s 219ms/step - loss: 0.4153 - auc: 0.7848 - val_loss: 0.4375 - val_auc: 0.7565\n",
      "Epoch 6/8\n",
      "679/679 [==============================] - 149s 219ms/step - loss: 0.4131 - auc: 0.7892 - val_loss: 0.4405 - val_auc: 0.7552\n",
      "Epoch 7/8\n",
      "679/679 [==============================] - 148s 218ms/step - loss: 0.4110 - auc: 0.7931 - val_loss: 0.4438 - val_auc: 0.7534\n",
      "Epoch 8/8\n",
      "679/679 [==============================] - 150s 221ms/step - loss: 0.4091 - auc: 0.7969 - val_loss: 0.4451 - val_auc: 0.7524\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category2_weight', 'product_id_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/679 [==============================] - 188s 239ms/step - loss: 0.4770 - auc: 0.6768 - val_loss: 0.4707 - val_auc: 0.6721\n",
      "Epoch 2/8\n",
      "679/679 [==============================] - 160s 236ms/step - loss: 0.4700 - auc: 0.6730 - val_loss: 0.4698 - val_auc: 0.6730\n",
      "Epoch 3/8\n",
      "679/679 [==============================] - 177s 259ms/step - loss: 0.4689 - auc: 0.6746 - val_loss: 0.4695 - val_auc: 0.6731\n",
      "Epoch 4/8\n",
      "679/679 [==============================] - 164s 241ms/step - loss: 0.4681 - auc: 0.6762 - val_loss: 0.4696 - val_auc: 0.6729\n",
      "Epoch 5/8\n",
      "679/679 [==============================] - 151s 223ms/step - loss: 0.4673 - auc: 0.6779 - val_loss: 0.4695 - val_auc: 0.6728\n",
      "Epoch 6/8\n",
      "679/679 [==============================] - 149s 220ms/step - loss: 0.4666 - auc: 0.6797 - val_loss: 0.4700 - val_auc: 0.6725\n",
      "Epoch 7/8\n",
      "679/679 [==============================] - 149s 220ms/step - loss: 0.4659 - auc: 0.6818 - val_loss: 0.4709 - val_auc: 0.6715\n",
      "Epoch 8/8\n",
      "679/679 [==============================] - 152s 224ms/step - loss: 0.4654 - auc: 0.6836 - val_loss: 0.4716 - val_auc: 0.6708\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'product_id_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/679 [==============================] - 195s 248ms/step - loss: 0.4696 - auc: 0.6762 - val_loss: 0.4619 - val_auc: 0.6868\n",
      "Epoch 2/8\n",
      "679/679 [==============================] - 150s 220ms/step - loss: 0.4609 - auc: 0.6883 - val_loss: 0.4609 - val_auc: 0.6881\n",
      "Epoch 3/8\n",
      "679/679 [==============================] - 149s 218ms/step - loss: 0.4598 - auc: 0.6903 - val_loss: 0.4608 - val_auc: 0.6883\n",
      "Epoch 4/8\n",
      "679/679 [==============================] - 149s 219ms/step - loss: 0.4591 - auc: 0.6917 - val_loss: 0.4607 - val_auc: 0.6885\n",
      "Epoch 5/8\n",
      "679/679 [==============================] - 151s 223ms/step - loss: 0.4586 - auc: 0.6930 - val_loss: 0.4612 - val_auc: 0.6886\n",
      "Epoch 6/8\n",
      "679/679 [==============================] - 155s 227ms/step - loss: 0.4580 - auc: 0.6949 - val_loss: 0.4621 - val_auc: 0.6885\n",
      "Epoch 7/8\n",
      "679/679 [==============================] - 154s 227ms/step - loss: 0.4574 - auc: 0.6966 - val_loss: 0.4620 - val_auc: 0.6877\n",
      "Epoch 8/8\n",
      "679/679 [==============================] - 154s 226ms/step - loss: 0.4568 - auc: 0.6986 - val_loss: 0.4640 - val_auc: 0.6868\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/679 [==============================] - 210s 268ms/step - loss: 0.4724 - auc: 0.6718 - val_loss: 0.4637 - val_auc: 0.6817\n",
      "Epoch 2/8\n",
      "679/679 [==============================] - 172s 253ms/step - loss: 0.4629 - auc: 0.6823 - val_loss: 0.4630 - val_auc: 0.6831\n",
      "Epoch 3/8\n",
      "679/679 [==============================] - 176s 259ms/step - loss: 0.4616 - auc: 0.6845 - val_loss: 0.4626 - val_auc: 0.6835\n",
      "Epoch 4/8\n",
      "679/679 [==============================] - 172s 253ms/step - loss: 0.4607 - auc: 0.6861 - val_loss: 0.4625 - val_auc: 0.6836\n",
      "Epoch 5/8\n",
      "679/679 [==============================] - 157s 230ms/step - loss: 0.4602 - auc: 0.6874 - val_loss: 0.4623 - val_auc: 0.6839\n",
      "Epoch 6/8\n",
      "679/679 [==============================] - 158s 232ms/step - loss: 0.4597 - auc: 0.6888 - val_loss: 0.4628 - val_auc: 0.6838\n",
      "Epoch 7/8\n",
      "679/679 [==============================] - 158s 232ms/step - loss: 0.4591 - auc: 0.6907 - val_loss: 0.4634 - val_auc: 0.6833\n",
      "Epoch 8/8\n",
      "679/679 [==============================] - 160s 236ms/step - loss: 0.4586 - auc: 0.6925 - val_loss: 0.4641 - val_auc: 0.6827\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'category3_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/679 [==============================] - 197s 249ms/step - loss: 0.4550 - auc: 0.7120 - val_loss: 0.4447 - val_auc: 0.7302\n",
      "Epoch 2/8\n",
      "679/679 [==============================] - 144s 212ms/step - loss: 0.4414 - auc: 0.7341 - val_loss: 0.4415 - val_auc: 0.7336\n",
      "Epoch 3/8\n",
      "679/679 [==============================] - 144s 212ms/step - loss: 0.4388 - auc: 0.7379 - val_loss: 0.4409 - val_auc: 0.7343\n",
      "Epoch 4/8\n",
      "679/679 [==============================] - 143s 211ms/step - loss: 0.4374 - auc: 0.7400 - val_loss: 0.4407 - val_auc: 0.7346\n",
      "Epoch 5/8\n",
      "679/679 [==============================] - 144s 211ms/step - loss: 0.4364 - auc: 0.7419 - val_loss: 0.4414 - val_auc: 0.7342\n",
      "Epoch 6/8\n",
      "679/679 [==============================] - 144s 211ms/step - loss: 0.4355 - auc: 0.7440 - val_loss: 0.4423 - val_auc: 0.7342\n",
      "Epoch 7/8\n",
      "679/679 [==============================] - 158s 233ms/step - loss: 0.4346 - auc: 0.7462 - val_loss: 0.4425 - val_auc: 0.7338\n",
      "Epoch 8/8\n",
      "679/679 [==============================] - 151s 222ms/step - loss: 0.4338 - auc: 0.7482 - val_loss: 0.4446 - val_auc: 0.7332\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'brand', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'category3_weight', 'brand_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/679 [==============================] - 182s 233ms/step - loss: 0.4649 - auc: 0.6908 - val_loss: 0.4555 - val_auc: 0.6980\n",
      "Epoch 2/8\n",
      "679/679 [==============================] - 146s 215ms/step - loss: 0.4531 - auc: 0.7010 - val_loss: 0.4538 - val_auc: 0.7009\n",
      "Epoch 3/8\n",
      "679/679 [==============================] - 144s 212ms/step - loss: 0.4513 - auc: 0.7047 - val_loss: 0.4534 - val_auc: 0.7025\n",
      "Epoch 4/8\n",
      "679/679 [==============================] - 145s 213ms/step - loss: 0.4504 - auc: 0.7071 - val_loss: 0.4536 - val_auc: 0.7024\n",
      "Epoch 5/8\n",
      "679/679 [==============================] - 143s 211ms/step - loss: 0.4498 - auc: 0.7090 - val_loss: 0.4547 - val_auc: 0.7027\n",
      "Epoch 6/8\n",
      "679/679 [==============================] - 144s 211ms/step - loss: 0.4492 - auc: 0.7110 - val_loss: 0.4543 - val_auc: 0.7023\n",
      "Epoch 7/8\n",
      "679/679 [==============================] - 144s 211ms/step - loss: 0.4488 - auc: 0.7130 - val_loss: 0.4550 - val_auc: 0.7027\n",
      "Epoch 8/8\n",
      "679/679 [==============================] - 144s 212ms/step - loss: 0.4484 - auc: 0.7149 - val_loss: 0.4569 - val_auc: 0.7012\n"
     ]
    }
   ],
   "source": [
    "mono_feature_models = {}\n",
    "for task_offer_feature in TASKS:\n",
    "    mono_feature_models[task_offer_feature] =\\\n",
    "        bi_linear_interaction_model(task_offer_feature, name=f'{task_offer_feature}_model')\n",
    "    mono_feature_models[task_offer_feature].fit(datasets['train'],\n",
    "                                                epochs=EPOCHS,\n",
    "                                                validation_data=datasets['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cc7d11-391a-4466-9bb5-bf9f2bbcc203",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb861dcc-1c7c-4a3e-be52-864c97543ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 25s, sys: 19.1 s, total: 4min 44s\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from utils import prepare_single_task_dataset\n",
    "test_datasets = {}\n",
    "for task_offer_feature in TASKS:\n",
    "    test_datasets[task_offer_feature] = \\\n",
    "        prepare_single_task_dataset(datasets['test'], task_offer_feature, offer_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "644699ac-98a0-496d-8a76-afb73852bc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category2_weight', 'product_id_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'product_id_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'category3_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'brand', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'category3_weight', 'brand_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['date', 'user_id'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category2_weight', 'product_id_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'product_id_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'category3_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'brand', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'category3_weight', 'brand_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['date', 'user_id'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category2_weight', 'product_id_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'product_id_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'category3_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'brand', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'category3_weight', 'brand_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['date', 'user_id'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category2_weight', 'product_id_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'product_id_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'category3_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'brand', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'category3_weight', 'brand_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['date', 'user_id'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category2_weight', 'product_id_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'product_id_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'category3_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'brand', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'category3_weight', 'brand_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['date', 'user_id'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category2_weight', 'product_id_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['product_id', 'category3', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'product_id_weight', 'category3_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'date', 'brand', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'brand_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'priceCluster', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'category3_weight', 'priceCluster_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['category2', 'product_id', 'category3', 'date', 'brand', 'user_id', 'category1', 'category2_weight', 'product_id_weight', 'category3_weight', 'brand_weight', 'category1_weight'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "/usr/local/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['date', 'user_id'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 29min 4s, sys: 24min 25s, total: 3h 53min 29s\n",
      "Wall time: 1h 10min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "from utils import evaluate_model, wAUC\n",
    "\n",
    "aucs = defaultdict(dict)\n",
    "for task_offer_feature in TASKS:\n",
    "    for model_name in TASKS:\n",
    "        aucs[task_offer_feature][f'MONO:{model_name}'] = \\\n",
    "            evaluate_model(mono_feature_models[model_name],\n",
    "                           task_offer_feature, test_datasets, NUMBER_OF_NEGATIVES, inverse_lookups)\n",
    "    aucs[task_offer_feature]['group_by augmentations'] = \\\n",
    "            evaluate_model(eval_model, task_offer_feature, test_datasets, NUMBER_OF_NEGATIVES, inverse_lookups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f862e7c9-c599-408c-8572-d2f924a36806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.DataFrame()\n",
    "for task_name in aucs:\n",
    "    for model_name in aucs[task_name]:\n",
    "        w_auc = wAUC(aucs[task_name][model_name])\n",
    "        results = pd.concat([results,\n",
    "                             pd.Series({'wAUC': w_auc, 'offers': task_name, 'model': model_name}).to_frame().T],\n",
    "                            ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec9ac730-c8f3-4a95-8102-a2551742f98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1b3f5_row0_col0, #T_1b3f5_row1_col1, #T_1b3f5_row2_col2, #T_1b3f5_row3_col3, #T_1b3f5_row4_col4, #T_1b3f5_row6_col5 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1b3f5_row0_col1 {\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1b3f5_row0_col2 {\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1b3f5_row0_col3 {\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1b3f5_row0_col4 {\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1b3f5_row0_col5 {\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1b3f5_row1_col0, #T_1b3f5_row2_col4, #T_1b3f5_row3_col5, #T_1b3f5_row4_col1, #T_1b3f5_row4_col2, #T_1b3f5_row4_col3 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1b3f5_row1_col2 {\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1b3f5_row1_col3, #T_1b3f5_row5_col0 {\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1b3f5_row1_col4 {\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1b3f5_row1_col5 {\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1b3f5_row2_col0, #T_1b3f5_row2_col5 {\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1b3f5_row2_col1 {\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1b3f5_row2_col3 {\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1b3f5_row3_col0 {\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1b3f5_row3_col1 {\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1b3f5_row3_col2 {\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1b3f5_row3_col4 {\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1b3f5_row4_col0 {\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1b3f5_row4_col5 {\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1b3f5_row5_col1 {\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1b3f5_row5_col2 {\n",
       "  background-color: #f5c0a7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1b3f5_row5_col3 {\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1b3f5_row5_col4 {\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1b3f5_row5_col5 {\n",
       "  background-color: #b70d28;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1b3f5_row6_col0 {\n",
       "  background-color: #b50927;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1b3f5_row6_col1 {\n",
       "  background-color: #d1493f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1b3f5_row6_col2 {\n",
       "  background-color: #b8122a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1b3f5_row6_col3 {\n",
       "  background-color: #c0282f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1b3f5_row6_col4 {\n",
       "  background-color: #cd423b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1b3f5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >offers</th>\n",
       "      <th id=\"T_1b3f5_level0_col0\" class=\"col_heading level0 col0\" >brand</th>\n",
       "      <th id=\"T_1b3f5_level0_col1\" class=\"col_heading level0 col1\" >category1</th>\n",
       "      <th id=\"T_1b3f5_level0_col2\" class=\"col_heading level0 col2\" >category2</th>\n",
       "      <th id=\"T_1b3f5_level0_col3\" class=\"col_heading level0 col3\" >category3</th>\n",
       "      <th id=\"T_1b3f5_level0_col4\" class=\"col_heading level0 col4\" >price</th>\n",
       "      <th id=\"T_1b3f5_level0_col5\" class=\"col_heading level0 col5\" >product_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1b3f5_level0_row0\" class=\"row_heading level0 row0\" >MONO:brand</th>\n",
       "      <td id=\"T_1b3f5_row0_col0\" class=\"data row0 col0\" >0.760</td>\n",
       "      <td id=\"T_1b3f5_row0_col1\" class=\"data row0 col1\" >0.622</td>\n",
       "      <td id=\"T_1b3f5_row0_col2\" class=\"data row0 col2\" >0.641</td>\n",
       "      <td id=\"T_1b3f5_row0_col3\" class=\"data row0 col3\" >0.628</td>\n",
       "      <td id=\"T_1b3f5_row0_col4\" class=\"data row0 col4\" >0.606</td>\n",
       "      <td id=\"T_1b3f5_row0_col5\" class=\"data row0 col5\" >0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1b3f5_level0_row1\" class=\"row_heading level0 row1\" >MONO:category1</th>\n",
       "      <td id=\"T_1b3f5_row1_col0\" class=\"data row1 col0\" >0.647</td>\n",
       "      <td id=\"T_1b3f5_row1_col1\" class=\"data row1 col1\" >0.734</td>\n",
       "      <td id=\"T_1b3f5_row1_col2\" class=\"data row1 col2\" >0.728</td>\n",
       "      <td id=\"T_1b3f5_row1_col3\" class=\"data row1 col3\" >0.710</td>\n",
       "      <td id=\"T_1b3f5_row1_col4\" class=\"data row1 col4\" >0.575</td>\n",
       "      <td id=\"T_1b3f5_row1_col5\" class=\"data row1 col5\" >0.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1b3f5_level0_row2\" class=\"row_heading level0 row2\" >MONO:category2</th>\n",
       "      <td id=\"T_1b3f5_row2_col0\" class=\"data row2 col0\" >0.654</td>\n",
       "      <td id=\"T_1b3f5_row2_col1\" class=\"data row2 col1\" >0.722</td>\n",
       "      <td id=\"T_1b3f5_row2_col2\" class=\"data row2 col2\" >0.741</td>\n",
       "      <td id=\"T_1b3f5_row2_col3\" class=\"data row2 col3\" >0.701</td>\n",
       "      <td id=\"T_1b3f5_row2_col4\" class=\"data row2 col4\" >0.571</td>\n",
       "      <td id=\"T_1b3f5_row2_col5\" class=\"data row2 col5\" >0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1b3f5_level0_row3\" class=\"row_heading level0 row3\" >MONO:category3</th>\n",
       "      <td id=\"T_1b3f5_row3_col0\" class=\"data row3 col0\" >0.651</td>\n",
       "      <td id=\"T_1b3f5_row3_col1\" class=\"data row3 col1\" >0.699</td>\n",
       "      <td id=\"T_1b3f5_row3_col2\" class=\"data row3 col2\" >0.715</td>\n",
       "      <td id=\"T_1b3f5_row3_col3\" class=\"data row3 col3\" >0.745</td>\n",
       "      <td id=\"T_1b3f5_row3_col4\" class=\"data row3 col4\" >0.574</td>\n",
       "      <td id=\"T_1b3f5_row3_col5\" class=\"data row3 col5\" >0.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1b3f5_level0_row4\" class=\"row_heading level0 row4\" >MONO:price</th>\n",
       "      <td id=\"T_1b3f5_row4_col0\" class=\"data row4 col0\" >0.657</td>\n",
       "      <td id=\"T_1b3f5_row4_col1\" class=\"data row4 col1\" >0.583</td>\n",
       "      <td id=\"T_1b3f5_row4_col2\" class=\"data row4 col2\" >0.590</td>\n",
       "      <td id=\"T_1b3f5_row4_col3\" class=\"data row4 col3\" >0.602</td>\n",
       "      <td id=\"T_1b3f5_row4_col4\" class=\"data row4 col4\" >0.705</td>\n",
       "      <td id=\"T_1b3f5_row4_col5\" class=\"data row4 col5\" >0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1b3f5_level0_row5\" class=\"row_heading level0 row5\" >MONO:product_id</th>\n",
       "      <td id=\"T_1b3f5_row5_col0\" class=\"data row5 col0\" >0.733</td>\n",
       "      <td id=\"T_1b3f5_row5_col1\" class=\"data row5 col1\" >0.676</td>\n",
       "      <td id=\"T_1b3f5_row5_col2\" class=\"data row5 col2\" >0.686</td>\n",
       "      <td id=\"T_1b3f5_row5_col3\" class=\"data row5 col3\" >0.680</td>\n",
       "      <td id=\"T_1b3f5_row5_col4\" class=\"data row5 col4\" >0.652</td>\n",
       "      <td id=\"T_1b3f5_row5_col5\" class=\"data row5 col5\" >0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1b3f5_level0_row6\" class=\"row_heading level0 row6\" >group_by augmentations</th>\n",
       "      <td id=\"T_1b3f5_row6_col0\" class=\"data row6 col0\" >0.760</td>\n",
       "      <td id=\"T_1b3f5_row6_col1\" class=\"data row6 col1\" >0.721</td>\n",
       "      <td id=\"T_1b3f5_row6_col2\" class=\"data row6 col2\" >0.739</td>\n",
       "      <td id=\"T_1b3f5_row6_col3\" class=\"data row6 col3\" >0.740</td>\n",
       "      <td id=\"T_1b3f5_row6_col4\" class=\"data row6 col4\" >0.695</td>\n",
       "      <td id=\"T_1b3f5_row6_col5\" class=\"data row6 col5\" >0.773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8079226bb0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(results, 'wAUC', 'model', 'offers')\\\n",
    "    .rename(columns={'priceCluster': 'price'}, index={'MONO:priceCluster': 'MONO:price'})\\\n",
    "    .style.background_gradient(cmap='coolwarm').format(precision=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom [moksha-tf2-cpu.2-7] (Local)",
   "language": "python",
   "name": "local-eu.gcr.io_tinyclues-experiments_tinyclues_moksha-tf2-cpu.2-7_latest__moksha"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
